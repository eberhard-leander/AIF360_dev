{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of the fairness adjuster, using the same structure as the AIF360 adversarial debiasing example\n",
    "\n",
    "The source notebook can be found here:\n",
    "https://github.com/Trusted-AI/AIF360/blob/main/examples/demo_adversarial_debiasing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "from aif360.algorithms.inprocessing.fairness_adjuster import FairnessAdjuster\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import (\n",
    "    load_preproc_data_adult,\n",
    "    load_preproc_data_compas,\n",
    "    load_preproc_data_german,\n",
    ")\n",
    "from aif360.datasets import (\n",
    "    AdultDataset,\n",
    "    BinaryLabelDataset,\n",
    "    CompasDataset,\n",
    "    GermanDataset,\n",
    ")\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AIF360_dev/aif360/algorithms/preprocessing/optim_preproc_helpers/data_preproc_functions.py:261: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sex'] = df['personal_status'].replace(status_map)\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig = load_preproc_data_german([\"age\", \"sex\"])\n",
    "\n",
    "# privileged_groups = [{'sex': 1}]\n",
    "# unprivileged_groups = [{'sex': 0}]\n",
    "privileged_groups = [{\"age\": 1}]\n",
    "unprivileged_groups = [{\"age\": 0}]\n",
    "\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 11)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(\n",
    "    dataset_orig_train.privileged_protected_attributes,\n",
    "    dataset_orig_train.unprivileged_protected_attributes,\n",
    ")\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.155667\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.136994\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_train,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_orig_train.mean_difference()\n",
    ")\n",
    "metric_orig_test = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_orig_test.mean_difference()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.155667\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.136994\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_train,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "display(\n",
    "    Markdown(\n",
    "        \"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_scaled_train.mean_difference()\n",
    ")\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_scaled_test.mean_difference()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn plan classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 21:00:33.819383: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session()\n",
    "plain_model = FairnessAdjuster(\n",
    "    privileged_groups=privileged_groups,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    scope_name=\"plain_classifier\",\n",
    "    debias=False,\n",
    "    sess=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/aif360/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "epoch 0; iter: 0; batch classifier loss: 0.650745\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733432434.206422   30857 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.558319\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579147\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566931\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607225\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533261\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616294\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537298\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548235\n",
      "epoch 10; iter: 0; batch classifier loss: 0.554410\n",
      "epoch 11; iter: 0; batch classifier loss: 0.608081\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556615\n",
      "epoch 13; iter: 0; batch classifier loss: 0.573949\n",
      "epoch 14; iter: 0; batch classifier loss: 0.556723\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526735\n",
      "epoch 16; iter: 0; batch classifier loss: 0.559974\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550279\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514289\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545309\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529533\n",
      "epoch 21; iter: 0; batch classifier loss: 0.546288\n",
      "epoch 22; iter: 0; batch classifier loss: 0.569639\n",
      "epoch 23; iter: 0; batch classifier loss: 0.517402\n",
      "epoch 24; iter: 0; batch classifier loss: 0.583733\n",
      "epoch 25; iter: 0; batch classifier loss: 0.613359\n",
      "epoch 26; iter: 0; batch classifier loss: 0.523738\n",
      "epoch 27; iter: 0; batch classifier loss: 0.616372\n",
      "epoch 28; iter: 0; batch classifier loss: 0.573764\n",
      "epoch 29; iter: 0; batch classifier loss: 0.541072\n",
      "epoch 30; iter: 0; batch classifier loss: 0.556841\n",
      "epoch 31; iter: 0; batch classifier loss: 0.575477\n",
      "epoch 32; iter: 0; batch classifier loss: 0.601627\n",
      "epoch 33; iter: 0; batch classifier loss: 0.525806\n",
      "epoch 34; iter: 0; batch classifier loss: 0.606264\n",
      "epoch 35; iter: 0; batch classifier loss: 0.521694\n",
      "epoch 36; iter: 0; batch classifier loss: 0.537592\n",
      "epoch 37; iter: 0; batch classifier loss: 0.587794\n",
      "epoch 38; iter: 0; batch classifier loss: 0.535225\n",
      "epoch 39; iter: 0; batch classifier loss: 0.561874\n",
      "epoch 40; iter: 0; batch classifier loss: 0.529434\n",
      "epoch 41; iter: 0; batch classifier loss: 0.587057\n",
      "epoch 42; iter: 0; batch classifier loss: 0.481440\n",
      "epoch 43; iter: 0; batch classifier loss: 0.547608\n",
      "epoch 44; iter: 0; batch classifier loss: 0.540144\n",
      "epoch 45; iter: 0; batch classifier loss: 0.542309\n",
      "epoch 46; iter: 0; batch classifier loss: 0.603932\n",
      "epoch 47; iter: 0; batch classifier loss: 0.552696\n",
      "epoch 48; iter: 0; batch classifier loss: 0.463467\n",
      "epoch 49; iter: 0; batch classifier loss: 0.513515\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.082519\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.013632\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.024079\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.010524\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.012157\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.009310\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.009111\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.010962\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.009790\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.008231\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.008704\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.006358\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.006671\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.006254\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.006257\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.005885\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.007727\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.004789\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.006122\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.006307\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.005310\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.005081\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.005261\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.006084\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.004954\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.003905\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.004542\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.003872\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.004555\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.004269\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.002615\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.003825\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.003801\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.003206\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.003160\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.003515\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.003164\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.003250\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.003105\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.003103\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.002350\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.002658\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.003155\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.003074\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.002819\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.002570\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.002789\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.002273\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.002424\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.002177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.fairness_adjuster.FairnessAdjuster at 0x7f05498d2fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 21:00:35.097035: W tensorflow/c/c_api.cc:305] Operation '{name:'plain_classifier/plain_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node plain_classifier/plain_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](plain_classifier/plain_classifier/classifier_model/b2/Adam_1, plain_classifier/plain_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.228974\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.361702\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.713333\n",
      "Test set: Balanced classification accuracy = 0.552439\n",
      "Test set: Disparate impact = 0.638298\n",
      "Test set: Equal opportunity difference = -0.185185\n",
      "Test set: Average odds difference = -0.392593\n",
      "Test set: Theil_index = 0.072837\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(\n",
    "    dataset_nodebiasing_train,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_nodebiasing_train.mean_difference()\n",
    ")\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(\n",
    "    dataset_nodebiasing_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_nodebiasing_test.mean_difference()\n",
    ")\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(\n",
    "    dataset_orig_test,\n",
    "    dataset_nodebiasing_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "print(\n",
    "    \"Test set: Classification accuracy = %f\"\n",
    "    % classified_metric_nodebiasing_test.accuracy()\n",
    ")\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5 * (TPR + TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\n",
    "    \"Test set: Disparate impact = %f\"\n",
    "    % classified_metric_nodebiasing_test.disparate_impact()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Equal opportunity difference = %f\"\n",
    "    % classified_metric_nodebiasing_test.equal_opportunity_difference()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Average odds difference = %f\"\n",
    "    % classified_metric_nodebiasing_test.average_odds_difference()\n",
    ")\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = FairnessAdjuster(\n",
    "    privileged_groups=privileged_groups,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    scope_name=\"debiased_classifier\",\n",
    "    adversary_loss_weight=0.01,\n",
    "    debias=True,\n",
    "    sess=sess,\n",
    "    classifier_num_hidden_units=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = FairnessAdjuster(\n",
    "    privileged_groups=privileged_groups,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    scope_name=\"debiased_classifier\",\n",
    "    adversary_loss_weight=0.01,\n",
    "    debias=True,\n",
    "    sess=sess,\n",
    "    classifier_num_hidden_units=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.640058\n",
      "epoch 1; iter: 0; batch classifier loss: 0.623254\n",
      "epoch 2; iter: 0; batch classifier loss: 0.601313\n",
      "epoch 3; iter: 0; batch classifier loss: 0.601454\n",
      "epoch 4; iter: 0; batch classifier loss: 0.588761\n",
      "epoch 5; iter: 0; batch classifier loss: 0.536065\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567071\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555931\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559509\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545400\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.587716\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503853\n",
      "epoch 13; iter: 0; batch classifier loss: 0.605185\n",
      "epoch 14; iter: 0; batch classifier loss: 0.597196\n",
      "epoch 15; iter: 0; batch classifier loss: 0.573468\n",
      "epoch 16; iter: 0; batch classifier loss: 0.581813\n",
      "epoch 17; iter: 0; batch classifier loss: 0.573018\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496678\n",
      "epoch 19; iter: 0; batch classifier loss: 0.590861\n",
      "epoch 20; iter: 0; batch classifier loss: 0.535679\n",
      "epoch 21; iter: 0; batch classifier loss: 0.526133\n",
      "epoch 22; iter: 0; batch classifier loss: 0.581727\n",
      "epoch 23; iter: 0; batch classifier loss: 0.527542\n",
      "epoch 24; iter: 0; batch classifier loss: 0.506340\n",
      "epoch 25; iter: 0; batch classifier loss: 0.580390\n",
      "epoch 26; iter: 0; batch classifier loss: 0.525923\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505049\n",
      "epoch 28; iter: 0; batch classifier loss: 0.557393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.637025\n",
      "epoch 30; iter: 0; batch classifier loss: 0.562302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.590076\n",
      "epoch 32; iter: 0; batch classifier loss: 0.571657\n",
      "epoch 33; iter: 0; batch classifier loss: 0.545940\n",
      "epoch 34; iter: 0; batch classifier loss: 0.604684\n",
      "epoch 35; iter: 0; batch classifier loss: 0.599919\n",
      "epoch 36; iter: 0; batch classifier loss: 0.578144\n",
      "epoch 37; iter: 0; batch classifier loss: 0.547508\n",
      "epoch 38; iter: 0; batch classifier loss: 0.565602\n",
      "epoch 39; iter: 0; batch classifier loss: 0.505427\n",
      "epoch 40; iter: 0; batch classifier loss: 0.550944\n",
      "epoch 41; iter: 0; batch classifier loss: 0.518262\n",
      "epoch 42; iter: 0; batch classifier loss: 0.614523\n",
      "epoch 43; iter: 0; batch classifier loss: 0.535789\n",
      "epoch 44; iter: 0; batch classifier loss: 0.505960\n",
      "epoch 45; iter: 0; batch classifier loss: 0.599350\n",
      "epoch 46; iter: 0; batch classifier loss: 0.652107\n",
      "epoch 47; iter: 0; batch classifier loss: 0.536579\n",
      "epoch 48; iter: 0; batch classifier loss: 0.557859\n",
      "epoch 49; iter: 0; batch classifier loss: 0.627486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 23:41:21.361115: W tensorflow/c/c_api.cc:305] Operation '{name:'plain_classifier/plain_classifier_1/adjuster_model/b2/Adam_1/Assign' id:583 op device:{requested: '', assigned: ''} def:{{{node plain_classifier/plain_classifier_1/adjuster_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](plain_classifier/plain_classifier_1/adjuster_model/b2/Adam_1, plain_classifier/plain_classifier_1/adjuster_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch adjuster loss: 0.049534; batch classifier loss; 0.588066; batch adversarial loss: 1.138376\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.025235; batch classifier loss; 0.589828; batch adversarial loss: 1.100961\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.021321; batch classifier loss; 0.529649; batch adversarial loss: 1.120205\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.015487; batch classifier loss; 0.553760; batch adversarial loss: 1.127738\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.016768; batch classifier loss; 0.506626; batch adversarial loss: 1.081528\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.013977; batch classifier loss; 0.587664; batch adversarial loss: 1.090887\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.015725; batch classifier loss; 0.588134; batch adversarial loss: 1.109634\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.009863; batch classifier loss; 0.593729; batch adversarial loss: 1.152706\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.011342; batch classifier loss; 0.544848; batch adversarial loss: 1.098327\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.008431; batch classifier loss; 0.531620; batch adversarial loss: 1.107135\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.007115; batch classifier loss; 0.516499; batch adversarial loss: 1.034185\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.006168; batch classifier loss; 0.567754; batch adversarial loss: 1.089671\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.007455; batch classifier loss; 0.580073; batch adversarial loss: 1.024985\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.006204; batch classifier loss; 0.514363; batch adversarial loss: 1.040537\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.005867; batch classifier loss; 0.495775; batch adversarial loss: 1.033910\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.004685; batch classifier loss; 0.509567; batch adversarial loss: 1.023989\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.004693; batch classifier loss; 0.645288; batch adversarial loss: 1.069946\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.004151; batch classifier loss; 0.537775; batch adversarial loss: 1.000667\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.003758; batch classifier loss; 0.619252; batch adversarial loss: 1.004594\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.004483; batch classifier loss; 0.553178; batch adversarial loss: 1.032831\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.002849; batch classifier loss; 0.528698; batch adversarial loss: 0.993939\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.003306; batch classifier loss; 0.575877; batch adversarial loss: 0.966346\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.002891; batch classifier loss; 0.598825; batch adversarial loss: 0.989212\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.003218; batch classifier loss; 0.568921; batch adversarial loss: 1.043969\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.004490; batch classifier loss; 0.568132; batch adversarial loss: 0.999659\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.002953; batch classifier loss; 0.556603; batch adversarial loss: 0.982787\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.003600; batch classifier loss; 0.518103; batch adversarial loss: 0.983201\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.002931; batch classifier loss; 0.619266; batch adversarial loss: 0.987053\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.003683; batch classifier loss; 0.538556; batch adversarial loss: 0.957922\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.004071; batch classifier loss; 0.555713; batch adversarial loss: 0.983141\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.003591; batch classifier loss; 0.504479; batch adversarial loss: 0.905631\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.003295; batch classifier loss; 0.557789; batch adversarial loss: 0.918371\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.003861; batch classifier loss; 0.539211; batch adversarial loss: 0.950469\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.004168; batch classifier loss; 0.505841; batch adversarial loss: 0.939944\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.004013; batch classifier loss; 0.496327; batch adversarial loss: 0.913471\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.004823; batch classifier loss; 0.527257; batch adversarial loss: 0.934327\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.003611; batch classifier loss; 0.557408; batch adversarial loss: 0.909312\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.004761; batch classifier loss; 0.494504; batch adversarial loss: 0.898036\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.004358; batch classifier loss; 0.591339; batch adversarial loss: 0.935153\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.003750; batch classifier loss; 0.533789; batch adversarial loss: 0.904638\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.004685; batch classifier loss; 0.511770; batch adversarial loss: 0.888811\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.004118; batch classifier loss; 0.535662; batch adversarial loss: 0.890478\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.004180; batch classifier loss; 0.575052; batch adversarial loss: 0.928236\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.004402; batch classifier loss; 0.556511; batch adversarial loss: 0.879665\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.004882; batch classifier loss; 0.598246; batch adversarial loss: 0.888248\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.003913; batch classifier loss; 0.509582; batch adversarial loss: 0.844686\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.003554; batch classifier loss; 0.569026; batch adversarial loss: 0.870801\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.004291; batch classifier loss; 0.554737; batch adversarial loss: 0.875396\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.003569; batch classifier loss; 0.538100; batch adversarial loss: 0.852280\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.003846; batch classifier loss; 0.568175; batch adversarial loss: 0.854870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.fairness_adjuster.FairnessAdjuster at 0x7f0549471290>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 23:41:26.432710: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:876 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(\n",
    "    dataset_orig_test,\n",
    "    dataset_nodebiasing_train,\n",
    "    dataset_nodebiasing_test,\n",
    "    dataset_debiasing_train,\n",
    "    dataset_debiasing_test,\n",
    "):\n",
    "    metric_dataset_debiasing_train = BinaryLabelDatasetMetric(\n",
    "        dataset_debiasing_train,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "    )\n",
    "    metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(\n",
    "        dataset_nodebiasing_test,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "    )\n",
    "    classified_metric_nodebiasing_test = ClassificationMetric(\n",
    "        dataset_orig_test,\n",
    "        dataset_nodebiasing_test,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "    )\n",
    "\n",
    "    metric_dataset_debiasing_train = BinaryLabelDatasetMetric(\n",
    "        dataset_debiasing_train,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "    )\n",
    "    metric_dataset_debiasing_test = BinaryLabelDatasetMetric(\n",
    "        dataset_debiasing_test,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "    )\n",
    "    classified_metric_debiasing_test = ClassificationMetric(\n",
    "        dataset_orig_test,\n",
    "        dataset_debiasing_test,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "    )\n",
    "    metrics_dict = {\n",
    "        \"No Debiasing: Train Set: mean outcomes difference\": metric_dataset_nodebiasing_train.mean_difference(),\n",
    "        \"No Debiasing: Test Set: mean outcomes difference\": metric_dataset_nodebiasing_train.mean_difference(),\n",
    "        \"No Debiasing: Test Set: mean outcomes difference\": metric_dataset_nodebiasing_train.mean_difference(),\n",
    "        \"No Debiasing: Test Set: Classification accuracy\": classified_metric_nodebiasing_test.accuracy(),\n",
    "        \"No Debiasing: Test Set: Disparate impact\": classified_metric_nodebiasing_test.disparate_impact(),\n",
    "        \"No Debiasing: Test Set: Average odds difference\": classified_metric_nodebiasing_test.average_odds_difference(),\n",
    "        \"Debiasing: Train Set: mean outcomes difference\": metric_dataset_debiasing_train.mean_difference(),\n",
    "        \"Debiasing: Test Set: mean outcomes difference\": metric_dataset_debiasing_train.mean_difference(),\n",
    "        \"Debiasing: Test Set: mean outcomes difference\": metric_dataset_debiasing_train.mean_difference(),\n",
    "        \"Debiasing: Test Set: Classification accuracy\": classified_metric_debiasing_test.accuracy(),\n",
    "        \"Debiasing: Test Set: Disparate impact\": classified_metric_debiasing_test.disparate_impact(),\n",
    "        \"Debiasing: Test Set: Average odds difference\": classified_metric_debiasing_test.average_odds_difference(),\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.228974\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.361702\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.328671\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.574468\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.713333\n",
      "Test set: Balanced classification accuracy = 0.552439\n",
      "Test set: Disparate impact = 0.638298\n",
      "Test set: Equal opportunity difference = -0.185185\n",
      "Test set: Average odds difference = -0.392593\n",
      "Test set: Theil_index = 0.072837\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.700000\n",
      "Test set: Balanced classification accuracy = 0.551660\n",
      "Test set: Disparate impact = 0.425532\n",
      "Test set: Equal opportunity difference = -0.444444\n",
      "Test set: Average odds difference = -0.597222\n",
      "Test set: Theil_index = 0.096589\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_nodebiasing_train.mean_difference()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_nodebiasing_test.mean_difference()\n",
    ")\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(\n",
    "    dataset_debiasing_train,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_debiasing_train.mean_difference()\n",
    ")\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(\n",
    "    dataset_debiasing_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_debiasing_test.mean_difference()\n",
    ")\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\n",
    "    \"Test set: Classification accuracy = %f\"\n",
    "    % classified_metric_nodebiasing_test.accuracy()\n",
    ")\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5 * (TPR + TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\n",
    "    \"Test set: Disparate impact = %f\"\n",
    "    % classified_metric_nodebiasing_test.disparate_impact()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Equal opportunity difference = %f\"\n",
    "    % classified_metric_nodebiasing_test.equal_opportunity_difference()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Average odds difference = %f\"\n",
    "    % classified_metric_nodebiasing_test.average_odds_difference()\n",
    ")\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(\n",
    "    dataset_orig_test,\n",
    "    dataset_debiasing_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "print(\n",
    "    \"Test set: Classification accuracy = %f\"\n",
    "    % classified_metric_debiasing_test.accuracy()\n",
    ")\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5 * (TPR + TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\n",
    "    \"Test set: Disparate impact = %f\"\n",
    "    % classified_metric_debiasing_test.disparate_impact()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Equal opportunity difference = %f\"\n",
    "    % classified_metric_debiasing_test.equal_opportunity_difference()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Average odds difference = %f\"\n",
    "    % classified_metric_debiasing_test.average_odds_difference()\n",
    ")\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    References:\n",
    "    [1] B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning,\" \n",
    "    AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aif360",
   "language": "python",
   "name": "aif360"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
