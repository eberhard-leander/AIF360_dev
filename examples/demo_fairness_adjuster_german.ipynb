{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of the fairness adjuster, using the same structure as the AIF360 adversarial debiasing example\n",
    "\n",
    "The source notebook can be found here:\n",
    "https://github.com/Trusted-AI/AIF360/blob/main/examples/demo_adversarial_debiasing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 01:37:33.208856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733362653.220348  134095 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733362653.223844  134095 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 01:37:33.235898: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ubuntu/miniconda3/envs/aif360/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/home/ubuntu/miniconda3/envs/aif360/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "from aif360.algorithms.inprocessing.fairness_adjuster import FairnessAdjuster\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import (\n",
    "    load_preproc_data_adult,\n",
    "    load_preproc_data_compas,\n",
    "    load_preproc_data_german,\n",
    ")\n",
    "from aif360.datasets import (\n",
    "    AdultDataset,\n",
    "    BinaryLabelDataset,\n",
    "    CompasDataset,\n",
    "    GermanDataset,\n",
    ")\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AIF360_dev/aif360/algorithms/preprocessing/optim_preproc_helpers/data_preproc_functions.py:261: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sex'] = df['personal_status'].replace(status_map)\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig = load_preproc_data_german([\"age\", \"sex\"])\n",
    "\n",
    "# privileged_groups = [{'sex': 1}]\n",
    "# unprivileged_groups = [{'sex': 0}]\n",
    "privileged_groups = [{\"age\": 1}]\n",
    "unprivileged_groups = [{\"age\": 0}]\n",
    "\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 11)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(\n",
    "    dataset_orig_train.privileged_protected_attributes,\n",
    "    dataset_orig_train.unprivileged_protected_attributes,\n",
    ")\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.156031\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.134953\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_train,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_orig_train.mean_difference()\n",
    ")\n",
    "metric_orig_test = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_orig_test.mean_difference()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.156031\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.134953\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_train,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "display(\n",
    "    Markdown(\n",
    "        \"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_scaled_train.mean_difference()\n",
    ")\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_scaled_test.mean_difference()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn plan classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 01:40:11.702797: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session()\n",
    "plain_model = FairnessAdjuster(\n",
    "    privileged_groups=privileged_groups,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    scope_name=\"plain_classifier\",\n",
    "    debias=False,\n",
    "    sess=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/aif360/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691506\n",
      "epoch 1; iter: 0; batch classifier loss: 0.652496\n",
      "epoch 2; iter: 0; batch classifier loss: 0.599050\n",
      "epoch 3; iter: 0; batch classifier loss: 0.645443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733362819.317209  134095 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.561317\n",
      "epoch 5; iter: 0; batch classifier loss: 0.669750\n",
      "epoch 6; iter: 0; batch classifier loss: 0.556796\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580640\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571397\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574895\n",
      "epoch 10; iter: 0; batch classifier loss: 0.601938\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532943\n",
      "epoch 12; iter: 0; batch classifier loss: 0.546194\n",
      "epoch 13; iter: 0; batch classifier loss: 0.505287\n",
      "epoch 14; iter: 0; batch classifier loss: 0.571458\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539189\n",
      "epoch 16; iter: 0; batch classifier loss: 0.589610\n",
      "epoch 17; iter: 0; batch classifier loss: 0.563824\n",
      "epoch 18; iter: 0; batch classifier loss: 0.550951\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541019\n",
      "epoch 20; iter: 0; batch classifier loss: 0.497706\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486871\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526006\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477855\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454332\n",
      "epoch 25; iter: 0; batch classifier loss: 0.570813\n",
      "epoch 26; iter: 0; batch classifier loss: 0.539694\n",
      "epoch 27; iter: 0; batch classifier loss: 0.544163\n",
      "epoch 28; iter: 0; batch classifier loss: 0.593763\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486961\n",
      "epoch 30; iter: 0; batch classifier loss: 0.527021\n",
      "epoch 31; iter: 0; batch classifier loss: 0.559855\n",
      "epoch 32; iter: 0; batch classifier loss: 0.509224\n",
      "epoch 33; iter: 0; batch classifier loss: 0.486704\n",
      "epoch 34; iter: 0; batch classifier loss: 0.565137\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478331\n",
      "epoch 36; iter: 0; batch classifier loss: 0.528053\n",
      "epoch 37; iter: 0; batch classifier loss: 0.606208\n",
      "epoch 38; iter: 0; batch classifier loss: 0.515937\n",
      "epoch 39; iter: 0; batch classifier loss: 0.563456\n",
      "epoch 40; iter: 0; batch classifier loss: 0.603999\n",
      "epoch 41; iter: 0; batch classifier loss: 0.546518\n",
      "epoch 42; iter: 0; batch classifier loss: 0.500221\n",
      "epoch 43; iter: 0; batch classifier loss: 0.613969\n",
      "epoch 44; iter: 0; batch classifier loss: 0.547461\n",
      "epoch 45; iter: 0; batch classifier loss: 0.573076\n",
      "epoch 46; iter: 0; batch classifier loss: 0.656092\n",
      "epoch 47; iter: 0; batch classifier loss: 0.605857\n",
      "epoch 48; iter: 0; batch classifier loss: 0.557825\n",
      "epoch 49; iter: 0; batch classifier loss: 0.573727\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.046492\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.021477\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.009937\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.012349\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.010776\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.008819\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.007983\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.008214\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.007689\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.007423\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.007609\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.007718\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.006238\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.005973\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.005007\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.005876\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.005073\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.005497\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.004529\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.004895\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.005276\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.003952\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.003915\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.003372\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.003517\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.004102\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.003568\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.004282\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.003532\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.002816\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.002478\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.002140\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.002685\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.002376\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.002548\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.002291\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.002063\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.001885\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.001772\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.002082\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.002154\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.001811\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.002067\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.001894\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.001516\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.001604\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.001295\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.001609\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.001311\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.fairness_adjuster.FairnessAdjuster at 0x7f4abc49fb50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 01:40:37.823144: W tensorflow/c/c_api.cc:305] Operation '{name:'plain_classifier/plain_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node plain_classifier/plain_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](plain_classifier/plain_classifier/classifier_model/b2/Adam_1, plain_classifier/plain_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.286140\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.366803\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.666667\n",
      "Test set: Balanced classification accuracy = 0.531768\n",
      "Test set: Disparate impact = 0.630165\n",
      "Test set: Equal opportunity difference = -0.316628\n",
      "Test set: Average odds difference = -0.371735\n",
      "Test set: Theil_index = 0.095291\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(\n",
    "    dataset_nodebiasing_train,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_nodebiasing_train.mean_difference()\n",
    ")\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(\n",
    "    dataset_nodebiasing_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_nodebiasing_test.mean_difference()\n",
    ")\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(\n",
    "    dataset_orig_test,\n",
    "    dataset_nodebiasing_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "print(\n",
    "    \"Test set: Classification accuracy = %f\"\n",
    "    % classified_metric_nodebiasing_test.accuracy()\n",
    ")\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5 * (TPR + TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\n",
    "    \"Test set: Disparate impact = %f\"\n",
    "    % classified_metric_nodebiasing_test.disparate_impact()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Equal opportunity difference = %f\"\n",
    "    % classified_metric_nodebiasing_test.equal_opportunity_difference()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Average odds difference = %f\"\n",
    "    % classified_metric_nodebiasing_test.average_odds_difference()\n",
    ")\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = FairnessAdjuster(\n",
    "    privileged_groups=privileged_groups,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    scope_name=\"debiased_classifier\",\n",
    "    adversary_loss_weight=0.01,\n",
    "    debias=True,\n",
    "    sess=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.712397\n",
      "epoch 1; iter: 0; batch classifier loss: 0.641707\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609574\n",
      "epoch 3; iter: 0; batch classifier loss: 0.601586\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594361\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597414\n",
      "epoch 6; iter: 0; batch classifier loss: 0.623095\n",
      "epoch 7; iter: 0; batch classifier loss: 0.579439\n",
      "epoch 8; iter: 0; batch classifier loss: 0.544041\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500621\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575007\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536670\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536997\n",
      "epoch 13; iter: 0; batch classifier loss: 0.579212\n",
      "epoch 14; iter: 0; batch classifier loss: 0.488289\n",
      "epoch 15; iter: 0; batch classifier loss: 0.532040\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507235\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559672\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541051\n",
      "epoch 19; iter: 0; batch classifier loss: 0.575580\n",
      "epoch 20; iter: 0; batch classifier loss: 0.563838\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511284\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502921\n",
      "epoch 23; iter: 0; batch classifier loss: 0.564425\n",
      "epoch 24; iter: 0; batch classifier loss: 0.647254\n",
      "epoch 25; iter: 0; batch classifier loss: 0.543822\n",
      "epoch 26; iter: 0; batch classifier loss: 0.540544\n",
      "epoch 27; iter: 0; batch classifier loss: 0.523596\n",
      "epoch 28; iter: 0; batch classifier loss: 0.601303\n",
      "epoch 29; iter: 0; batch classifier loss: 0.566721\n",
      "epoch 30; iter: 0; batch classifier loss: 0.564135\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523187\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525834\n",
      "epoch 33; iter: 0; batch classifier loss: 0.507049\n",
      "epoch 34; iter: 0; batch classifier loss: 0.585082\n",
      "epoch 35; iter: 0; batch classifier loss: 0.539762\n",
      "epoch 36; iter: 0; batch classifier loss: 0.540725\n",
      "epoch 37; iter: 0; batch classifier loss: 0.491101\n",
      "epoch 38; iter: 0; batch classifier loss: 0.584658\n",
      "epoch 39; iter: 0; batch classifier loss: 0.530714\n",
      "epoch 40; iter: 0; batch classifier loss: 0.508647\n",
      "epoch 41; iter: 0; batch classifier loss: 0.497274\n",
      "epoch 42; iter: 0; batch classifier loss: 0.555778\n",
      "epoch 43; iter: 0; batch classifier loss: 0.517655\n",
      "epoch 44; iter: 0; batch classifier loss: 0.597519\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470536\n",
      "epoch 46; iter: 0; batch classifier loss: 0.552891\n",
      "epoch 47; iter: 0; batch classifier loss: 0.491745\n",
      "epoch 48; iter: 0; batch classifier loss: 0.563898\n",
      "epoch 49; iter: 0; batch classifier loss: 0.535659\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.025821; batch classifier loss; 0.538257; batch adversarial loss: 0.556986\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.017118; batch classifier loss; 0.514819; batch adversarial loss: 0.485077\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.016217; batch classifier loss; 0.439724; batch adversarial loss: 0.464723\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.010461; batch classifier loss; 0.543617; batch adversarial loss: 0.493700\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.012905; batch classifier loss; 0.591459; batch adversarial loss: 0.465674\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.011107; batch classifier loss; 0.527867; batch adversarial loss: 0.479809\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.010885; batch classifier loss; 0.504012; batch adversarial loss: 0.489643\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.007369; batch classifier loss; 0.505315; batch adversarial loss: 0.490165\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.007710; batch classifier loss; 0.542661; batch adversarial loss: 0.497891\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.006037; batch classifier loss; 0.453845; batch adversarial loss: 0.455641\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.007275; batch classifier loss; 0.570116; batch adversarial loss: 0.459404\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.008228; batch classifier loss; 0.542217; batch adversarial loss: 0.484610\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.005133; batch classifier loss; 0.564567; batch adversarial loss: 0.508333\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.005722; batch classifier loss; 0.586241; batch adversarial loss: 0.461862\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.006215; batch classifier loss; 0.523069; batch adversarial loss: 0.479923\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.006806; batch classifier loss; 0.454134; batch adversarial loss: 0.442700\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.004663; batch classifier loss; 0.516432; batch adversarial loss: 0.431994\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.004971; batch classifier loss; 0.552083; batch adversarial loss: 0.518823\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.003787; batch classifier loss; 0.571355; batch adversarial loss: 0.474542\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.004448; batch classifier loss; 0.563274; batch adversarial loss: 0.511113\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.004734; batch classifier loss; 0.525807; batch adversarial loss: 0.484592\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.003870; batch classifier loss; 0.518488; batch adversarial loss: 0.487096\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.003446; batch classifier loss; 0.576948; batch adversarial loss: 0.498245\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.004808; batch classifier loss; 0.551140; batch adversarial loss: 0.458145\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.003911; batch classifier loss; 0.486311; batch adversarial loss: 0.479856\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.003627; batch classifier loss; 0.523329; batch adversarial loss: 0.466056\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.003605; batch classifier loss; 0.516939; batch adversarial loss: 0.497866\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.004027; batch classifier loss; 0.525833; batch adversarial loss: 0.457676\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.003380; batch classifier loss; 0.465927; batch adversarial loss: 0.510048\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.002679; batch classifier loss; 0.566263; batch adversarial loss: 0.407286\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.003377; batch classifier loss; 0.542246; batch adversarial loss: 0.500718\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.003545; batch classifier loss; 0.444200; batch adversarial loss: 0.466465\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.003923; batch classifier loss; 0.493935; batch adversarial loss: 0.472682\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.004223; batch classifier loss; 0.508134; batch adversarial loss: 0.467301\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.003862; batch classifier loss; 0.538841; batch adversarial loss: 0.487459\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.003414; batch classifier loss; 0.449655; batch adversarial loss: 0.502699\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.005386; batch classifier loss; 0.543586; batch adversarial loss: 0.510531\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.003450; batch classifier loss; 0.524035; batch adversarial loss: 0.504926\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.003697; batch classifier loss; 0.560925; batch adversarial loss: 0.436087\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.004265; batch classifier loss; 0.488249; batch adversarial loss: 0.410317\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.004332; batch classifier loss; 0.508711; batch adversarial loss: 0.499046\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.004753; batch classifier loss; 0.513703; batch adversarial loss: 0.452103\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.004775; batch classifier loss; 0.516084; batch adversarial loss: 0.477608\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.005710; batch classifier loss; 0.586917; batch adversarial loss: 0.562903\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.004448; batch classifier loss; 0.523014; batch adversarial loss: 0.442847\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.004975; batch classifier loss; 0.609752; batch adversarial loss: 0.486008\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.005170; batch classifier loss; 0.531151; batch adversarial loss: 0.506483\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.005135; batch classifier loss; 0.524690; batch adversarial loss: 0.528666\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.004869; batch classifier loss; 0.589814; batch adversarial loss: 0.447270\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.007137; batch classifier loss; 0.499292; batch adversarial loss: 0.536871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.fairness_adjuster.FairnessAdjuster at 0x7f4ab83a0050>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 01:41:06.481032: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.286140\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.366803\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.263752\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.223946\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.666667\n",
      "Test set: Balanced classification accuracy = 0.531768\n",
      "Test set: Disparate impact = 0.630165\n",
      "Test set: Equal opportunity difference = -0.316628\n",
      "Test set: Average odds difference = -0.371735\n",
      "Test set: Theil_index = 0.095291\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.686667\n",
      "Test set: Balanced classification accuracy = 0.544405\n",
      "Test set: Disparate impact = 0.774203\n",
      "Test set: Equal opportunity difference = -0.090822\n",
      "Test set: Average odds difference = -0.238832\n",
      "Test set: Theil_index = 0.071174\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_nodebiasing_train.mean_difference()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_nodebiasing_test.mean_difference()\n",
    ")\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(\n",
    "    dataset_debiasing_train,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_debiasing_train.mean_difference()\n",
    ")\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(\n",
    "    dataset_debiasing_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "    % metric_dataset_debiasing_test.mean_difference()\n",
    ")\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\n",
    "    \"Test set: Classification accuracy = %f\"\n",
    "    % classified_metric_nodebiasing_test.accuracy()\n",
    ")\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5 * (TPR + TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\n",
    "    \"Test set: Disparate impact = %f\"\n",
    "    % classified_metric_nodebiasing_test.disparate_impact()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Equal opportunity difference = %f\"\n",
    "    % classified_metric_nodebiasing_test.equal_opportunity_difference()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Average odds difference = %f\"\n",
    "    % classified_metric_nodebiasing_test.average_odds_difference()\n",
    ")\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(\n",
    "    dataset_orig_test,\n",
    "    dataset_debiasing_test,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "print(\n",
    "    \"Test set: Classification accuracy = %f\"\n",
    "    % classified_metric_debiasing_test.accuracy()\n",
    ")\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5 * (TPR + TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\n",
    "    \"Test set: Disparate impact = %f\"\n",
    "    % classified_metric_debiasing_test.disparate_impact()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Equal opportunity difference = %f\"\n",
    "    % classified_metric_debiasing_test.equal_opportunity_difference()\n",
    ")\n",
    "print(\n",
    "    \"Test set: Average odds difference = %f\"\n",
    "    % classified_metric_debiasing_test.average_odds_difference()\n",
    ")\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    References:\n",
    "    [1] B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning,\" \n",
    "    AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aif360",
   "language": "python",
   "name": "aif360"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
