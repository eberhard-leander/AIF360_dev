{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77f78f1-bbf9-4aa2-8ec6-770e81cff82c",
   "metadata": {},
   "source": [
    "# CV Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779c3e6c-a01b-4980-955f-13df60267837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:12.632359: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733534532.644101  130415 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733534532.647628  130415 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-07 01:22:12.660313: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ubuntu/miniconda3/envs/aif360/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/home/ubuntu/miniconda3/envs/aif360/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "from aif360.algorithms.inprocessing.fairness_adjuster import FairnessAdjuster\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import (\n",
    "    load_preproc_data_adult,\n",
    "    load_preproc_data_compas,\n",
    "    load_preproc_data_german,\n",
    ")\n",
    "from aif360.datasets import (\n",
    "    AdultDataset,\n",
    "    BinaryLabelDataset,\n",
    "    CompasDataset,\n",
    "    GermanDataset,\n",
    ")\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faaf39f4-c97f-41d0-8fbc-bc77ea549c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AIF360_dev/aif360/algorithms/preprocessing/optim_preproc_helpers/data_preproc_functions.py:261: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sex'] = df['personal_status'].replace(status_map)\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = load_preproc_data_german([\"age\", \"sex\"])\n",
    "privileged_groups = [{\"age\": 1}]\n",
    "unprivileged_groups = [{\"age\": 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23007a55-be71-44bc-9fd2-f78ce2bd3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "\n",
    "min_max_scaler = MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e72b206-70b0-4189-97a2-c255e21f7614",
   "metadata": {},
   "source": [
    "Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a49cb98-4106-4c39-828f-88ddecec6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig.features = min_max_scaler.fit_transform(dataset_orig.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29974c55-e8af-45e6-a41f-e71184477f62",
   "metadata": {},
   "source": [
    "CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "166e2407-f436-49aa-819d-0cc61542cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score  # Replace with desired metric\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def cross_validate_seeds(\n",
    "    dataset, privileged_group, unprivileged_groups, seeds=5, n_folds=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs cross-validation with multiple seeds.\n",
    "\n",
    "    Parameters:\n",
    "        model: The Scikit-learn model to validate.\n",
    "        X: Feature matrix.\n",
    "        y: Target vector.\n",
    "        seeds: Number of seeds for cross-validation.\n",
    "        folds: Number of folds for each cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        results: Dictionary containing accuracy scores for each seed and fold.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    original_df = dataset.convert_to_dataframe()[0]\n",
    "    for seed in range(seeds):\n",
    "        print(f\"\\nSeed {seed + 1}/{seeds}\")\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "        fold_results = []\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(kf.split(original_df)):\n",
    "            print(f\"{seed=} || {fold=}\")\n",
    "            # Splitting data\n",
    "            dataset_X_train, dataset_X_test = dataset.subset(train_idx), dataset.subset(\n",
    "                test_idx\n",
    "            )\n",
    "\n",
    "            # Training model\n",
    "            sess = tf.Session()\n",
    "            model = FairnessAdjuster(\n",
    "                privileged_groups=privileged_groups,\n",
    "                unprivileged_groups=unprivileged_groups,\n",
    "                scope_name=\"debiased_classifier\",\n",
    "                adversary_loss_weight=0.01,\n",
    "                debias=True,\n",
    "                sess=sess,\n",
    "                classifier_num_hidden_units=100,\n",
    "            )\n",
    "            model.fit(dataset_X_train)\n",
    "\n",
    "            # Making predictions\n",
    "            dataset_preds = model.predict(dataset_X_test)\n",
    "\n",
    "            # Evaluating model\n",
    "            metrics = get_metrics(\n",
    "                dataset_X_test,\n",
    "                dataset_preds,\n",
    "                unprivileged_groups,\n",
    "                privileged_groups,\n",
    "            )\n",
    "            fold_results.append(metrics)\n",
    "\n",
    "            # end session\n",
    "            sess.close()\n",
    "            tf.reset_default_graph()\n",
    "        results[f\"Seed {seed}\"] = fold_results\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45f5854-17ad-4b22-9408-40ec54907c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(\n",
    "    dataset_orig_test, dataset_pred_test, unprivileged_groups, privileged_groups\n",
    "):\n",
    "    metric_dataset_debiasing_test = BinaryLabelDatasetMetric(\n",
    "        dataset_orig_test,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "    )\n",
    "    classified_metric_debiasing_test = ClassificationMetric(\n",
    "        dataset_orig_test,\n",
    "        dataset_pred_test,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "    )\n",
    "    metrics_dict = {\n",
    "        \"Test Set: mean outcomes difference\": metric_dataset_debiasing_test.mean_difference(),\n",
    "        \"Test Set: Classification accuracy\": classified_metric_debiasing_test.accuracy(),\n",
    "        \"Test Set: Disparate impact\": classified_metric_debiasing_test.disparate_impact(),\n",
    "        \"Test Set: Average odds difference\": classified_metric_debiasing_test.average_odds_difference(),\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cddf7c8f-1cbd-48f5-90bb-77fe8eb235d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed 1/5\n",
      "seed=0 || fold=0\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/aif360/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:16.855697: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733534536.965279  130415 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.820269\n",
      "epoch 1; iter: 0; batch classifier loss: 0.780574\n",
      "epoch 2; iter: 0; batch classifier loss: 0.684352\n",
      "epoch 3; iter: 0; batch classifier loss: 0.642363\n",
      "epoch 4; iter: 0; batch classifier loss: 0.665911\n",
      "epoch 5; iter: 0; batch classifier loss: 0.666919\n",
      "epoch 6; iter: 0; batch classifier loss: 0.631005\n",
      "epoch 7; iter: 0; batch classifier loss: 0.654215\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533161\n",
      "epoch 9; iter: 0; batch classifier loss: 0.609605\n",
      "epoch 10; iter: 0; batch classifier loss: 0.562595\n",
      "epoch 11; iter: 0; batch classifier loss: 0.589132\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578125\n",
      "epoch 13; iter: 0; batch classifier loss: 0.600686\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543627\n",
      "epoch 15; iter: 0; batch classifier loss: 0.581816\n",
      "epoch 16; iter: 0; batch classifier loss: 0.589964\n",
      "epoch 17; iter: 0; batch classifier loss: 0.561705\n",
      "epoch 18; iter: 0; batch classifier loss: 0.607794\n",
      "epoch 19; iter: 0; batch classifier loss: 0.563456\n",
      "epoch 20; iter: 0; batch classifier loss: 0.613927\n",
      "epoch 21; iter: 0; batch classifier loss: 0.590102\n",
      "epoch 22; iter: 0; batch classifier loss: 0.549482\n",
      "epoch 23; iter: 0; batch classifier loss: 0.572880\n",
      "epoch 24; iter: 0; batch classifier loss: 0.579436\n",
      "epoch 25; iter: 0; batch classifier loss: 0.616206\n",
      "epoch 26; iter: 0; batch classifier loss: 0.588704\n",
      "epoch 27; iter: 0; batch classifier loss: 0.512440\n",
      "epoch 28; iter: 0; batch classifier loss: 0.570140\n",
      "epoch 29; iter: 0; batch classifier loss: 0.574863\n",
      "epoch 30; iter: 0; batch classifier loss: 0.568480\n",
      "epoch 31; iter: 0; batch classifier loss: 0.596253\n",
      "epoch 32; iter: 0; batch classifier loss: 0.579372\n",
      "epoch 33; iter: 0; batch classifier loss: 0.590830\n",
      "epoch 34; iter: 0; batch classifier loss: 0.566901\n",
      "epoch 35; iter: 0; batch classifier loss: 0.522674\n",
      "epoch 36; iter: 0; batch classifier loss: 0.515657\n",
      "epoch 37; iter: 0; batch classifier loss: 0.575135\n",
      "epoch 38; iter: 0; batch classifier loss: 0.591815\n",
      "epoch 39; iter: 0; batch classifier loss: 0.599581\n",
      "epoch 40; iter: 0; batch classifier loss: 0.544923\n",
      "epoch 41; iter: 0; batch classifier loss: 0.528034\n",
      "epoch 42; iter: 0; batch classifier loss: 0.565620\n",
      "epoch 43; iter: 0; batch classifier loss: 0.628444\n",
      "epoch 44; iter: 0; batch classifier loss: 0.567616\n",
      "epoch 45; iter: 0; batch classifier loss: 0.526894\n",
      "epoch 46; iter: 0; batch classifier loss: 0.606571\n",
      "epoch 47; iter: 0; batch classifier loss: 0.543199\n",
      "epoch 48; iter: 0; batch classifier loss: 0.649901\n",
      "epoch 49; iter: 0; batch classifier loss: 0.643698\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.063070; batch classifier loss; 0.601820; batch adversarial loss: 0.464024\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.048213; batch classifier loss; 0.535580; batch adversarial loss: 0.514031\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.045467; batch classifier loss; 0.539112; batch adversarial loss: 0.501176\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.034995; batch classifier loss; 0.586763; batch adversarial loss: 0.424363\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.033463; batch classifier loss; 0.591100; batch adversarial loss: 0.461198\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.027000; batch classifier loss; 0.521624; batch adversarial loss: 0.461257\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.021206; batch classifier loss; 0.526783; batch adversarial loss: 0.540527\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.021747; batch classifier loss; 0.531517; batch adversarial loss: 0.466871\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.017184; batch classifier loss; 0.599364; batch adversarial loss: 0.399086\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.026357; batch classifier loss; 0.620892; batch adversarial loss: 0.593192\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.023033; batch classifier loss; 0.581141; batch adversarial loss: 0.536319\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.019461; batch classifier loss; 0.595872; batch adversarial loss: 0.582433\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.018944; batch classifier loss; 0.571429; batch adversarial loss: 0.433140\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.018765; batch classifier loss; 0.610055; batch adversarial loss: 0.508777\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.014378; batch classifier loss; 0.519923; batch adversarial loss: 0.493428\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.015955; batch classifier loss; 0.568687; batch adversarial loss: 0.490442\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.015261; batch classifier loss; 0.592144; batch adversarial loss: 0.481398\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.015016; batch classifier loss; 0.570605; batch adversarial loss: 0.474076\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.013647; batch classifier loss; 0.528958; batch adversarial loss: 0.468853\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.013004; batch classifier loss; 0.589691; batch adversarial loss: 0.496472\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.013551; batch classifier loss; 0.545659; batch adversarial loss: 0.504247\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.011252; batch classifier loss; 0.516539; batch adversarial loss: 0.465895\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.013859; batch classifier loss; 0.570988; batch adversarial loss: 0.536180\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.014203; batch classifier loss; 0.561952; batch adversarial loss: 0.547281\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.010680; batch classifier loss; 0.539626; batch adversarial loss: 0.476557\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.010563; batch classifier loss; 0.536762; batch adversarial loss: 0.502471\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.010090; batch classifier loss; 0.558343; batch adversarial loss: 0.479002\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.010056; batch classifier loss; 0.569428; batch adversarial loss: 0.446766\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.013779; batch classifier loss; 0.531806; batch adversarial loss: 0.518239\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.011120; batch classifier loss; 0.599551; batch adversarial loss: 0.415726\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.011141; batch classifier loss; 0.547257; batch adversarial loss: 0.445133\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.008351; batch classifier loss; 0.619593; batch adversarial loss: 0.470391\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.009677; batch classifier loss; 0.603865; batch adversarial loss: 0.422633\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.011015; batch classifier loss; 0.539871; batch adversarial loss: 0.464310\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.009192; batch classifier loss; 0.576990; batch adversarial loss: 0.476182\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.010219; batch classifier loss; 0.565579; batch adversarial loss: 0.503986\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.012940; batch classifier loss; 0.599793; batch adversarial loss: 0.580522\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.009160; batch classifier loss; 0.547089; batch adversarial loss: 0.430822\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.011155; batch classifier loss; 0.565005; batch adversarial loss: 0.516785\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.008835; batch classifier loss; 0.512183; batch adversarial loss: 0.404739\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.013047; batch classifier loss; 0.567423; batch adversarial loss: 0.481424\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.011668; batch classifier loss; 0.562209; batch adversarial loss: 0.535258\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.010658; batch classifier loss; 0.574547; batch adversarial loss: 0.460799\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.010546; batch classifier loss; 0.553199; batch adversarial loss: 0.449197\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.008273; batch classifier loss; 0.521837; batch adversarial loss: 0.484264\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.012018; batch classifier loss; 0.546378; batch adversarial loss: 0.534808\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.009482; batch classifier loss; 0.577542; batch adversarial loss: 0.436013\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.010131; batch classifier loss; 0.651079; batch adversarial loss: 0.434819\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.009117; batch classifier loss; 0.500993; batch adversarial loss: 0.446499\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.009480; batch classifier loss; 0.566208; batch adversarial loss: 0.418888\n",
      "seed=0 || fold=1\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673023\n",
      "epoch 1; iter: 0; batch classifier loss: 0.626759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:18.179158: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.646547\n",
      "epoch 3; iter: 0; batch classifier loss: 0.637121\n",
      "epoch 4; iter: 0; batch classifier loss: 0.643286\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593559\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575874\n",
      "epoch 7; iter: 0; batch classifier loss: 0.647824\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522139\n",
      "epoch 9; iter: 0; batch classifier loss: 0.590948\n",
      "epoch 10; iter: 0; batch classifier loss: 0.628074\n",
      "epoch 11; iter: 0; batch classifier loss: 0.572241\n",
      "epoch 12; iter: 0; batch classifier loss: 0.593793\n",
      "epoch 13; iter: 0; batch classifier loss: 0.601677\n",
      "epoch 14; iter: 0; batch classifier loss: 0.587601\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497918\n",
      "epoch 16; iter: 0; batch classifier loss: 0.577022\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534119\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530621\n",
      "epoch 19; iter: 0; batch classifier loss: 0.540438\n",
      "epoch 20; iter: 0; batch classifier loss: 0.570042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.566744\n",
      "epoch 22; iter: 0; batch classifier loss: 0.583380\n",
      "epoch 23; iter: 0; batch classifier loss: 0.620064\n",
      "epoch 24; iter: 0; batch classifier loss: 0.627791\n",
      "epoch 25; iter: 0; batch classifier loss: 0.481008\n",
      "epoch 26; iter: 0; batch classifier loss: 0.529506\n",
      "epoch 27; iter: 0; batch classifier loss: 0.578490\n",
      "epoch 28; iter: 0; batch classifier loss: 0.551369\n",
      "epoch 29; iter: 0; batch classifier loss: 0.504606\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550226\n",
      "epoch 31; iter: 0; batch classifier loss: 0.567481\n",
      "epoch 32; iter: 0; batch classifier loss: 0.555926\n",
      "epoch 33; iter: 0; batch classifier loss: 0.511212\n",
      "epoch 34; iter: 0; batch classifier loss: 0.547258\n",
      "epoch 35; iter: 0; batch classifier loss: 0.581438\n",
      "epoch 36; iter: 0; batch classifier loss: 0.610197\n",
      "epoch 37; iter: 0; batch classifier loss: 0.576977\n",
      "epoch 38; iter: 0; batch classifier loss: 0.574466\n",
      "epoch 39; iter: 0; batch classifier loss: 0.505255\n",
      "epoch 40; iter: 0; batch classifier loss: 0.560681\n",
      "epoch 41; iter: 0; batch classifier loss: 0.563943\n",
      "epoch 42; iter: 0; batch classifier loss: 0.553946\n",
      "epoch 43; iter: 0; batch classifier loss: 0.600508\n",
      "epoch 44; iter: 0; batch classifier loss: 0.526699\n",
      "epoch 45; iter: 0; batch classifier loss: 0.550074\n",
      "epoch 46; iter: 0; batch classifier loss: 0.551453\n",
      "epoch 47; iter: 0; batch classifier loss: 0.522284\n",
      "epoch 48; iter: 0; batch classifier loss: 0.564031\n",
      "epoch 49; iter: 0; batch classifier loss: 0.566678\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.046859; batch classifier loss; 0.544067; batch adversarial loss: 0.816509\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.036485; batch classifier loss; 0.507554; batch adversarial loss: 0.814920\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.024027; batch classifier loss; 0.501103; batch adversarial loss: 0.811194\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.026673; batch classifier loss; 0.569947; batch adversarial loss: 0.795509\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.019171; batch classifier loss; 0.563664; batch adversarial loss: 0.819088\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.021439; batch classifier loss; 0.546700; batch adversarial loss: 0.781872\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.014966; batch classifier loss; 0.591150; batch adversarial loss: 0.806036\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.010437; batch classifier loss; 0.521919; batch adversarial loss: 0.780284\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.011310; batch classifier loss; 0.529646; batch adversarial loss: 0.793248\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.008549; batch classifier loss; 0.489831; batch adversarial loss: 0.768352\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.007757; batch classifier loss; 0.571174; batch adversarial loss: 0.790897\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.007457; batch classifier loss; 0.599905; batch adversarial loss: 0.772155\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.006275; batch classifier loss; 0.574797; batch adversarial loss: 0.771565\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.006162; batch classifier loss; 0.508150; batch adversarial loss: 0.758305\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.004353; batch classifier loss; 0.611671; batch adversarial loss: 0.774627\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.003982; batch classifier loss; 0.502010; batch adversarial loss: 0.731663\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.002568; batch classifier loss; 0.558174; batch adversarial loss: 0.771014\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.003098; batch classifier loss; 0.504027; batch adversarial loss: 0.711153\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.002879; batch classifier loss; 0.559939; batch adversarial loss: 0.747689\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.002703; batch classifier loss; 0.534049; batch adversarial loss: 0.737638\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.002824; batch classifier loss; 0.501247; batch adversarial loss: 0.712320\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.002399; batch classifier loss; 0.538384; batch adversarial loss: 0.716205\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.002329; batch classifier loss; 0.577725; batch adversarial loss: 0.729695\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.002200; batch classifier loss; 0.571069; batch adversarial loss: 0.706946\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.002265; batch classifier loss; 0.581836; batch adversarial loss: 0.715871\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.002003; batch classifier loss; 0.546953; batch adversarial loss: 0.697884\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.001702; batch classifier loss; 0.621288; batch adversarial loss: 0.722992\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.001696; batch classifier loss; 0.549407; batch adversarial loss: 0.682504\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.001476; batch classifier loss; 0.582736; batch adversarial loss: 0.697077\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.001292; batch classifier loss; 0.561095; batch adversarial loss: 0.682657\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.001615; batch classifier loss; 0.562171; batch adversarial loss: 0.678879\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.001667; batch classifier loss; 0.609935; batch adversarial loss: 0.691558\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.001380; batch classifier loss; 0.536417; batch adversarial loss: 0.656730\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.001698; batch classifier loss; 0.525165; batch adversarial loss: 0.661711\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.001236; batch classifier loss; 0.528189; batch adversarial loss: 0.655649\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.001025; batch classifier loss; 0.527472; batch adversarial loss: 0.637979\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.001484; batch classifier loss; 0.610799; batch adversarial loss: 0.668902\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.001173; batch classifier loss; 0.559231; batch adversarial loss: 0.663880\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.000969; batch classifier loss; 0.591069; batch adversarial loss: 0.656778\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.001262; batch classifier loss; 0.548272; batch adversarial loss: 0.649573\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.001014; batch classifier loss; 0.575508; batch adversarial loss: 0.652925\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.001404; batch classifier loss; 0.540322; batch adversarial loss: 0.637084\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.000886; batch classifier loss; 0.543822; batch adversarial loss: 0.647553\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.000936; batch classifier loss; 0.602003; batch adversarial loss: 0.646757\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.001177; batch classifier loss; 0.535227; batch adversarial loss: 0.634120\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.000944; batch classifier loss; 0.566191; batch adversarial loss: 0.636787\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.001193; batch classifier loss; 0.584642; batch adversarial loss: 0.624980\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.000985; batch classifier loss; 0.471632; batch adversarial loss: 0.583614\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.001268; batch classifier loss; 0.592525; batch adversarial loss: 0.599223\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.000821; batch classifier loss; 0.574075; batch adversarial loss: 0.620675\n",
      "seed=0 || fold=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:19.556794: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.674586\n",
      "epoch 1; iter: 0; batch classifier loss: 0.636804\n",
      "epoch 2; iter: 0; batch classifier loss: 0.597949\n",
      "epoch 3; iter: 0; batch classifier loss: 0.634998\n",
      "epoch 4; iter: 0; batch classifier loss: 0.644915\n",
      "epoch 5; iter: 0; batch classifier loss: 0.599536\n",
      "epoch 6; iter: 0; batch classifier loss: 0.560876\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592765\n",
      "epoch 8; iter: 0; batch classifier loss: 0.625662\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539251\n",
      "epoch 10; iter: 0; batch classifier loss: 0.580755\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552340\n",
      "epoch 12; iter: 0; batch classifier loss: 0.603151\n",
      "epoch 13; iter: 0; batch classifier loss: 0.565497\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560776\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527930\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561400\n",
      "epoch 17; iter: 0; batch classifier loss: 0.592522\n",
      "epoch 18; iter: 0; batch classifier loss: 0.573235\n",
      "epoch 19; iter: 0; batch classifier loss: 0.637074\n",
      "epoch 20; iter: 0; batch classifier loss: 0.577961\n",
      "epoch 21; iter: 0; batch classifier loss: 0.568805\n",
      "epoch 22; iter: 0; batch classifier loss: 0.560840\n",
      "epoch 23; iter: 0; batch classifier loss: 0.588822\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501894\n",
      "epoch 25; iter: 0; batch classifier loss: 0.581761\n",
      "epoch 26; iter: 0; batch classifier loss: 0.570663\n",
      "epoch 27; iter: 0; batch classifier loss: 0.541770\n",
      "epoch 28; iter: 0; batch classifier loss: 0.573477\n",
      "epoch 29; iter: 0; batch classifier loss: 0.548501\n",
      "epoch 30; iter: 0; batch classifier loss: 0.587918\n",
      "epoch 31; iter: 0; batch classifier loss: 0.594714\n",
      "epoch 32; iter: 0; batch classifier loss: 0.596816\n",
      "epoch 33; iter: 0; batch classifier loss: 0.531404\n",
      "epoch 34; iter: 0; batch classifier loss: 0.522962\n",
      "epoch 35; iter: 0; batch classifier loss: 0.570458\n",
      "epoch 36; iter: 0; batch classifier loss: 0.511757\n",
      "epoch 37; iter: 0; batch classifier loss: 0.525036\n",
      "epoch 38; iter: 0; batch classifier loss: 0.547646\n",
      "epoch 39; iter: 0; batch classifier loss: 0.595304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.565803\n",
      "epoch 41; iter: 0; batch classifier loss: 0.608436\n",
      "epoch 42; iter: 0; batch classifier loss: 0.569380\n",
      "epoch 43; iter: 0; batch classifier loss: 0.629143\n",
      "epoch 44; iter: 0; batch classifier loss: 0.570183\n",
      "epoch 45; iter: 0; batch classifier loss: 0.576539\n",
      "epoch 46; iter: 0; batch classifier loss: 0.567910\n",
      "epoch 47; iter: 0; batch classifier loss: 0.511466\n",
      "epoch 48; iter: 0; batch classifier loss: 0.618286\n",
      "epoch 49; iter: 0; batch classifier loss: 0.581863\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.087156; batch classifier loss; 0.539835; batch adversarial loss: 0.709345\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.037994; batch classifier loss; 0.494829; batch adversarial loss: 0.683388\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.036536; batch classifier loss; 0.515719; batch adversarial loss: 0.672127\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.026336; batch classifier loss; 0.566049; batch adversarial loss: 0.698295\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.022530; batch classifier loss; 0.536806; batch adversarial loss: 0.692357\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.015735; batch classifier loss; 0.445338; batch adversarial loss: 0.652482\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.013529; batch classifier loss; 0.588222; batch adversarial loss: 0.676389\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.014635; batch classifier loss; 0.568316; batch adversarial loss: 0.668627\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.012678; batch classifier loss; 0.558201; batch adversarial loss: 0.673325\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.008766; batch classifier loss; 0.573050; batch adversarial loss: 0.653566\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.010616; batch classifier loss; 0.551726; batch adversarial loss: 0.674886\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.007638; batch classifier loss; 0.556367; batch adversarial loss: 0.649083\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.008864; batch classifier loss; 0.582304; batch adversarial loss: 0.663358\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.008493; batch classifier loss; 0.504923; batch adversarial loss: 0.626249\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.007606; batch classifier loss; 0.559677; batch adversarial loss: 0.622535\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.006834; batch classifier loss; 0.611304; batch adversarial loss: 0.643722\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.008445; batch classifier loss; 0.567211; batch adversarial loss: 0.628920\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.005987; batch classifier loss; 0.520278; batch adversarial loss: 0.610082\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.007447; batch classifier loss; 0.598585; batch adversarial loss: 0.635755\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.004249; batch classifier loss; 0.618795; batch adversarial loss: 0.636199\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.004179; batch classifier loss; 0.523027; batch adversarial loss: 0.618069\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.003524; batch classifier loss; 0.572171; batch adversarial loss: 0.608994\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.004804; batch classifier loss; 0.572921; batch adversarial loss: 0.622860\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.004181; batch classifier loss; 0.544948; batch adversarial loss: 0.595663\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.004029; batch classifier loss; 0.535237; batch adversarial loss: 0.593473\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.003467; batch classifier loss; 0.576437; batch adversarial loss: 0.588873\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.003353; batch classifier loss; 0.506399; batch adversarial loss: 0.558847\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.002507; batch classifier loss; 0.609667; batch adversarial loss: 0.611414\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.002513; batch classifier loss; 0.585841; batch adversarial loss: 0.591412\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.003264; batch classifier loss; 0.591553; batch adversarial loss: 0.576302\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.002813; batch classifier loss; 0.530500; batch adversarial loss: 0.568184\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.002905; batch classifier loss; 0.643815; batch adversarial loss: 0.610641\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.002419; batch classifier loss; 0.514412; batch adversarial loss: 0.548516\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.002130; batch classifier loss; 0.565046; batch adversarial loss: 0.572988\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.002637; batch classifier loss; 0.623248; batch adversarial loss: 0.593198\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.002649; batch classifier loss; 0.575024; batch adversarial loss: 0.575526\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.001476; batch classifier loss; 0.511455; batch adversarial loss: 0.549480\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.001527; batch classifier loss; 0.603044; batch adversarial loss: 0.559823\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.002196; batch classifier loss; 0.561058; batch adversarial loss: 0.545659\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.001792; batch classifier loss; 0.582977; batch adversarial loss: 0.567474\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.001652; batch classifier loss; 0.651846; batch adversarial loss: 0.606728\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.001623; batch classifier loss; 0.497761; batch adversarial loss: 0.548858\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.001719; batch classifier loss; 0.500025; batch adversarial loss: 0.536669\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.001557; batch classifier loss; 0.579793; batch adversarial loss: 0.519241\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.001558; batch classifier loss; 0.600788; batch adversarial loss: 0.535567\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.001334; batch classifier loss; 0.574281; batch adversarial loss: 0.552971\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.001577; batch classifier loss; 0.589245; batch adversarial loss: 0.545220\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.002092; batch classifier loss; 0.555205; batch adversarial loss: 0.570874\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.001498; batch classifier loss; 0.522827; batch adversarial loss: 0.513821\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001224; batch classifier loss; 0.606396; batch adversarial loss: 0.527005\n",
      "seed=0 || fold=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:20.959922: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.712254\n",
      "epoch 1; iter: 0; batch classifier loss: 0.646128\n",
      "epoch 2; iter: 0; batch classifier loss: 0.615896\n",
      "epoch 3; iter: 0; batch classifier loss: 0.647627\n",
      "epoch 4; iter: 0; batch classifier loss: 0.561986\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545906\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578263\n",
      "epoch 8; iter: 0; batch classifier loss: 0.580514\n",
      "epoch 9; iter: 0; batch classifier loss: 0.588680\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513912\n",
      "epoch 11; iter: 0; batch classifier loss: 0.638302\n",
      "epoch 12; iter: 0; batch classifier loss: 0.647840\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575592\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.594003\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545190\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523015\n",
      "epoch 18; iter: 0; batch classifier loss: 0.603306\n",
      "epoch 19; iter: 0; batch classifier loss: 0.567904\n",
      "epoch 20; iter: 0; batch classifier loss: 0.557826\n",
      "epoch 21; iter: 0; batch classifier loss: 0.593399\n",
      "epoch 22; iter: 0; batch classifier loss: 0.595960\n",
      "epoch 23; iter: 0; batch classifier loss: 0.585473\n",
      "epoch 24; iter: 0; batch classifier loss: 0.545244\n",
      "epoch 25; iter: 0; batch classifier loss: 0.643420\n",
      "epoch 26; iter: 0; batch classifier loss: 0.629067\n",
      "epoch 27; iter: 0; batch classifier loss: 0.563530\n",
      "epoch 28; iter: 0; batch classifier loss: 0.631628\n",
      "epoch 29; iter: 0; batch classifier loss: 0.570202\n",
      "epoch 30; iter: 0; batch classifier loss: 0.533380\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515300\n",
      "epoch 32; iter: 0; batch classifier loss: 0.604929\n",
      "epoch 33; iter: 0; batch classifier loss: 0.568446\n",
      "epoch 34; iter: 0; batch classifier loss: 0.550913\n",
      "epoch 35; iter: 0; batch classifier loss: 0.559722\n",
      "epoch 36; iter: 0; batch classifier loss: 0.510026\n",
      "epoch 37; iter: 0; batch classifier loss: 0.562663\n",
      "epoch 38; iter: 0; batch classifier loss: 0.540116\n",
      "epoch 39; iter: 0; batch classifier loss: 0.571145\n",
      "epoch 40; iter: 0; batch classifier loss: 0.529008\n",
      "epoch 41; iter: 0; batch classifier loss: 0.544123\n",
      "epoch 42; iter: 0; batch classifier loss: 0.596789\n",
      "epoch 43; iter: 0; batch classifier loss: 0.553957\n",
      "epoch 44; iter: 0; batch classifier loss: 0.557721\n",
      "epoch 45; iter: 0; batch classifier loss: 0.593260\n",
      "epoch 46; iter: 0; batch classifier loss: 0.550875\n",
      "epoch 47; iter: 0; batch classifier loss: 0.525840\n",
      "epoch 48; iter: 0; batch classifier loss: 0.548456\n",
      "epoch 49; iter: 0; batch classifier loss: 0.606491\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.089689; batch classifier loss; 0.604441; batch adversarial loss: 0.960224\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.061480; batch classifier loss; 0.528071; batch adversarial loss: 0.955026\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.038783; batch classifier loss; 0.567228; batch adversarial loss: 0.927126\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.030606; batch classifier loss; 0.586979; batch adversarial loss: 0.946849\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.030707; batch classifier loss; 0.545174; batch adversarial loss: 0.939084\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.024389; batch classifier loss; 0.590702; batch adversarial loss: 0.915390\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.018329; batch classifier loss; 0.558215; batch adversarial loss: 0.914090\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.019412; batch classifier loss; 0.573840; batch adversarial loss: 0.902618\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.015775; batch classifier loss; 0.565400; batch adversarial loss: 0.914347\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.012408; batch classifier loss; 0.546459; batch adversarial loss: 0.925564\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.008927; batch classifier loss; 0.483738; batch adversarial loss: 0.918372\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.008825; batch classifier loss; 0.554202; batch adversarial loss: 0.907818\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.009057; batch classifier loss; 0.562808; batch adversarial loss: 0.910223\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.006700; batch classifier loss; 0.593528; batch adversarial loss: 0.889313\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.005942; batch classifier loss; 0.523811; batch adversarial loss: 0.862332\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.004289; batch classifier loss; 0.561713; batch adversarial loss: 0.882761\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.004783; batch classifier loss; 0.601120; batch adversarial loss: 0.836654\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.003901; batch classifier loss; 0.586477; batch adversarial loss: 0.852697\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.003595; batch classifier loss; 0.600839; batch adversarial loss: 0.867993\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.003505; batch classifier loss; 0.512587; batch adversarial loss: 0.848330\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.004210; batch classifier loss; 0.597259; batch adversarial loss: 0.850850\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.003433; batch classifier loss; 0.540191; batch adversarial loss: 0.825027\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.002568; batch classifier loss; 0.558195; batch adversarial loss: 0.829289\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.002586; batch classifier loss; 0.568279; batch adversarial loss: 0.829002\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.002996; batch classifier loss; 0.539916; batch adversarial loss: 0.813404\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.002310; batch classifier loss; 0.582138; batch adversarial loss: 0.817482\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.002352; batch classifier loss; 0.506977; batch adversarial loss: 0.799812\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.002358; batch classifier loss; 0.562372; batch adversarial loss: 0.805580\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.002136; batch classifier loss; 0.518914; batch adversarial loss: 0.801939\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.003065; batch classifier loss; 0.528589; batch adversarial loss: 0.789377\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.002503; batch classifier loss; 0.525279; batch adversarial loss: 0.761001\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.001955; batch classifier loss; 0.577982; batch adversarial loss: 0.780088\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.002152; batch classifier loss; 0.559086; batch adversarial loss: 0.772361\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.002121; batch classifier loss; 0.565086; batch adversarial loss: 0.772820\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.001781; batch classifier loss; 0.550858; batch adversarial loss: 0.756102\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.001797; batch classifier loss; 0.540261; batch adversarial loss: 0.752867\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.001801; batch classifier loss; 0.592847; batch adversarial loss: 0.748879\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.002223; batch classifier loss; 0.634341; batch adversarial loss: 0.750330\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.002407; batch classifier loss; 0.570562; batch adversarial loss: 0.744305\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.001919; batch classifier loss; 0.566607; batch adversarial loss: 0.733270\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.002167; batch classifier loss; 0.581632; batch adversarial loss: 0.732611\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.001549; batch classifier loss; 0.537148; batch adversarial loss: 0.719407\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.002348; batch classifier loss; 0.546361; batch adversarial loss: 0.719161\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.002198; batch classifier loss; 0.476683; batch adversarial loss: 0.711716\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.002168; batch classifier loss; 0.559685; batch adversarial loss: 0.714000\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.002149; batch classifier loss; 0.532836; batch adversarial loss: 0.706197\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.002304; batch classifier loss; 0.625862; batch adversarial loss: 0.706544\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.001998; batch classifier loss; 0.551612; batch adversarial loss: 0.695568\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.001735; batch classifier loss; 0.526880; batch adversarial loss: 0.693867\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.002105; batch classifier loss; 0.541681; batch adversarial loss: 0.689741\n",
      "seed=0 || fold=4\n",
      "epoch 0; iter: 0; batch classifier loss: 0.842274\n",
      "epoch 1; iter: 0; batch classifier loss: 0.738272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:22.337008: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.689767\n",
      "epoch 3; iter: 0; batch classifier loss: 0.645624\n",
      "epoch 4; iter: 0; batch classifier loss: 0.631537\n",
      "epoch 5; iter: 0; batch classifier loss: 0.598540\n",
      "epoch 6; iter: 0; batch classifier loss: 0.613222\n",
      "epoch 7; iter: 0; batch classifier loss: 0.602777\n",
      "epoch 8; iter: 0; batch classifier loss: 0.592521\n",
      "epoch 9; iter: 0; batch classifier loss: 0.599210\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520806\n",
      "epoch 11; iter: 0; batch classifier loss: 0.596581\n",
      "epoch 12; iter: 0; batch classifier loss: 0.584919\n",
      "epoch 13; iter: 0; batch classifier loss: 0.619875\n",
      "epoch 14; iter: 0; batch classifier loss: 0.590587\n",
      "epoch 15; iter: 0; batch classifier loss: 0.585361\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525266\n",
      "epoch 17; iter: 0; batch classifier loss: 0.551067\n",
      "epoch 18; iter: 0; batch classifier loss: 0.585060\n",
      "epoch 19; iter: 0; batch classifier loss: 0.563229\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477867\n",
      "epoch 21; iter: 0; batch classifier loss: 0.595937\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525451\n",
      "epoch 23; iter: 0; batch classifier loss: 0.571752\n",
      "epoch 24; iter: 0; batch classifier loss: 0.579917\n",
      "epoch 25; iter: 0; batch classifier loss: 0.554462\n",
      "epoch 26; iter: 0; batch classifier loss: 0.538565\n",
      "epoch 27; iter: 0; batch classifier loss: 0.573859\n",
      "epoch 28; iter: 0; batch classifier loss: 0.585930\n",
      "epoch 29; iter: 0; batch classifier loss: 0.599320\n",
      "epoch 30; iter: 0; batch classifier loss: 0.559934\n",
      "epoch 31; iter: 0; batch classifier loss: 0.599370\n",
      "epoch 32; iter: 0; batch classifier loss: 0.521622\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474039\n",
      "epoch 34; iter: 0; batch classifier loss: 0.598272\n",
      "epoch 35; iter: 0; batch classifier loss: 0.550470\n",
      "epoch 36; iter: 0; batch classifier loss: 0.567518\n",
      "epoch 37; iter: 0; batch classifier loss: 0.488860\n",
      "epoch 38; iter: 0; batch classifier loss: 0.642515\n",
      "epoch 39; iter: 0; batch classifier loss: 0.582390\n",
      "epoch 40; iter: 0; batch classifier loss: 0.600813\n",
      "epoch 41; iter: 0; batch classifier loss: 0.614707\n",
      "epoch 42; iter: 0; batch classifier loss: 0.551709\n",
      "epoch 43; iter: 0; batch classifier loss: 0.543086\n",
      "epoch 44; iter: 0; batch classifier loss: 0.596486\n",
      "epoch 45; iter: 0; batch classifier loss: 0.590256\n",
      "epoch 46; iter: 0; batch classifier loss: 0.485245\n",
      "epoch 47; iter: 0; batch classifier loss: 0.491492\n",
      "epoch 48; iter: 0; batch classifier loss: 0.561751\n",
      "epoch 49; iter: 0; batch classifier loss: 0.571982\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.051574; batch classifier loss; 0.510517; batch adversarial loss: 0.499176\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.022390; batch classifier loss; 0.596765; batch adversarial loss: 0.477811\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.017699; batch classifier loss; 0.547500; batch adversarial loss: 0.524777\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.014657; batch classifier loss; 0.538917; batch adversarial loss: 0.515737\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.019882; batch classifier loss; 0.523746; batch adversarial loss: 0.531660\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.015072; batch classifier loss; 0.547851; batch adversarial loss: 0.511905\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.013636; batch classifier loss; 0.585997; batch adversarial loss: 0.505622\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.011979; batch classifier loss; 0.545032; batch adversarial loss: 0.514960\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.011367; batch classifier loss; 0.497542; batch adversarial loss: 0.498693\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.010399; batch classifier loss; 0.510981; batch adversarial loss: 0.493516\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.011071; batch classifier loss; 0.579376; batch adversarial loss: 0.535809\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.007385; batch classifier loss; 0.524750; batch adversarial loss: 0.502205\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.007985; batch classifier loss; 0.516260; batch adversarial loss: 0.525454\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.005903; batch classifier loss; 0.510204; batch adversarial loss: 0.462884\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.005327; batch classifier loss; 0.554868; batch adversarial loss: 0.517137\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.007307; batch classifier loss; 0.582041; batch adversarial loss: 0.496846\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.005052; batch classifier loss; 0.543767; batch adversarial loss: 0.485738\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.005944; batch classifier loss; 0.577997; batch adversarial loss: 0.494418\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.005796; batch classifier loss; 0.495164; batch adversarial loss: 0.461902\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.004255; batch classifier loss; 0.585241; batch adversarial loss: 0.489584\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.003826; batch classifier loss; 0.583855; batch adversarial loss: 0.475567\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.004176; batch classifier loss; 0.543204; batch adversarial loss: 0.467490\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.002918; batch classifier loss; 0.581699; batch adversarial loss: 0.457026\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.003618; batch classifier loss; 0.561152; batch adversarial loss: 0.506481\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.003098; batch classifier loss; 0.611550; batch adversarial loss: 0.537414\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.003459; batch classifier loss; 0.528407; batch adversarial loss: 0.468118\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.002861; batch classifier loss; 0.539919; batch adversarial loss: 0.432063\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.003052; batch classifier loss; 0.554709; batch adversarial loss: 0.422281\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.002763; batch classifier loss; 0.562070; batch adversarial loss: 0.487073\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.002299; batch classifier loss; 0.557446; batch adversarial loss: 0.456011\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.002520; batch classifier loss; 0.528203; batch adversarial loss: 0.453059\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.003070; batch classifier loss; 0.527014; batch adversarial loss: 0.497133\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.002054; batch classifier loss; 0.593298; batch adversarial loss: 0.486119\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.002774; batch classifier loss; 0.574302; batch adversarial loss: 0.486345\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.002064; batch classifier loss; 0.544329; batch adversarial loss: 0.454038\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.002641; batch classifier loss; 0.576215; batch adversarial loss: 0.495899\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.002749; batch classifier loss; 0.536066; batch adversarial loss: 0.542678\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.002480; batch classifier loss; 0.530265; batch adversarial loss: 0.478294\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.002389; batch classifier loss; 0.632012; batch adversarial loss: 0.450035\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.002520; batch classifier loss; 0.548987; batch adversarial loss: 0.411302\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.002204; batch classifier loss; 0.525166; batch adversarial loss: 0.429543\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.002807; batch classifier loss; 0.559264; batch adversarial loss: 0.503988\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.002409; batch classifier loss; 0.610729; batch adversarial loss: 0.409092\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.002306; batch classifier loss; 0.518062; batch adversarial loss: 0.514610\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.002158; batch classifier loss; 0.568375; batch adversarial loss: 0.469592\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.003175; batch classifier loss; 0.554917; batch adversarial loss: 0.529472\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.002278; batch classifier loss; 0.550870; batch adversarial loss: 0.444843\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.002963; batch classifier loss; 0.526634; batch adversarial loss: 0.486769\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.002331; batch classifier loss; 0.519679; batch adversarial loss: 0.440421\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001814; batch classifier loss; 0.599268; batch adversarial loss: 0.450386\n",
      "\n",
      "Seed 2/5\n",
      "seed=1 || fold=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:23.845426: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.792464\n",
      "epoch 1; iter: 0; batch classifier loss: 0.761151\n",
      "epoch 2; iter: 0; batch classifier loss: 0.695458\n",
      "epoch 3; iter: 0; batch classifier loss: 0.677537\n",
      "epoch 4; iter: 0; batch classifier loss: 0.652413\n",
      "epoch 5; iter: 0; batch classifier loss: 0.606694\n",
      "epoch 6; iter: 0; batch classifier loss: 0.638052\n",
      "epoch 7; iter: 0; batch classifier loss: 0.649675\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586064\n",
      "epoch 9; iter: 0; batch classifier loss: 0.596272\n",
      "epoch 10; iter: 0; batch classifier loss: 0.604925\n",
      "epoch 11; iter: 0; batch classifier loss: 0.665086\n",
      "epoch 12; iter: 0; batch classifier loss: 0.589211\n",
      "epoch 13; iter: 0; batch classifier loss: 0.610244\n",
      "epoch 14; iter: 0; batch classifier loss: 0.580823\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570669\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571073\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534820\n",
      "epoch 18; iter: 0; batch classifier loss: 0.683356\n",
      "epoch 19; iter: 0; batch classifier loss: 0.556609\n",
      "epoch 20; iter: 0; batch classifier loss: 0.651070\n",
      "epoch 21; iter: 0; batch classifier loss: 0.546466\n",
      "epoch 22; iter: 0; batch classifier loss: 0.538709\n",
      "epoch 23; iter: 0; batch classifier loss: 0.539833\n",
      "epoch 24; iter: 0; batch classifier loss: 0.556723\n",
      "epoch 25; iter: 0; batch classifier loss: 0.627441\n",
      "epoch 26; iter: 0; batch classifier loss: 0.551172\n",
      "epoch 27; iter: 0; batch classifier loss: 0.541265\n",
      "epoch 28; iter: 0; batch classifier loss: 0.558690\n",
      "epoch 29; iter: 0; batch classifier loss: 0.554275\n",
      "epoch 30; iter: 0; batch classifier loss: 0.598814\n",
      "epoch 31; iter: 0; batch classifier loss: 0.586887\n",
      "epoch 32; iter: 0; batch classifier loss: 0.589586\n",
      "epoch 33; iter: 0; batch classifier loss: 0.557565\n",
      "epoch 34; iter: 0; batch classifier loss: 0.548526\n",
      "epoch 35; iter: 0; batch classifier loss: 0.590291\n",
      "epoch 36; iter: 0; batch classifier loss: 0.554276\n",
      "epoch 37; iter: 0; batch classifier loss: 0.585009\n",
      "epoch 38; iter: 0; batch classifier loss: 0.611609\n",
      "epoch 39; iter: 0; batch classifier loss: 0.599292\n",
      "epoch 40; iter: 0; batch classifier loss: 0.581393\n",
      "epoch 41; iter: 0; batch classifier loss: 0.509520\n",
      "epoch 42; iter: 0; batch classifier loss: 0.535617\n",
      "epoch 43; iter: 0; batch classifier loss: 0.567162\n",
      "epoch 44; iter: 0; batch classifier loss: 0.569921\n",
      "epoch 45; iter: 0; batch classifier loss: 0.582134\n",
      "epoch 46; iter: 0; batch classifier loss: 0.601022\n",
      "epoch 47; iter: 0; batch classifier loss: 0.614395\n",
      "epoch 48; iter: 0; batch classifier loss: 0.534292\n",
      "epoch 49; iter: 0; batch classifier loss: 0.588947\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.061157; batch classifier loss; 0.552610; batch adversarial loss: 0.629865\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.030596; batch classifier loss; 0.564517; batch adversarial loss: 0.605749\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.033542; batch classifier loss; 0.512203; batch adversarial loss: 0.598154\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.021226; batch classifier loss; 0.594126; batch adversarial loss: 0.605176\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.016829; batch classifier loss; 0.615442; batch adversarial loss: 0.573385\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.021000; batch classifier loss; 0.601692; batch adversarial loss: 0.616841\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.019330; batch classifier loss; 0.525299; batch adversarial loss: 0.590020\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.016033; batch classifier loss; 0.654583; batch adversarial loss: 0.577036\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.016057; batch classifier loss; 0.513091; batch adversarial loss: 0.601415\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.017843; batch classifier loss; 0.551699; batch adversarial loss: 0.565585\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.011170; batch classifier loss; 0.575132; batch adversarial loss: 0.571950\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.015357; batch classifier loss; 0.559794; batch adversarial loss: 0.570914\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.013237; batch classifier loss; 0.535875; batch adversarial loss: 0.595580\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.012993; batch classifier loss; 0.550183; batch adversarial loss: 0.578499\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.013632; batch classifier loss; 0.632180; batch adversarial loss: 0.558893\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.013593; batch classifier loss; 0.565119; batch adversarial loss: 0.571231\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.010410; batch classifier loss; 0.551122; batch adversarial loss: 0.568503\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.014391; batch classifier loss; 0.545459; batch adversarial loss: 0.570855\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.012741; batch classifier loss; 0.544343; batch adversarial loss: 0.555614\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.010957; batch classifier loss; 0.505882; batch adversarial loss: 0.555069\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.012886; batch classifier loss; 0.596404; batch adversarial loss: 0.551532\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.010572; batch classifier loss; 0.535409; batch adversarial loss: 0.552191\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.012741; batch classifier loss; 0.569754; batch adversarial loss: 0.565796\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.010148; batch classifier loss; 0.614230; batch adversarial loss: 0.518704\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.013231; batch classifier loss; 0.523108; batch adversarial loss: 0.547636\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.010628; batch classifier loss; 0.547150; batch adversarial loss: 0.548881\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.011820; batch classifier loss; 0.579221; batch adversarial loss: 0.535429\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.010711; batch classifier loss; 0.544295; batch adversarial loss: 0.543092\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.009295; batch classifier loss; 0.548002; batch adversarial loss: 0.506019\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.012927; batch classifier loss; 0.556912; batch adversarial loss: 0.564993\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.013154; batch classifier loss; 0.577019; batch adversarial loss: 0.552271\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.008080; batch classifier loss; 0.493131; batch adversarial loss: 0.460674\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.010296; batch classifier loss; 0.596957; batch adversarial loss: 0.534137\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.011951; batch classifier loss; 0.570528; batch adversarial loss: 0.526619\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.011419; batch classifier loss; 0.609825; batch adversarial loss: 0.514975\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.013631; batch classifier loss; 0.543032; batch adversarial loss: 0.557275\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.011669; batch classifier loss; 0.546424; batch adversarial loss: 0.576451\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.011582; batch classifier loss; 0.499121; batch adversarial loss: 0.532744\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.009595; batch classifier loss; 0.515851; batch adversarial loss: 0.507989\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.010422; batch classifier loss; 0.630118; batch adversarial loss: 0.505554\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.010202; batch classifier loss; 0.616819; batch adversarial loss: 0.497985\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.011155; batch classifier loss; 0.526116; batch adversarial loss: 0.477515\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.010583; batch classifier loss; 0.554197; batch adversarial loss: 0.501337\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.010762; batch classifier loss; 0.555078; batch adversarial loss: 0.499649\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.010954; batch classifier loss; 0.596379; batch adversarial loss: 0.514382\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.010854; batch classifier loss; 0.536820; batch adversarial loss: 0.518143\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.009684; batch classifier loss; 0.574431; batch adversarial loss: 0.458330\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.008931; batch classifier loss; 0.478003; batch adversarial loss: 0.518718\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.009789; batch classifier loss; 0.525260; batch adversarial loss: 0.507544\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.011561; batch classifier loss; 0.568933; batch adversarial loss: 0.500938\n",
      "seed=1 || fold=1\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715027\n",
      "epoch 1; iter: 0; batch classifier loss: 0.663679\n",
      "epoch 2; iter: 0; batch classifier loss: 0.614226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:25.502806: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.596770\n",
      "epoch 4; iter: 0; batch classifier loss: 0.646900\n",
      "epoch 5; iter: 0; batch classifier loss: 0.599412\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599999\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554685\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555291\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547967\n",
      "epoch 10; iter: 0; batch classifier loss: 0.623716\n",
      "epoch 11; iter: 0; batch classifier loss: 0.635306\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550935\n",
      "epoch 13; iter: 0; batch classifier loss: 0.573859\n",
      "epoch 14; iter: 0; batch classifier loss: 0.578568\n",
      "epoch 15; iter: 0; batch classifier loss: 0.598760\n",
      "epoch 16; iter: 0; batch classifier loss: 0.524478\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541134\n",
      "epoch 18; iter: 0; batch classifier loss: 0.587892\n",
      "epoch 19; iter: 0; batch classifier loss: 0.561030\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518898\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545411\n",
      "epoch 22; iter: 0; batch classifier loss: 0.560854\n",
      "epoch 23; iter: 0; batch classifier loss: 0.582439\n",
      "epoch 24; iter: 0; batch classifier loss: 0.630791\n",
      "epoch 25; iter: 0; batch classifier loss: 0.645096\n",
      "epoch 26; iter: 0; batch classifier loss: 0.560153\n",
      "epoch 27; iter: 0; batch classifier loss: 0.579546\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514365\n",
      "epoch 29; iter: 0; batch classifier loss: 0.526341\n",
      "epoch 30; iter: 0; batch classifier loss: 0.522996\n",
      "epoch 31; iter: 0; batch classifier loss: 0.545094\n",
      "epoch 32; iter: 0; batch classifier loss: 0.546502\n",
      "epoch 33; iter: 0; batch classifier loss: 0.548042\n",
      "epoch 34; iter: 0; batch classifier loss: 0.617790\n",
      "epoch 35; iter: 0; batch classifier loss: 0.514727\n",
      "epoch 36; iter: 0; batch classifier loss: 0.542507\n",
      "epoch 37; iter: 0; batch classifier loss: 0.505270\n",
      "epoch 38; iter: 0; batch classifier loss: 0.513546\n",
      "epoch 39; iter: 0; batch classifier loss: 0.568592\n",
      "epoch 40; iter: 0; batch classifier loss: 0.585185\n",
      "epoch 41; iter: 0; batch classifier loss: 0.549225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.555683\n",
      "epoch 43; iter: 0; batch classifier loss: 0.618219\n",
      "epoch 44; iter: 0; batch classifier loss: 0.557493\n",
      "epoch 45; iter: 0; batch classifier loss: 0.555666\n",
      "epoch 46; iter: 0; batch classifier loss: 0.549574\n",
      "epoch 47; iter: 0; batch classifier loss: 0.548953\n",
      "epoch 48; iter: 0; batch classifier loss: 0.505696\n",
      "epoch 49; iter: 0; batch classifier loss: 0.539724\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.088214; batch classifier loss; 0.654857; batch adversarial loss: 0.807175\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.048671; batch classifier loss; 0.557102; batch adversarial loss: 0.737911\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.024443; batch classifier loss; 0.601673; batch adversarial loss: 0.755049\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.022834; batch classifier loss; 0.562404; batch adversarial loss: 0.710335\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.015029; batch classifier loss; 0.564608; batch adversarial loss: 0.665172\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.013998; batch classifier loss; 0.542145; batch adversarial loss: 0.642959\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.012116; batch classifier loss; 0.523056; batch adversarial loss: 0.678305\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.012268; batch classifier loss; 0.530010; batch adversarial loss: 0.663685\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.009347; batch classifier loss; 0.571692; batch adversarial loss: 0.699895\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.011702; batch classifier loss; 0.559463; batch adversarial loss: 0.715549\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.010427; batch classifier loss; 0.570854; batch adversarial loss: 0.661570\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.009554; batch classifier loss; 0.472725; batch adversarial loss: 0.594884\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.008066; batch classifier loss; 0.596350; batch adversarial loss: 0.670192\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.008720; batch classifier loss; 0.569363; batch adversarial loss: 0.648088\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.007535; batch classifier loss; 0.601964; batch adversarial loss: 0.665655\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.006396; batch classifier loss; 0.589295; batch adversarial loss: 0.702196\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.006860; batch classifier loss; 0.538655; batch adversarial loss: 0.624508\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.006510; batch classifier loss; 0.537897; batch adversarial loss: 0.614468\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.005794; batch classifier loss; 0.551287; batch adversarial loss: 0.622106\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.004880; batch classifier loss; 0.501311; batch adversarial loss: 0.584478\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.003794; batch classifier loss; 0.596947; batch adversarial loss: 0.643263\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.004965; batch classifier loss; 0.526378; batch adversarial loss: 0.596314\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.004920; batch classifier loss; 0.529365; batch adversarial loss: 0.587290\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.004799; batch classifier loss; 0.522091; batch adversarial loss: 0.600617\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.003566; batch classifier loss; 0.516373; batch adversarial loss: 0.564344\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.005057; batch classifier loss; 0.605744; batch adversarial loss: 0.630131\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.004220; batch classifier loss; 0.514136; batch adversarial loss: 0.591204\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.004160; batch classifier loss; 0.540277; batch adversarial loss: 0.616215\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.003873; batch classifier loss; 0.510140; batch adversarial loss: 0.541742\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.003494; batch classifier loss; 0.593906; batch adversarial loss: 0.575725\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.002986; batch classifier loss; 0.506389; batch adversarial loss: 0.605013\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.003608; batch classifier loss; 0.552446; batch adversarial loss: 0.545384\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.002727; batch classifier loss; 0.556669; batch adversarial loss: 0.575871\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.003138; batch classifier loss; 0.582675; batch adversarial loss: 0.588857\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.002800; batch classifier loss; 0.565768; batch adversarial loss: 0.599145\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.003141; batch classifier loss; 0.542593; batch adversarial loss: 0.572842\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.002827; batch classifier loss; 0.538282; batch adversarial loss: 0.553609\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.002455; batch classifier loss; 0.574367; batch adversarial loss: 0.591307\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.002641; batch classifier loss; 0.554146; batch adversarial loss: 0.612164\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.002311; batch classifier loss; 0.514833; batch adversarial loss: 0.535841\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.002830; batch classifier loss; 0.539565; batch adversarial loss: 0.585264\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.002019; batch classifier loss; 0.527760; batch adversarial loss: 0.557167\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.002240; batch classifier loss; 0.573409; batch adversarial loss: 0.617364\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.002203; batch classifier loss; 0.547733; batch adversarial loss: 0.545166\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.002572; batch classifier loss; 0.534396; batch adversarial loss: 0.516042\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.002392; batch classifier loss; 0.477466; batch adversarial loss: 0.532827\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.002089; batch classifier loss; 0.580772; batch adversarial loss: 0.595814\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.001827; batch classifier loss; 0.570276; batch adversarial loss: 0.512260\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.002288; batch classifier loss; 0.539823; batch adversarial loss: 0.535584\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.002250; batch classifier loss; 0.521218; batch adversarial loss: 0.513930\n",
      "seed=1 || fold=2\n",
      "epoch 0; iter: 0; batch classifier loss: 0.752402\n",
      "epoch 1; iter: 0; batch classifier loss: 0.690873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:26.846383: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.621235\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609192\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598161\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571588\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596454\n",
      "epoch 7; iter: 0; batch classifier loss: 0.647657\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572992\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547068\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594075\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547721\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519607\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583358\n",
      "epoch 14; iter: 0; batch classifier loss: 0.561853\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525939\n",
      "epoch 16; iter: 0; batch classifier loss: 0.575345\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510197\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559226\n",
      "epoch 19; iter: 0; batch classifier loss: 0.597214\n",
      "epoch 20; iter: 0; batch classifier loss: 0.598552\n",
      "epoch 21; iter: 0; batch classifier loss: 0.657964\n",
      "epoch 22; iter: 0; batch classifier loss: 0.556130\n",
      "epoch 23; iter: 0; batch classifier loss: 0.540530\n",
      "epoch 24; iter: 0; batch classifier loss: 0.568132\n",
      "epoch 25; iter: 0; batch classifier loss: 0.530598\n",
      "epoch 26; iter: 0; batch classifier loss: 0.602706\n",
      "epoch 27; iter: 0; batch classifier loss: 0.535401\n",
      "epoch 28; iter: 0; batch classifier loss: 0.545488\n",
      "epoch 29; iter: 0; batch classifier loss: 0.606666\n",
      "epoch 30; iter: 0; batch classifier loss: 0.599643\n",
      "epoch 31; iter: 0; batch classifier loss: 0.543993\n",
      "epoch 32; iter: 0; batch classifier loss: 0.532164\n",
      "epoch 33; iter: 0; batch classifier loss: 0.566648\n",
      "epoch 34; iter: 0; batch classifier loss: 0.566489\n",
      "epoch 35; iter: 0; batch classifier loss: 0.618197\n",
      "epoch 36; iter: 0; batch classifier loss: 0.596150\n",
      "epoch 37; iter: 0; batch classifier loss: 0.592940\n",
      "epoch 38; iter: 0; batch classifier loss: 0.504019\n",
      "epoch 39; iter: 0; batch classifier loss: 0.575765\n",
      "epoch 40; iter: 0; batch classifier loss: 0.538547\n",
      "epoch 41; iter: 0; batch classifier loss: 0.553108\n",
      "epoch 42; iter: 0; batch classifier loss: 0.577404\n",
      "epoch 43; iter: 0; batch classifier loss: 0.552011\n",
      "epoch 44; iter: 0; batch classifier loss: 0.547528\n",
      "epoch 45; iter: 0; batch classifier loss: 0.555668\n",
      "epoch 46; iter: 0; batch classifier loss: 0.530745\n",
      "epoch 47; iter: 0; batch classifier loss: 0.592248\n",
      "epoch 48; iter: 0; batch classifier loss: 0.642822\n",
      "epoch 49; iter: 0; batch classifier loss: 0.541451\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.080253; batch classifier loss; 0.502126; batch adversarial loss: 0.707636\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.024950; batch classifier loss; 0.528106; batch adversarial loss: 0.701497\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.019688; batch classifier loss; 0.527297; batch adversarial loss: 0.697705\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.020547; batch classifier loss; 0.587325; batch adversarial loss: 0.696449\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.016119; batch classifier loss; 0.568871; batch adversarial loss: 0.690696\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.013759; batch classifier loss; 0.554654; batch adversarial loss: 0.688165\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.012924; batch classifier loss; 0.539965; batch adversarial loss: 0.672729\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.014367; batch classifier loss; 0.537262; batch adversarial loss: 0.669515\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.012505; batch classifier loss; 0.539453; batch adversarial loss: 0.666782\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.013658; batch classifier loss; 0.539899; batch adversarial loss: 0.656586\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.007520; batch classifier loss; 0.622683; batch adversarial loss: 0.668288\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.007126; batch classifier loss; 0.582155; batch adversarial loss: 0.660426\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.010422; batch classifier loss; 0.534128; batch adversarial loss: 0.652615\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.007069; batch classifier loss; 0.555324; batch adversarial loss: 0.657276\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.008895; batch classifier loss; 0.605533; batch adversarial loss: 0.649864\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.006120; batch classifier loss; 0.504173; batch adversarial loss: 0.641161\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.005914; batch classifier loss; 0.516688; batch adversarial loss: 0.628738\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.004967; batch classifier loss; 0.559720; batch adversarial loss: 0.632487\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.005507; batch classifier loss; 0.497150; batch adversarial loss: 0.623581\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.005080; batch classifier loss; 0.550630; batch adversarial loss: 0.613313\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.003920; batch classifier loss; 0.633598; batch adversarial loss: 0.617521\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.004176; batch classifier loss; 0.542431; batch adversarial loss: 0.606368\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.004172; batch classifier loss; 0.508827; batch adversarial loss: 0.614433\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.004453; batch classifier loss; 0.535229; batch adversarial loss: 0.613819\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.003616; batch classifier loss; 0.600255; batch adversarial loss: 0.602389\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.002668; batch classifier loss; 0.487292; batch adversarial loss: 0.573565\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.002626; batch classifier loss; 0.573977; batch adversarial loss: 0.593417\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.003440; batch classifier loss; 0.636969; batch adversarial loss: 0.595573\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.002635; batch classifier loss; 0.498571; batch adversarial loss: 0.585837\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.002709; batch classifier loss; 0.590338; batch adversarial loss: 0.574359\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.003249; batch classifier loss; 0.504332; batch adversarial loss: 0.584797\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.002228; batch classifier loss; 0.533274; batch adversarial loss: 0.578546\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.002386; batch classifier loss; 0.589075; batch adversarial loss: 0.580649\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.002795; batch classifier loss; 0.571814; batch adversarial loss: 0.575762\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.002260; batch classifier loss; 0.596771; batch adversarial loss: 0.579278\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.002445; batch classifier loss; 0.579946; batch adversarial loss: 0.579883\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.002000; batch classifier loss; 0.500325; batch adversarial loss: 0.543975\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.002437; batch classifier loss; 0.521434; batch adversarial loss: 0.550209\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.002594; batch classifier loss; 0.519859; batch adversarial loss: 0.543279\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.002075; batch classifier loss; 0.632311; batch adversarial loss: 0.582225\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.002291; batch classifier loss; 0.557348; batch adversarial loss: 0.583341\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.002002; batch classifier loss; 0.556723; batch adversarial loss: 0.541868\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.002633; batch classifier loss; 0.562136; batch adversarial loss: 0.548633\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.002701; batch classifier loss; 0.565588; batch adversarial loss: 0.552959\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.002118; batch classifier loss; 0.586284; batch adversarial loss: 0.525253\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.002709; batch classifier loss; 0.575759; batch adversarial loss: 0.524603\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.001944; batch classifier loss; 0.553972; batch adversarial loss: 0.509518\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.002042; batch classifier loss; 0.584276; batch adversarial loss: 0.530333\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.002509; batch classifier loss; 0.580038; batch adversarial loss: 0.558264\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001875; batch classifier loss; 0.536290; batch adversarial loss: 0.515507\n",
      "seed=1 || fold=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:28.286104: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.719754\n",
      "epoch 1; iter: 0; batch classifier loss: 0.666699\n",
      "epoch 2; iter: 0; batch classifier loss: 0.637203\n",
      "epoch 3; iter: 0; batch classifier loss: 0.626740\n",
      "epoch 4; iter: 0; batch classifier loss: 0.630095\n",
      "epoch 5; iter: 0; batch classifier loss: 0.630201\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584402\n",
      "epoch 7; iter: 0; batch classifier loss: 0.515744\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568467\n",
      "epoch 9; iter: 0; batch classifier loss: 0.606016\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558406\n",
      "epoch 11; iter: 0; batch classifier loss: 0.504255\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557308\n",
      "epoch 13; iter: 0; batch classifier loss: 0.590199\n",
      "epoch 14; iter: 0; batch classifier loss: 0.592012\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563359\n",
      "epoch 16; iter: 0; batch classifier loss: 0.565628\n",
      "epoch 17; iter: 0; batch classifier loss: 0.558154\n",
      "epoch 18; iter: 0; batch classifier loss: 0.527462\n",
      "epoch 19; iter: 0; batch classifier loss: 0.564669\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529342\n",
      "epoch 21; iter: 0; batch classifier loss: 0.563965\n",
      "epoch 22; iter: 0; batch classifier loss: 0.532056\n",
      "epoch 23; iter: 0; batch classifier loss: 0.637154\n",
      "epoch 24; iter: 0; batch classifier loss: 0.536841\n",
      "epoch 25; iter: 0; batch classifier loss: 0.536705\n",
      "epoch 26; iter: 0; batch classifier loss: 0.552383\n",
      "epoch 27; iter: 0; batch classifier loss: 0.556793\n",
      "epoch 28; iter: 0; batch classifier loss: 0.579819\n",
      "epoch 29; iter: 0; batch classifier loss: 0.597517\n",
      "epoch 30; iter: 0; batch classifier loss: 0.558706\n",
      "epoch 31; iter: 0; batch classifier loss: 0.522766\n",
      "epoch 32; iter: 0; batch classifier loss: 0.580393\n",
      "epoch 33; iter: 0; batch classifier loss: 0.532600\n",
      "epoch 34; iter: 0; batch classifier loss: 0.528394\n",
      "epoch 35; iter: 0; batch classifier loss: 0.662506\n",
      "epoch 36; iter: 0; batch classifier loss: 0.592677\n",
      "epoch 37; iter: 0; batch classifier loss: 0.510326\n",
      "epoch 38; iter: 0; batch classifier loss: 0.553074\n",
      "epoch 39; iter: 0; batch classifier loss: 0.541850\n",
      "epoch 40; iter: 0; batch classifier loss: 0.577771\n",
      "epoch 41; iter: 0; batch classifier loss: 0.566022\n",
      "epoch 42; iter: 0; batch classifier loss: 0.575011\n",
      "epoch 43; iter: 0; batch classifier loss: 0.538200\n",
      "epoch 44; iter: 0; batch classifier loss: 0.520674\n",
      "epoch 45; iter: 0; batch classifier loss: 0.487442\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495039\n",
      "epoch 47; iter: 0; batch classifier loss: 0.542339\n",
      "epoch 48; iter: 0; batch classifier loss: 0.584726\n",
      "epoch 49; iter: 0; batch classifier loss: 0.553380\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.053729; batch classifier loss; 0.513176; batch adversarial loss: 0.651121\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.035377; batch classifier loss; 0.465222; batch adversarial loss: 0.673690\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.022214; batch classifier loss; 0.519925; batch adversarial loss: 0.670863\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.014310; batch classifier loss; 0.581829; batch adversarial loss: 0.665781\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.012701; batch classifier loss; 0.559130; batch adversarial loss: 0.667525\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.012244; batch classifier loss; 0.618936; batch adversarial loss: 0.632740\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.010950; batch classifier loss; 0.576404; batch adversarial loss: 0.652382\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.009686; batch classifier loss; 0.540824; batch adversarial loss: 0.636358\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.008235; batch classifier loss; 0.493965; batch adversarial loss: 0.646109\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.010476; batch classifier loss; 0.608530; batch adversarial loss: 0.647482\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.005841; batch classifier loss; 0.590046; batch adversarial loss: 0.616047\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.007209; batch classifier loss; 0.495521; batch adversarial loss: 0.625836\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.006462; batch classifier loss; 0.535750; batch adversarial loss: 0.661303\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.007115; batch classifier loss; 0.629054; batch adversarial loss: 0.581012\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.005000; batch classifier loss; 0.543225; batch adversarial loss: 0.596174\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.004275; batch classifier loss; 0.543299; batch adversarial loss: 0.627642\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.004752; batch classifier loss; 0.511325; batch adversarial loss: 0.660281\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.003509; batch classifier loss; 0.599541; batch adversarial loss: 0.620661\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.004492; batch classifier loss; 0.572434; batch adversarial loss: 0.600043\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.004100; batch classifier loss; 0.578314; batch adversarial loss: 0.603489\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.003357; batch classifier loss; 0.575136; batch adversarial loss: 0.582490\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.002778; batch classifier loss; 0.531104; batch adversarial loss: 0.647861\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.003162; batch classifier loss; 0.574702; batch adversarial loss: 0.599530\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.002928; batch classifier loss; 0.500129; batch adversarial loss: 0.622566\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.003070; batch classifier loss; 0.537149; batch adversarial loss: 0.586001\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.002440; batch classifier loss; 0.603006; batch adversarial loss: 0.623814\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.002014; batch classifier loss; 0.540480; batch adversarial loss: 0.568630\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.002643; batch classifier loss; 0.536082; batch adversarial loss: 0.591315\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.002536; batch classifier loss; 0.550893; batch adversarial loss: 0.537363\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.001812; batch classifier loss; 0.560372; batch adversarial loss: 0.619088\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.002282; batch classifier loss; 0.577796; batch adversarial loss: 0.650779\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.002126; batch classifier loss; 0.610455; batch adversarial loss: 0.523978\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.001809; batch classifier loss; 0.587909; batch adversarial loss: 0.615273\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.002033; batch classifier loss; 0.522428; batch adversarial loss: 0.568128\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.001702; batch classifier loss; 0.526809; batch adversarial loss: 0.567328\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.001900; batch classifier loss; 0.595894; batch adversarial loss: 0.489985\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.001850; batch classifier loss; 0.548675; batch adversarial loss: 0.551602\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.001760; batch classifier loss; 0.516185; batch adversarial loss: 0.567813\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.001703; batch classifier loss; 0.559390; batch adversarial loss: 0.567655\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.001614; batch classifier loss; 0.536199; batch adversarial loss: 0.518680\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.001724; batch classifier loss; 0.554950; batch adversarial loss: 0.547709\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.001824; batch classifier loss; 0.616671; batch adversarial loss: 0.506982\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.001833; batch classifier loss; 0.611049; batch adversarial loss: 0.570122\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.001834; batch classifier loss; 0.520327; batch adversarial loss: 0.530642\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.002181; batch classifier loss; 0.522259; batch adversarial loss: 0.545665\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.001524; batch classifier loss; 0.546573; batch adversarial loss: 0.521217\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.001682; batch classifier loss; 0.611546; batch adversarial loss: 0.523478\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.002002; batch classifier loss; 0.647704; batch adversarial loss: 0.515789\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.001625; batch classifier loss; 0.562891; batch adversarial loss: 0.548562\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001637; batch classifier loss; 0.525087; batch adversarial loss: 0.513068\n",
      "seed=1 || fold=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:29.692624: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.659440\n",
      "epoch 1; iter: 0; batch classifier loss: 0.611134\n",
      "epoch 2; iter: 0; batch classifier loss: 0.601768\n",
      "epoch 3; iter: 0; batch classifier loss: 0.626491\n",
      "epoch 4; iter: 0; batch classifier loss: 0.638347\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574928\n",
      "epoch 6; iter: 0; batch classifier loss: 0.635120\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603163\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533833\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580674\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553048\n",
      "epoch 11; iter: 0; batch classifier loss: 0.636130\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548342\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575852\n",
      "epoch 14; iter: 0; batch classifier loss: 0.574633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.621603\n",
      "epoch 16; iter: 0; batch classifier loss: 0.619549\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550385\n",
      "epoch 18; iter: 0; batch classifier loss: 0.630862\n",
      "epoch 19; iter: 0; batch classifier loss: 0.559303\n",
      "epoch 20; iter: 0; batch classifier loss: 0.605542\n",
      "epoch 21; iter: 0; batch classifier loss: 0.574328\n",
      "epoch 22; iter: 0; batch classifier loss: 0.498490\n",
      "epoch 23; iter: 0; batch classifier loss: 0.575126\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517044\n",
      "epoch 25; iter: 0; batch classifier loss: 0.698827\n",
      "epoch 26; iter: 0; batch classifier loss: 0.550009\n",
      "epoch 27; iter: 0; batch classifier loss: 0.598552\n",
      "epoch 28; iter: 0; batch classifier loss: 0.562456\n",
      "epoch 29; iter: 0; batch classifier loss: 0.592983\n",
      "epoch 30; iter: 0; batch classifier loss: 0.641254\n",
      "epoch 31; iter: 0; batch classifier loss: 0.580578\n",
      "epoch 32; iter: 0; batch classifier loss: 0.584138\n",
      "epoch 33; iter: 0; batch classifier loss: 0.560225\n",
      "epoch 34; iter: 0; batch classifier loss: 0.643831\n",
      "epoch 35; iter: 0; batch classifier loss: 0.566161\n",
      "epoch 36; iter: 0; batch classifier loss: 0.546997\n",
      "epoch 37; iter: 0; batch classifier loss: 0.601079\n",
      "epoch 38; iter: 0; batch classifier loss: 0.559388\n",
      "epoch 39; iter: 0; batch classifier loss: 0.588072\n",
      "epoch 40; iter: 0; batch classifier loss: 0.579285\n",
      "epoch 41; iter: 0; batch classifier loss: 0.622729\n",
      "epoch 42; iter: 0; batch classifier loss: 0.575689\n",
      "epoch 43; iter: 0; batch classifier loss: 0.587220\n",
      "epoch 44; iter: 0; batch classifier loss: 0.591988\n",
      "epoch 45; iter: 0; batch classifier loss: 0.643608\n",
      "epoch 46; iter: 0; batch classifier loss: 0.582371\n",
      "epoch 47; iter: 0; batch classifier loss: 0.529644\n",
      "epoch 48; iter: 0; batch classifier loss: 0.595020\n",
      "epoch 49; iter: 0; batch classifier loss: 0.563627\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.105416; batch classifier loss; 0.631845; batch adversarial loss: 0.766709\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.069885; batch classifier loss; 0.528013; batch adversarial loss: 0.813267\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.035625; batch classifier loss; 0.549329; batch adversarial loss: 0.764941\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.030794; batch classifier loss; 0.556475; batch adversarial loss: 0.759387\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.034411; batch classifier loss; 0.623111; batch adversarial loss: 0.749587\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.023516; batch classifier loss; 0.596387; batch adversarial loss: 0.720802\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.024873; batch classifier loss; 0.539538; batch adversarial loss: 0.733070\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.020495; batch classifier loss; 0.554603; batch adversarial loss: 0.743341\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.019369; batch classifier loss; 0.611868; batch adversarial loss: 0.720352\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.015873; batch classifier loss; 0.595608; batch adversarial loss: 0.738133\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.016702; batch classifier loss; 0.559756; batch adversarial loss: 0.726489\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.012247; batch classifier loss; 0.584804; batch adversarial loss: 0.700376\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.011776; batch classifier loss; 0.546362; batch adversarial loss: 0.707855\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.012614; batch classifier loss; 0.600403; batch adversarial loss: 0.688112\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.010475; batch classifier loss; 0.592805; batch adversarial loss: 0.725592\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.010109; batch classifier loss; 0.559496; batch adversarial loss: 0.692339\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.009415; batch classifier loss; 0.604680; batch adversarial loss: 0.683796\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.007551; batch classifier loss; 0.609924; batch adversarial loss: 0.673579\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.008780; batch classifier loss; 0.559039; batch adversarial loss: 0.680860\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.007721; batch classifier loss; 0.516856; batch adversarial loss: 0.695448\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.007305; batch classifier loss; 0.587229; batch adversarial loss: 0.690731\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.005948; batch classifier loss; 0.513981; batch adversarial loss: 0.700979\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.006406; batch classifier loss; 0.591165; batch adversarial loss: 0.674746\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.004798; batch classifier loss; 0.553702; batch adversarial loss: 0.660932\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.006008; batch classifier loss; 0.546340; batch adversarial loss: 0.675689\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.006835; batch classifier loss; 0.544590; batch adversarial loss: 0.672320\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.005898; batch classifier loss; 0.593784; batch adversarial loss: 0.669345\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.004979; batch classifier loss; 0.659065; batch adversarial loss: 0.639926\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.005195; batch classifier loss; 0.580035; batch adversarial loss: 0.688668\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.005194; batch classifier loss; 0.551694; batch adversarial loss: 0.657940\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.005468; batch classifier loss; 0.568894; batch adversarial loss: 0.626194\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.004375; batch classifier loss; 0.556450; batch adversarial loss: 0.661268\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.003675; batch classifier loss; 0.524771; batch adversarial loss: 0.629780\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.003067; batch classifier loss; 0.500515; batch adversarial loss: 0.674316\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.003924; batch classifier loss; 0.593600; batch adversarial loss: 0.607768\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.003700; batch classifier loss; 0.562703; batch adversarial loss: 0.643885\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.003625; batch classifier loss; 0.624445; batch adversarial loss: 0.602770\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.003480; batch classifier loss; 0.526810; batch adversarial loss: 0.632065\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.004170; batch classifier loss; 0.609978; batch adversarial loss: 0.611364\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.003860; batch classifier loss; 0.549973; batch adversarial loss: 0.623513\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.002985; batch classifier loss; 0.487192; batch adversarial loss: 0.664928\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.003383; batch classifier loss; 0.523816; batch adversarial loss: 0.585273\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.003922; batch classifier loss; 0.554558; batch adversarial loss: 0.620548\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.002326; batch classifier loss; 0.567204; batch adversarial loss: 0.610412\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.002843; batch classifier loss; 0.627982; batch adversarial loss: 0.592741\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.003714; batch classifier loss; 0.572480; batch adversarial loss: 0.636242\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.002433; batch classifier loss; 0.600244; batch adversarial loss: 0.552351\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.003889; batch classifier loss; 0.568716; batch adversarial loss: 0.617029\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.002686; batch classifier loss; 0.587308; batch adversarial loss: 0.583048\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.002775; batch classifier loss; 0.601362; batch adversarial loss: 0.657690\n",
      "\n",
      "Seed 3/5\n",
      "seed=2 || fold=0\n",
      "epoch 0; iter: 0; batch classifier loss: 0.657582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:31.074974: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 0; batch classifier loss: 0.658759\n",
      "epoch 2; iter: 0; batch classifier loss: 0.637164\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567192\n",
      "epoch 4; iter: 0; batch classifier loss: 0.630034\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548450\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571003\n",
      "epoch 7; iter: 0; batch classifier loss: 0.575937\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576990\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501183\n",
      "epoch 10; iter: 0; batch classifier loss: 0.545002\n",
      "epoch 11; iter: 0; batch classifier loss: 0.604260\n",
      "epoch 12; iter: 0; batch classifier loss: 0.629896\n",
      "epoch 13; iter: 0; batch classifier loss: 0.571855\n",
      "epoch 14; iter: 0; batch classifier loss: 0.580951\n",
      "epoch 15; iter: 0; batch classifier loss: 0.573389\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592038\n",
      "epoch 17; iter: 0; batch classifier loss: 0.548488\n",
      "epoch 18; iter: 0; batch classifier loss: 0.560074\n",
      "epoch 19; iter: 0; batch classifier loss: 0.539040\n",
      "epoch 20; iter: 0; batch classifier loss: 0.585870\n",
      "epoch 21; iter: 0; batch classifier loss: 0.557512\n",
      "epoch 22; iter: 0; batch classifier loss: 0.616295\n",
      "epoch 23; iter: 0; batch classifier loss: 0.654395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.573833\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524703\n",
      "epoch 26; iter: 0; batch classifier loss: 0.559024\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478925\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532553\n",
      "epoch 29; iter: 0; batch classifier loss: 0.500392\n",
      "epoch 30; iter: 0; batch classifier loss: 0.589374\n",
      "epoch 31; iter: 0; batch classifier loss: 0.570946\n",
      "epoch 32; iter: 0; batch classifier loss: 0.611870\n",
      "epoch 33; iter: 0; batch classifier loss: 0.595760\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459890\n",
      "epoch 35; iter: 0; batch classifier loss: 0.608356\n",
      "epoch 36; iter: 0; batch classifier loss: 0.506435\n",
      "epoch 37; iter: 0; batch classifier loss: 0.545971\n",
      "epoch 38; iter: 0; batch classifier loss: 0.580768\n",
      "epoch 39; iter: 0; batch classifier loss: 0.551455\n",
      "epoch 40; iter: 0; batch classifier loss: 0.520549\n",
      "epoch 41; iter: 0; batch classifier loss: 0.567692\n",
      "epoch 42; iter: 0; batch classifier loss: 0.519078\n",
      "epoch 43; iter: 0; batch classifier loss: 0.569593\n",
      "epoch 44; iter: 0; batch classifier loss: 0.571354\n",
      "epoch 45; iter: 0; batch classifier loss: 0.570070\n",
      "epoch 46; iter: 0; batch classifier loss: 0.516686\n",
      "epoch 47; iter: 0; batch classifier loss: 0.576144\n",
      "epoch 48; iter: 0; batch classifier loss: 0.546372\n",
      "epoch 49; iter: 0; batch classifier loss: 0.576434\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.085354; batch classifier loss; 0.559778; batch adversarial loss: 0.540733\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.025378; batch classifier loss; 0.488014; batch adversarial loss: 0.509599\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.025037; batch classifier loss; 0.496622; batch adversarial loss: 0.522169\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.027396; batch classifier loss; 0.557690; batch adversarial loss: 0.505822\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.021690; batch classifier loss; 0.535305; batch adversarial loss: 0.497509\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.016306; batch classifier loss; 0.473420; batch adversarial loss: 0.526189\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.012782; batch classifier loss; 0.556020; batch adversarial loss: 0.503899\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.013959; batch classifier loss; 0.579954; batch adversarial loss: 0.516811\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.015320; batch classifier loss; 0.537414; batch adversarial loss: 0.489175\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.011280; batch classifier loss; 0.524039; batch adversarial loss: 0.495388\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.014431; batch classifier loss; 0.535964; batch adversarial loss: 0.487576\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.007372; batch classifier loss; 0.542767; batch adversarial loss: 0.510784\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.009323; batch classifier loss; 0.556943; batch adversarial loss: 0.488070\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.007595; batch classifier loss; 0.569074; batch adversarial loss: 0.493109\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.010477; batch classifier loss; 0.529782; batch adversarial loss: 0.496440\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.008079; batch classifier loss; 0.593667; batch adversarial loss: 0.526890\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.007301; batch classifier loss; 0.556631; batch adversarial loss: 0.502656\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.005356; batch classifier loss; 0.581992; batch adversarial loss: 0.501153\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.006624; batch classifier loss; 0.625154; batch adversarial loss: 0.521162\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.006400; batch classifier loss; 0.502149; batch adversarial loss: 0.424581\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.004110; batch classifier loss; 0.556254; batch adversarial loss: 0.487407\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.005520; batch classifier loss; 0.590480; batch adversarial loss: 0.462310\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.003627; batch classifier loss; 0.554301; batch adversarial loss: 0.446803\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.004606; batch classifier loss; 0.547337; batch adversarial loss: 0.454665\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.004079; batch classifier loss; 0.531260; batch adversarial loss: 0.515147\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.005287; batch classifier loss; 0.522637; batch adversarial loss: 0.441385\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.004190; batch classifier loss; 0.581342; batch adversarial loss: 0.518789\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.003594; batch classifier loss; 0.519238; batch adversarial loss: 0.461079\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.005838; batch classifier loss; 0.565260; batch adversarial loss: 0.502862\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.004006; batch classifier loss; 0.539762; batch adversarial loss: 0.473927\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.003525; batch classifier loss; 0.603569; batch adversarial loss: 0.483080\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.002839; batch classifier loss; 0.506044; batch adversarial loss: 0.492020\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.003814; batch classifier loss; 0.563606; batch adversarial loss: 0.441474\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.003240; batch classifier loss; 0.522845; batch adversarial loss: 0.471863\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.002447; batch classifier loss; 0.558039; batch adversarial loss: 0.486788\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.002834; batch classifier loss; 0.542559; batch adversarial loss: 0.454285\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.002166; batch classifier loss; 0.623846; batch adversarial loss: 0.491361\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.002783; batch classifier loss; 0.515547; batch adversarial loss: 0.472006\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.002194; batch classifier loss; 0.595100; batch adversarial loss: 0.470736\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.002317; batch classifier loss; 0.519854; batch adversarial loss: 0.449430\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.002679; batch classifier loss; 0.528098; batch adversarial loss: 0.453579\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.001815; batch classifier loss; 0.579975; batch adversarial loss: 0.417884\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.002429; batch classifier loss; 0.506581; batch adversarial loss: 0.478015\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.001514; batch classifier loss; 0.535630; batch adversarial loss: 0.443246\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.001985; batch classifier loss; 0.580850; batch adversarial loss: 0.489687\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.002303; batch classifier loss; 0.554356; batch adversarial loss: 0.453833\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.002271; batch classifier loss; 0.553662; batch adversarial loss: 0.453880\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.001979; batch classifier loss; 0.512318; batch adversarial loss: 0.471851\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.001451; batch classifier loss; 0.515886; batch adversarial loss: 0.495005\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001501; batch classifier loss; 0.566412; batch adversarial loss: 0.380953\n",
      "seed=2 || fold=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:32.447451: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.720036\n",
      "epoch 1; iter: 0; batch classifier loss: 0.670823\n",
      "epoch 2; iter: 0; batch classifier loss: 0.633127\n",
      "epoch 3; iter: 0; batch classifier loss: 0.662425\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566957\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567053\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550913\n",
      "epoch 7; iter: 0; batch classifier loss: 0.515657\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583223\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563349\n",
      "epoch 10; iter: 0; batch classifier loss: 0.606597\n",
      "epoch 11; iter: 0; batch classifier loss: 0.557116\n",
      "epoch 12; iter: 0; batch classifier loss: 0.575682\n",
      "epoch 13; iter: 0; batch classifier loss: 0.579565\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533013\n",
      "epoch 15; iter: 0; batch classifier loss: 0.592037\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554378\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537533\n",
      "epoch 18; iter: 0; batch classifier loss: 0.569195\n",
      "epoch 19; iter: 0; batch classifier loss: 0.572590\n",
      "epoch 20; iter: 0; batch classifier loss: 0.573880\n",
      "epoch 21; iter: 0; batch classifier loss: 0.522468\n",
      "epoch 22; iter: 0; batch classifier loss: 0.546571\n",
      "epoch 23; iter: 0; batch classifier loss: 0.642486\n",
      "epoch 24; iter: 0; batch classifier loss: 0.589874\n",
      "epoch 25; iter: 0; batch classifier loss: 0.603220\n",
      "epoch 26; iter: 0; batch classifier loss: 0.616656\n",
      "epoch 27; iter: 0; batch classifier loss: 0.530998\n",
      "epoch 28; iter: 0; batch classifier loss: 0.610604\n",
      "epoch 29; iter: 0; batch classifier loss: 0.581652\n",
      "epoch 30; iter: 0; batch classifier loss: 0.577927\n",
      "epoch 31; iter: 0; batch classifier loss: 0.562265\n",
      "epoch 32; iter: 0; batch classifier loss: 0.644049\n",
      "epoch 33; iter: 0; batch classifier loss: 0.592313\n",
      "epoch 34; iter: 0; batch classifier loss: 0.523757\n",
      "epoch 35; iter: 0; batch classifier loss: 0.534271\n",
      "epoch 36; iter: 0; batch classifier loss: 0.571882\n",
      "epoch 37; iter: 0; batch classifier loss: 0.561746\n",
      "epoch 38; iter: 0; batch classifier loss: 0.580326\n",
      "epoch 39; iter: 0; batch classifier loss: 0.574092\n",
      "epoch 40; iter: 0; batch classifier loss: 0.565574\n",
      "epoch 41; iter: 0; batch classifier loss: 0.553608\n",
      "epoch 42; iter: 0; batch classifier loss: 0.628507\n",
      "epoch 43; iter: 0; batch classifier loss: 0.532453\n",
      "epoch 44; iter: 0; batch classifier loss: 0.516085\n",
      "epoch 45; iter: 0; batch classifier loss: 0.607398\n",
      "epoch 46; iter: 0; batch classifier loss: 0.608814\n",
      "epoch 47; iter: 0; batch classifier loss: 0.515424\n",
      "epoch 48; iter: 0; batch classifier loss: 0.554395\n",
      "epoch 49; iter: 0; batch classifier loss: 0.548055\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.042713; batch classifier loss; 0.495854; batch adversarial loss: 0.966745\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.023573; batch classifier loss; 0.614314; batch adversarial loss: 0.950074\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.015442; batch classifier loss; 0.479431; batch adversarial loss: 1.024987\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.014513; batch classifier loss; 0.581296; batch adversarial loss: 0.956557\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.011950; batch classifier loss; 0.592591; batch adversarial loss: 0.909195\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.014633; batch classifier loss; 0.568515; batch adversarial loss: 0.919975\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.010118; batch classifier loss; 0.574313; batch adversarial loss: 0.926856\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.008560; batch classifier loss; 0.523423; batch adversarial loss: 0.947000\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.008823; batch classifier loss; 0.492901; batch adversarial loss: 0.952453\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.006948; batch classifier loss; 0.545573; batch adversarial loss: 0.909897\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.008118; batch classifier loss; 0.510490; batch adversarial loss: 0.963206\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.005794; batch classifier loss; 0.501797; batch adversarial loss: 0.938470\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.006855; batch classifier loss; 0.577893; batch adversarial loss: 0.908500\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.005546; batch classifier loss; 0.564569; batch adversarial loss: 0.893745\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.006023; batch classifier loss; 0.526875; batch adversarial loss: 0.913004\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.004370; batch classifier loss; 0.490368; batch adversarial loss: 0.912474\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.003795; batch classifier loss; 0.603611; batch adversarial loss: 0.861479\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.004722; batch classifier loss; 0.565526; batch adversarial loss: 0.878097\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.003619; batch classifier loss; 0.572824; batch adversarial loss: 0.826490\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.004043; batch classifier loss; 0.577372; batch adversarial loss: 0.847983\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.003224; batch classifier loss; 0.564314; batch adversarial loss: 0.845108\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.003008; batch classifier loss; 0.586116; batch adversarial loss: 0.823522\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.002602; batch classifier loss; 0.558638; batch adversarial loss: 0.866566\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.002442; batch classifier loss; 0.579222; batch adversarial loss: 0.824077\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.002924; batch classifier loss; 0.563800; batch adversarial loss: 0.816590\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.002804; batch classifier loss; 0.578119; batch adversarial loss: 0.786451\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.002299; batch classifier loss; 0.507546; batch adversarial loss: 0.801141\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.002810; batch classifier loss; 0.604506; batch adversarial loss: 0.814145\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.002441; batch classifier loss; 0.551065; batch adversarial loss: 0.811249\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.001816; batch classifier loss; 0.556036; batch adversarial loss: 0.793133\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.002194; batch classifier loss; 0.524948; batch adversarial loss: 0.810803\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.001677; batch classifier loss; 0.557056; batch adversarial loss: 0.775334\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.001560; batch classifier loss; 0.609973; batch adversarial loss: 0.749811\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.001992; batch classifier loss; 0.522007; batch adversarial loss: 0.795323\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.001481; batch classifier loss; 0.571790; batch adversarial loss: 0.756760\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.001662; batch classifier loss; 0.542144; batch adversarial loss: 0.786710\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.001705; batch classifier loss; 0.484913; batch adversarial loss: 0.796700\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.001466; batch classifier loss; 0.514515; batch adversarial loss: 0.764806\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.001801; batch classifier loss; 0.591624; batch adversarial loss: 0.752325\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.001559; batch classifier loss; 0.610421; batch adversarial loss: 0.721345\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.001407; batch classifier loss; 0.580861; batch adversarial loss: 0.731369\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.001520; batch classifier loss; 0.537254; batch adversarial loss: 0.770918\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.001054; batch classifier loss; 0.556301; batch adversarial loss: 0.726142\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.001063; batch classifier loss; 0.553953; batch adversarial loss: 0.722005\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.001640; batch classifier loss; 0.589712; batch adversarial loss: 0.728410\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.001476; batch classifier loss; 0.609117; batch adversarial loss: 0.687873\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.001373; batch classifier loss; 0.598963; batch adversarial loss: 0.698706\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.001213; batch classifier loss; 0.593332; batch adversarial loss: 0.708046\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.001476; batch classifier loss; 0.625340; batch adversarial loss: 0.683697\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001082; batch classifier loss; 0.578323; batch adversarial loss: 0.707966\n",
      "seed=2 || fold=2\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:33.820812: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 0; batch classifier loss: 0.652480\n",
      "epoch 2; iter: 0; batch classifier loss: 0.593836\n",
      "epoch 3; iter: 0; batch classifier loss: 0.667172\n",
      "epoch 4; iter: 0; batch classifier loss: 0.617632\n",
      "epoch 5; iter: 0; batch classifier loss: 0.629555\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606705\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592559\n",
      "epoch 8; iter: 0; batch classifier loss: 0.598138\n",
      "epoch 9; iter: 0; batch classifier loss: 0.600871\n",
      "epoch 10; iter: 0; batch classifier loss: 0.587744\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571867\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562654\n",
      "epoch 13; iter: 0; batch classifier loss: 0.584338\n",
      "epoch 14; iter: 0; batch classifier loss: 0.600245\n",
      "epoch 15; iter: 0; batch classifier loss: 0.655841\n",
      "epoch 16; iter: 0; batch classifier loss: 0.584291\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559993\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535218\n",
      "epoch 19; iter: 0; batch classifier loss: 0.610975\n",
      "epoch 20; iter: 0; batch classifier loss: 0.572582\n",
      "epoch 21; iter: 0; batch classifier loss: 0.557895\n",
      "epoch 22; iter: 0; batch classifier loss: 0.552408\n",
      "epoch 23; iter: 0; batch classifier loss: 0.589696\n",
      "epoch 24; iter: 0; batch classifier loss: 0.535552\n",
      "epoch 25; iter: 0; batch classifier loss: 0.549952\n",
      "epoch 26; iter: 0; batch classifier loss: 0.529070\n",
      "epoch 27; iter: 0; batch classifier loss: 0.545424\n",
      "epoch 28; iter: 0; batch classifier loss: 0.554856\n",
      "epoch 29; iter: 0; batch classifier loss: 0.545048\n",
      "epoch 30; iter: 0; batch classifier loss: 0.597906\n",
      "epoch 31; iter: 0; batch classifier loss: 0.570309\n",
      "epoch 32; iter: 0; batch classifier loss: 0.609422\n",
      "epoch 33; iter: 0; batch classifier loss: 0.621774\n",
      "epoch 34; iter: 0; batch classifier loss: 0.513211\n",
      "epoch 35; iter: 0; batch classifier loss: 0.571019\n",
      "epoch 36; iter: 0; batch classifier loss: 0.568583\n",
      "epoch 37; iter: 0; batch classifier loss: 0.540349\n",
      "epoch 38; iter: 0; batch classifier loss: 0.614897\n",
      "epoch 39; iter: 0; batch classifier loss: 0.502850\n",
      "epoch 40; iter: 0; batch classifier loss: 0.533081\n",
      "epoch 41; iter: 0; batch classifier loss: 0.535304\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474974\n",
      "epoch 43; iter: 0; batch classifier loss: 0.516088\n",
      "epoch 44; iter: 0; batch classifier loss: 0.614522\n",
      "epoch 45; iter: 0; batch classifier loss: 0.590855\n",
      "epoch 46; iter: 0; batch classifier loss: 0.555944\n",
      "epoch 47; iter: 0; batch classifier loss: 0.507351\n",
      "epoch 48; iter: 0; batch classifier loss: 0.555043\n",
      "epoch 49; iter: 0; batch classifier loss: 0.558353\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.045484; batch classifier loss; 0.552733; batch adversarial loss: 0.585741\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.021681; batch classifier loss; 0.555337; batch adversarial loss: 0.550677\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.018748; batch classifier loss; 0.566872; batch adversarial loss: 0.574562\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.014022; batch classifier loss; 0.597711; batch adversarial loss: 0.561596\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.011754; batch classifier loss; 0.585295; batch adversarial loss: 0.570801\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.011988; batch classifier loss; 0.585387; batch adversarial loss: 0.581000\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.007459; batch classifier loss; 0.594025; batch adversarial loss: 0.573065\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.008508; batch classifier loss; 0.563881; batch adversarial loss: 0.598133\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.006813; batch classifier loss; 0.564470; batch adversarial loss: 0.563856\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.005821; batch classifier loss; 0.596130; batch adversarial loss: 0.555022\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.005556; batch classifier loss; 0.585784; batch adversarial loss: 0.535509\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.005779; batch classifier loss; 0.567385; batch adversarial loss: 0.562384\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.005065; batch classifier loss; 0.573607; batch adversarial loss: 0.552966\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.004826; batch classifier loss; 0.580986; batch adversarial loss: 0.528517\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.004242; batch classifier loss; 0.610877; batch adversarial loss: 0.582934\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.003807; batch classifier loss; 0.543395; batch adversarial loss: 0.530125\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.003106; batch classifier loss; 0.578905; batch adversarial loss: 0.528674\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.003708; batch classifier loss; 0.552090; batch adversarial loss: 0.556188\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.002945; batch classifier loss; 0.602186; batch adversarial loss: 0.532467\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.002687; batch classifier loss; 0.584013; batch adversarial loss: 0.509680\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.002663; batch classifier loss; 0.533526; batch adversarial loss: 0.545651\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.002868; batch classifier loss; 0.585278; batch adversarial loss: 0.525931\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.002078; batch classifier loss; 0.582560; batch adversarial loss: 0.519274\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.002005; batch classifier loss; 0.534325; batch adversarial loss: 0.536848\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.002148; batch classifier loss; 0.562006; batch adversarial loss: 0.495330\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.002272; batch classifier loss; 0.571251; batch adversarial loss: 0.531653\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.002606; batch classifier loss; 0.507664; batch adversarial loss: 0.501769\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.001956; batch classifier loss; 0.585480; batch adversarial loss: 0.527809\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.001329; batch classifier loss; 0.606693; batch adversarial loss: 0.518429\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.001898; batch classifier loss; 0.618775; batch adversarial loss: 0.530308\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.001830; batch classifier loss; 0.588984; batch adversarial loss: 0.523022\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.001906; batch classifier loss; 0.568133; batch adversarial loss: 0.528056\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.001714; batch classifier loss; 0.569606; batch adversarial loss: 0.478875\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.001655; batch classifier loss; 0.524557; batch adversarial loss: 0.502285\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.001621; batch classifier loss; 0.507436; batch adversarial loss: 0.487112\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.001436; batch classifier loss; 0.563616; batch adversarial loss: 0.520525\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.001364; batch classifier loss; 0.593965; batch adversarial loss: 0.493921\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.001908; batch classifier loss; 0.583754; batch adversarial loss: 0.534504\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.001479; batch classifier loss; 0.518233; batch adversarial loss: 0.451394\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.001392; batch classifier loss; 0.526616; batch adversarial loss: 0.461934\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.001374; batch classifier loss; 0.637658; batch adversarial loss: 0.483810\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.001688; batch classifier loss; 0.561656; batch adversarial loss: 0.461749\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.001233; batch classifier loss; 0.540562; batch adversarial loss: 0.502457\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.001134; batch classifier loss; 0.529160; batch adversarial loss: 0.486941\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.001578; batch classifier loss; 0.557437; batch adversarial loss: 0.522734\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.001268; batch classifier loss; 0.562818; batch adversarial loss: 0.484855\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.001565; batch classifier loss; 0.530050; batch adversarial loss: 0.467298\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.001489; batch classifier loss; 0.561472; batch adversarial loss: 0.486511\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.001470; batch classifier loss; 0.560037; batch adversarial loss: 0.490348\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001314; batch classifier loss; 0.562256; batch adversarial loss: 0.476546\n",
      "seed=2 || fold=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:35.223866: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.742093\n",
      "epoch 1; iter: 0; batch classifier loss: 0.699286\n",
      "epoch 2; iter: 0; batch classifier loss: 0.644794\n",
      "epoch 3; iter: 0; batch classifier loss: 0.621186\n",
      "epoch 4; iter: 0; batch classifier loss: 0.646580\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573500\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585660\n",
      "epoch 7; iter: 0; batch classifier loss: 0.650111\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532696\n",
      "epoch 9; iter: 0; batch classifier loss: 0.617772\n",
      "epoch 10; iter: 0; batch classifier loss: 0.566242\n",
      "epoch 11; iter: 0; batch classifier loss: 0.585642\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548266\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520972\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530274\n",
      "epoch 15; iter: 0; batch classifier loss: 0.568765\n",
      "epoch 16; iter: 0; batch classifier loss: 0.565460\n",
      "epoch 17; iter: 0; batch classifier loss: 0.576428\n",
      "epoch 18; iter: 0; batch classifier loss: 0.604432\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490801\n",
      "epoch 20; iter: 0; batch classifier loss: 0.542572\n",
      "epoch 21; iter: 0; batch classifier loss: 0.570084\n",
      "epoch 22; iter: 0; batch classifier loss: 0.540070\n",
      "epoch 23; iter: 0; batch classifier loss: 0.597886\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465947\n",
      "epoch 25; iter: 0; batch classifier loss: 0.586648\n",
      "epoch 26; iter: 0; batch classifier loss: 0.600298\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491223\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471216\n",
      "epoch 29; iter: 0; batch classifier loss: 0.564062\n",
      "epoch 30; iter: 0; batch classifier loss: 0.585768\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515510\n",
      "epoch 32; iter: 0; batch classifier loss: 0.535915\n",
      "epoch 33; iter: 0; batch classifier loss: 0.524533\n",
      "epoch 34; iter: 0; batch classifier loss: 0.614437\n",
      "epoch 35; iter: 0; batch classifier loss: 0.616829\n",
      "epoch 36; iter: 0; batch classifier loss: 0.500040\n",
      "epoch 37; iter: 0; batch classifier loss: 0.525539\n",
      "epoch 38; iter: 0; batch classifier loss: 0.507777\n",
      "epoch 39; iter: 0; batch classifier loss: 0.528561\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490959\n",
      "epoch 41; iter: 0; batch classifier loss: 0.541902\n",
      "epoch 42; iter: 0; batch classifier loss: 0.486887\n",
      "epoch 43; iter: 0; batch classifier loss: 0.606993\n",
      "epoch 44; iter: 0; batch classifier loss: 0.530312\n",
      "epoch 45; iter: 0; batch classifier loss: 0.509040\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491374\n",
      "epoch 47; iter: 0; batch classifier loss: 0.516349\n",
      "epoch 48; iter: 0; batch classifier loss: 0.556114\n",
      "epoch 49; iter: 0; batch classifier loss: 0.561494\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.060315; batch classifier loss; 0.598378; batch adversarial loss: 0.991850\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.034557; batch classifier loss; 0.543101; batch adversarial loss: 0.980201\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.034581; batch classifier loss; 0.594679; batch adversarial loss: 0.978183\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.018506; batch classifier loss; 0.564073; batch adversarial loss: 0.968838\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.016391; batch classifier loss; 0.547832; batch adversarial loss: 1.003844\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.017503; batch classifier loss; 0.527589; batch adversarial loss: 0.954534\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.013051; batch classifier loss; 0.544179; batch adversarial loss: 0.958414\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.015280; batch classifier loss; 0.547471; batch adversarial loss: 0.927251\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.010165; batch classifier loss; 0.533953; batch adversarial loss: 0.945058\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.011383; batch classifier loss; 0.587823; batch adversarial loss: 0.923499\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.012589; batch classifier loss; 0.523391; batch adversarial loss: 0.901378\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.010590; batch classifier loss; 0.547190; batch adversarial loss: 0.927968\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.014568; batch classifier loss; 0.543769; batch adversarial loss: 0.913721\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.012535; batch classifier loss; 0.529020; batch adversarial loss: 0.925339\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.013637; batch classifier loss; 0.572309; batch adversarial loss: 0.893780\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.012257; batch classifier loss; 0.548698; batch adversarial loss: 0.873775\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.012934; batch classifier loss; 0.541339; batch adversarial loss: 0.903777\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.014776; batch classifier loss; 0.488808; batch adversarial loss: 0.889898\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.012568; batch classifier loss; 0.593368; batch adversarial loss: 0.865306\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.013098; batch classifier loss; 0.628197; batch adversarial loss: 0.859539\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.012959; batch classifier loss; 0.571778; batch adversarial loss: 0.850980\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.011955; batch classifier loss; 0.587125; batch adversarial loss: 0.854491\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.012215; batch classifier loss; 0.495228; batch adversarial loss: 0.849139\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.014877; batch classifier loss; 0.489164; batch adversarial loss: 0.839235\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.014913; batch classifier loss; 0.540581; batch adversarial loss: 0.824035\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.013737; batch classifier loss; 0.557701; batch adversarial loss: 0.831567\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.013947; batch classifier loss; 0.507438; batch adversarial loss: 0.806221\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.014996; batch classifier loss; 0.561215; batch adversarial loss: 0.812115\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.013854; batch classifier loss; 0.578901; batch adversarial loss: 0.804465\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.011610; batch classifier loss; 0.508825; batch adversarial loss: 0.807303\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.012863; batch classifier loss; 0.559898; batch adversarial loss: 0.797236\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.014477; batch classifier loss; 0.563500; batch adversarial loss: 0.777129\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.013088; batch classifier loss; 0.553465; batch adversarial loss: 0.776224\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.013437; batch classifier loss; 0.548617; batch adversarial loss: 0.781320\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.013284; batch classifier loss; 0.507182; batch adversarial loss: 0.773452\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.014333; batch classifier loss; 0.556500; batch adversarial loss: 0.769050\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.013930; batch classifier loss; 0.457512; batch adversarial loss: 0.769544\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.013318; batch classifier loss; 0.535900; batch adversarial loss: 0.757550\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.014003; batch classifier loss; 0.559733; batch adversarial loss: 0.751499\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.015365; batch classifier loss; 0.554019; batch adversarial loss: 0.739181\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.012544; batch classifier loss; 0.483681; batch adversarial loss: 0.743064\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.013189; batch classifier loss; 0.556782; batch adversarial loss: 0.719226\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.012547; batch classifier loss; 0.566191; batch adversarial loss: 0.727215\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.012847; batch classifier loss; 0.585068; batch adversarial loss: 0.720594\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.013374; batch classifier loss; 0.635358; batch adversarial loss: 0.710054\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.013758; batch classifier loss; 0.588691; batch adversarial loss: 0.720563\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.012782; batch classifier loss; 0.542377; batch adversarial loss: 0.713002\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.013846; batch classifier loss; 0.600274; batch adversarial loss: 0.699366\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.011882; batch classifier loss; 0.561574; batch adversarial loss: 0.699331\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.011658; batch classifier loss; 0.530136; batch adversarial loss: 0.697413\n",
      "seed=2 || fold=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:36.653959: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.679497\n",
      "epoch 1; iter: 0; batch classifier loss: 0.688078\n",
      "epoch 2; iter: 0; batch classifier loss: 0.631717\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575718\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601481\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567577\n",
      "epoch 6; iter: 0; batch classifier loss: 0.624263\n",
      "epoch 7; iter: 0; batch classifier loss: 0.605118\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559473\n",
      "epoch 9; iter: 0; batch classifier loss: 0.597366\n",
      "epoch 10; iter: 0; batch classifier loss: 0.602829\n",
      "epoch 11; iter: 0; batch classifier loss: 0.611361\n",
      "epoch 12; iter: 0; batch classifier loss: 0.612723\n",
      "epoch 13; iter: 0; batch classifier loss: 0.582884\n",
      "epoch 14; iter: 0; batch classifier loss: 0.582446\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524828\n",
      "epoch 16; iter: 0; batch classifier loss: 0.546537\n",
      "epoch 17; iter: 0; batch classifier loss: 0.572329\n",
      "epoch 18; iter: 0; batch classifier loss: 0.640852\n",
      "epoch 19; iter: 0; batch classifier loss: 0.570687\n",
      "epoch 20; iter: 0; batch classifier loss: 0.610524\n",
      "epoch 21; iter: 0; batch classifier loss: 0.565324\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516326\n",
      "epoch 23; iter: 0; batch classifier loss: 0.517698\n",
      "epoch 24; iter: 0; batch classifier loss: 0.604958\n",
      "epoch 25; iter: 0; batch classifier loss: 0.634991\n",
      "epoch 26; iter: 0; batch classifier loss: 0.509034\n",
      "epoch 27; iter: 0; batch classifier loss: 0.529046\n",
      "epoch 28; iter: 0; batch classifier loss: 0.626179\n",
      "epoch 29; iter: 0; batch classifier loss: 0.601302\n",
      "epoch 30; iter: 0; batch classifier loss: 0.535534\n",
      "epoch 31; iter: 0; batch classifier loss: 0.624782\n",
      "epoch 32; iter: 0; batch classifier loss: 0.669380\n",
      "epoch 33; iter: 0; batch classifier loss: 0.616088\n",
      "epoch 34; iter: 0; batch classifier loss: 0.591222\n",
      "epoch 35; iter: 0; batch classifier loss: 0.561337\n",
      "epoch 36; iter: 0; batch classifier loss: 0.602694\n",
      "epoch 37; iter: 0; batch classifier loss: 0.633514\n",
      "epoch 38; iter: 0; batch classifier loss: 0.568672\n",
      "epoch 39; iter: 0; batch classifier loss: 0.515222\n",
      "epoch 40; iter: 0; batch classifier loss: 0.621212\n",
      "epoch 41; iter: 0; batch classifier loss: 0.590545\n",
      "epoch 42; iter: 0; batch classifier loss: 0.581893\n",
      "epoch 43; iter: 0; batch classifier loss: 0.504828\n",
      "epoch 44; iter: 0; batch classifier loss: 0.612623\n",
      "epoch 45; iter: 0; batch classifier loss: 0.527562\n",
      "epoch 46; iter: 0; batch classifier loss: 0.566688\n",
      "epoch 47; iter: 0; batch classifier loss: 0.543176\n",
      "epoch 48; iter: 0; batch classifier loss: 0.562314\n",
      "epoch 49; iter: 0; batch classifier loss: 0.603766\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.211305; batch classifier loss; 0.587070; batch adversarial loss: 0.544494\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.152475; batch classifier loss; 0.572939; batch adversarial loss: 0.546933\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.106248; batch classifier loss; 0.554813; batch adversarial loss: 0.550186\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.070559; batch classifier loss; 0.541105; batch adversarial loss: 0.518119\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.077156; batch classifier loss; 0.578355; batch adversarial loss: 0.526938\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.052186; batch classifier loss; 0.578927; batch adversarial loss: 0.516973\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.047042; batch classifier loss; 0.540517; batch adversarial loss: 0.511239\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.050115; batch classifier loss; 0.555448; batch adversarial loss: 0.525676\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.051913; batch classifier loss; 0.557672; batch adversarial loss: 0.500856\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.044273; batch classifier loss; 0.569138; batch adversarial loss: 0.511541\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.043850; batch classifier loss; 0.506914; batch adversarial loss: 0.495629\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.050134; batch classifier loss; 0.567244; batch adversarial loss: 0.525628\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.045808; batch classifier loss; 0.522698; batch adversarial loss: 0.509179\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.042778; batch classifier loss; 0.550118; batch adversarial loss: 0.485357\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.036833; batch classifier loss; 0.585669; batch adversarial loss: 0.508829\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.041598; batch classifier loss; 0.596814; batch adversarial loss: 0.475879\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.038638; batch classifier loss; 0.607441; batch adversarial loss: 0.517009\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.035449; batch classifier loss; 0.554803; batch adversarial loss: 0.507838\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.040054; batch classifier loss; 0.557007; batch adversarial loss: 0.559458\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.034950; batch classifier loss; 0.557302; batch adversarial loss: 0.469853\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.033828; batch classifier loss; 0.563807; batch adversarial loss: 0.501131\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.039580; batch classifier loss; 0.564799; batch adversarial loss: 0.538507\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.038871; batch classifier loss; 0.527797; batch adversarial loss: 0.525738\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.036288; batch classifier loss; 0.602043; batch adversarial loss: 0.521281\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.033564; batch classifier loss; 0.547336; batch adversarial loss: 0.522541\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.040001; batch classifier loss; 0.557011; batch adversarial loss: 0.504889\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.034364; batch classifier loss; 0.551791; batch adversarial loss: 0.458301\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.031979; batch classifier loss; 0.606329; batch adversarial loss: 0.480870\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.034204; batch classifier loss; 0.519702; batch adversarial loss: 0.480750\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.030639; batch classifier loss; 0.589743; batch adversarial loss: 0.464131\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.030421; batch classifier loss; 0.589823; batch adversarial loss: 0.428949\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.027262; batch classifier loss; 0.476423; batch adversarial loss: 0.457951\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.030702; batch classifier loss; 0.501634; batch adversarial loss: 0.493240\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.028762; batch classifier loss; 0.572386; batch adversarial loss: 0.444336\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.031536; batch classifier loss; 0.571797; batch adversarial loss: 0.484685\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.037350; batch classifier loss; 0.547767; batch adversarial loss: 0.485497\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.034046; batch classifier loss; 0.610960; batch adversarial loss: 0.495962\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.040230; batch classifier loss; 0.529043; batch adversarial loss: 0.467746\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.037808; batch classifier loss; 0.600513; batch adversarial loss: 0.537941\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.027595; batch classifier loss; 0.545030; batch adversarial loss: 0.442290\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.032792; batch classifier loss; 0.554117; batch adversarial loss: 0.464411\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.035381; batch classifier loss; 0.548895; batch adversarial loss: 0.438121\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.035174; batch classifier loss; 0.573762; batch adversarial loss: 0.465740\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.035073; batch classifier loss; 0.535369; batch adversarial loss: 0.484201\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.029476; batch classifier loss; 0.571178; batch adversarial loss: 0.431533\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.038373; batch classifier loss; 0.602937; batch adversarial loss: 0.532431\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.037492; batch classifier loss; 0.624132; batch adversarial loss: 0.542754\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.034909; batch classifier loss; 0.572569; batch adversarial loss: 0.500745\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.028135; batch classifier loss; 0.625461; batch adversarial loss: 0.443229\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.039767; batch classifier loss; 0.590696; batch adversarial loss: 0.501246\n",
      "\n",
      "Seed 4/5\n",
      "seed=3 || fold=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:38.187842: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.693959\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637790\n",
      "epoch 2; iter: 0; batch classifier loss: 0.627027\n",
      "epoch 3; iter: 0; batch classifier loss: 0.597310\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597737\n",
      "epoch 5; iter: 0; batch classifier loss: 0.631152\n",
      "epoch 6; iter: 0; batch classifier loss: 0.614593\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574422\n",
      "epoch 8; iter: 0; batch classifier loss: 0.632783\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558759\n",
      "epoch 10; iter: 0; batch classifier loss: 0.640878\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552619\n",
      "epoch 12; iter: 0; batch classifier loss: 0.546336\n",
      "epoch 13; iter: 0; batch classifier loss: 0.545189\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554771\n",
      "epoch 15; iter: 0; batch classifier loss: 0.562557\n",
      "epoch 16; iter: 0; batch classifier loss: 0.579217\n",
      "epoch 17; iter: 0; batch classifier loss: 0.560309\n",
      "epoch 18; iter: 0; batch classifier loss: 0.537801\n",
      "epoch 19; iter: 0; batch classifier loss: 0.574695\n",
      "epoch 20; iter: 0; batch classifier loss: 0.564300\n",
      "epoch 21; iter: 0; batch classifier loss: 0.570006\n",
      "epoch 22; iter: 0; batch classifier loss: 0.584245\n",
      "epoch 23; iter: 0; batch classifier loss: 0.600133\n",
      "epoch 24; iter: 0; batch classifier loss: 0.594715\n",
      "epoch 25; iter: 0; batch classifier loss: 0.573999\n",
      "epoch 26; iter: 0; batch classifier loss: 0.529343\n",
      "epoch 27; iter: 0; batch classifier loss: 0.534021\n",
      "epoch 28; iter: 0; batch classifier loss: 0.509740\n",
      "epoch 29; iter: 0; batch classifier loss: 0.536456\n",
      "epoch 30; iter: 0; batch classifier loss: 0.517154\n",
      "epoch 31; iter: 0; batch classifier loss: 0.622492\n",
      "epoch 32; iter: 0; batch classifier loss: 0.580454\n",
      "epoch 33; iter: 0; batch classifier loss: 0.526925\n",
      "epoch 34; iter: 0; batch classifier loss: 0.563421\n",
      "epoch 35; iter: 0; batch classifier loss: 0.573366\n",
      "epoch 36; iter: 0; batch classifier loss: 0.603998\n",
      "epoch 37; iter: 0; batch classifier loss: 0.506064\n",
      "epoch 38; iter: 0; batch classifier loss: 0.553907\n",
      "epoch 39; iter: 0; batch classifier loss: 0.538822\n",
      "epoch 40; iter: 0; batch classifier loss: 0.527752\n",
      "epoch 41; iter: 0; batch classifier loss: 0.525926\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483481\n",
      "epoch 43; iter: 0; batch classifier loss: 0.522266\n",
      "epoch 44; iter: 0; batch classifier loss: 0.510800\n",
      "epoch 45; iter: 0; batch classifier loss: 0.520054\n",
      "epoch 46; iter: 0; batch classifier loss: 0.545292\n",
      "epoch 47; iter: 0; batch classifier loss: 0.516779\n",
      "epoch 48; iter: 0; batch classifier loss: 0.506833\n",
      "epoch 49; iter: 0; batch classifier loss: 0.618503\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.039762; batch classifier loss; 0.550760; batch adversarial loss: 0.790419\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.024940; batch classifier loss; 0.559583; batch adversarial loss: 0.790134\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.022468; batch classifier loss; 0.557640; batch adversarial loss: 0.785787\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.015444; batch classifier loss; 0.524894; batch adversarial loss: 0.755545\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.015333; batch classifier loss; 0.568828; batch adversarial loss: 0.782591\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.017001; batch classifier loss; 0.573226; batch adversarial loss: 0.758515\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.013125; batch classifier loss; 0.610855; batch adversarial loss: 0.762358\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.010702; batch classifier loss; 0.570542; batch adversarial loss: 0.760922\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.008048; batch classifier loss; 0.563025; batch adversarial loss: 0.757482\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.008899; batch classifier loss; 0.502127; batch adversarial loss: 0.709686\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.006802; batch classifier loss; 0.569024; batch adversarial loss: 0.738579\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.007090; batch classifier loss; 0.563331; batch adversarial loss: 0.740595\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.006178; batch classifier loss; 0.622865; batch adversarial loss: 0.744614\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.005474; batch classifier loss; 0.522982; batch adversarial loss: 0.714883\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.005087; batch classifier loss; 0.622827; batch adversarial loss: 0.731469\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.005138; batch classifier loss; 0.512530; batch adversarial loss: 0.705794\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.004591; batch classifier loss; 0.568353; batch adversarial loss: 0.710179\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.003844; batch classifier loss; 0.563108; batch adversarial loss: 0.704845\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.003396; batch classifier loss; 0.530031; batch adversarial loss: 0.699748\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.002937; batch classifier loss; 0.535485; batch adversarial loss: 0.690679\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.002259; batch classifier loss; 0.526716; batch adversarial loss: 0.681087\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.002471; batch classifier loss; 0.530866; batch adversarial loss: 0.678168\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.002198; batch classifier loss; 0.577756; batch adversarial loss: 0.673119\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.002102; batch classifier loss; 0.602951; batch adversarial loss: 0.686225\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.001742; batch classifier loss; 0.517385; batch adversarial loss: 0.666293\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.001607; batch classifier loss; 0.583395; batch adversarial loss: 0.677438\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.001592; batch classifier loss; 0.647949; batch adversarial loss: 0.682166\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.001236; batch classifier loss; 0.595309; batch adversarial loss: 0.655931\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.001346; batch classifier loss; 0.548134; batch adversarial loss: 0.657274\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.001684; batch classifier loss; 0.510425; batch adversarial loss: 0.643321\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.001625; batch classifier loss; 0.566693; batch adversarial loss: 0.650129\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.001033; batch classifier loss; 0.592978; batch adversarial loss: 0.649607\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.001026; batch classifier loss; 0.535568; batch adversarial loss: 0.630050\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.001235; batch classifier loss; 0.569909; batch adversarial loss: 0.641545\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.001175; batch classifier loss; 0.594755; batch adversarial loss: 0.645064\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.001123; batch classifier loss; 0.505860; batch adversarial loss: 0.611703\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.001179; batch classifier loss; 0.546862; batch adversarial loss: 0.627112\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.000834; batch classifier loss; 0.564805; batch adversarial loss: 0.618757\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.000960; batch classifier loss; 0.577469; batch adversarial loss: 0.631172\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.000673; batch classifier loss; 0.506689; batch adversarial loss: 0.587704\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.001220; batch classifier loss; 0.573140; batch adversarial loss: 0.613247\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.000783; batch classifier loss; 0.521020; batch adversarial loss: 0.593846\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.000773; batch classifier loss; 0.589505; batch adversarial loss: 0.604981\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.000797; batch classifier loss; 0.549010; batch adversarial loss: 0.608693\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.000849; batch classifier loss; 0.534115; batch adversarial loss: 0.578431\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.000904; batch classifier loss; 0.570500; batch adversarial loss: 0.601013\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.000694; batch classifier loss; 0.591370; batch adversarial loss: 0.596432\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.000644; batch classifier loss; 0.527667; batch adversarial loss: 0.595228\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.000743; batch classifier loss; 0.572708; batch adversarial loss: 0.588633\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.000491; batch classifier loss; 0.575113; batch adversarial loss: 0.571992\n",
      "seed=3 || fold=1\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:39.565709: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 0; batch classifier loss: 0.680321\n",
      "epoch 2; iter: 0; batch classifier loss: 0.668551\n",
      "epoch 3; iter: 0; batch classifier loss: 0.636094\n",
      "epoch 4; iter: 0; batch classifier loss: 0.654149\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586796\n",
      "epoch 6; iter: 0; batch classifier loss: 0.616515\n",
      "epoch 7; iter: 0; batch classifier loss: 0.619128\n",
      "epoch 8; iter: 0; batch classifier loss: 0.601606\n",
      "epoch 9; iter: 0; batch classifier loss: 0.622239\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581630\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490657\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547477\n",
      "epoch 13; iter: 0; batch classifier loss: 0.621474\n",
      "epoch 14; iter: 0; batch classifier loss: 0.564470\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555572\n",
      "epoch 16; iter: 0; batch classifier loss: 0.538640\n",
      "epoch 17; iter: 0; batch classifier loss: 0.603347\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555053\n",
      "epoch 19; iter: 0; batch classifier loss: 0.567396\n",
      "epoch 20; iter: 0; batch classifier loss: 0.556528\n",
      "epoch 21; iter: 0; batch classifier loss: 0.583709\n",
      "epoch 22; iter: 0; batch classifier loss: 0.602186\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525453\n",
      "epoch 24; iter: 0; batch classifier loss: 0.565641\n",
      "epoch 25; iter: 0; batch classifier loss: 0.589939\n",
      "epoch 26; iter: 0; batch classifier loss: 0.584921\n",
      "epoch 27; iter: 0; batch classifier loss: 0.602704\n",
      "epoch 28; iter: 0; batch classifier loss: 0.541373\n",
      "epoch 29; iter: 0; batch classifier loss: 0.579916\n",
      "epoch 30; iter: 0; batch classifier loss: 0.535990\n",
      "epoch 31; iter: 0; batch classifier loss: 0.595808\n",
      "epoch 32; iter: 0; batch classifier loss: 0.561556\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475538\n",
      "epoch 34; iter: 0; batch classifier loss: 0.550112\n",
      "epoch 35; iter: 0; batch classifier loss: 0.540671\n",
      "epoch 36; iter: 0; batch classifier loss: 0.565155\n",
      "epoch 37; iter: 0; batch classifier loss: 0.600350\n",
      "epoch 38; iter: 0; batch classifier loss: 0.584595\n",
      "epoch 39; iter: 0; batch classifier loss: 0.600926\n",
      "epoch 40; iter: 0; batch classifier loss: 0.550600\n",
      "epoch 41; iter: 0; batch classifier loss: 0.556934\n",
      "epoch 42; iter: 0; batch classifier loss: 0.543935\n",
      "epoch 43; iter: 0; batch classifier loss: 0.537464\n",
      "epoch 44; iter: 0; batch classifier loss: 0.590424\n",
      "epoch 45; iter: 0; batch classifier loss: 0.561597\n",
      "epoch 46; iter: 0; batch classifier loss: 0.539236\n",
      "epoch 47; iter: 0; batch classifier loss: 0.565823\n",
      "epoch 48; iter: 0; batch classifier loss: 0.536058\n",
      "epoch 49; iter: 0; batch classifier loss: 0.695007\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.034614; batch classifier loss; 0.592995; batch adversarial loss: 0.700729\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.031713; batch classifier loss; 0.540486; batch adversarial loss: 0.692866\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.020785; batch classifier loss; 0.601760; batch adversarial loss: 0.693508\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.016002; batch classifier loss; 0.564136; batch adversarial loss: 0.681766\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.015082; batch classifier loss; 0.591023; batch adversarial loss: 0.675642\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.010714; batch classifier loss; 0.596124; batch adversarial loss: 0.674312\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.011620; batch classifier loss; 0.639907; batch adversarial loss: 0.675168\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.012272; batch classifier loss; 0.638677; batch adversarial loss: 0.662520\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.010989; batch classifier loss; 0.550410; batch adversarial loss: 0.653274\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.007109; batch classifier loss; 0.529601; batch adversarial loss: 0.656186\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.008114; batch classifier loss; 0.586425; batch adversarial loss: 0.642499\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.005578; batch classifier loss; 0.584624; batch adversarial loss: 0.649409\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.005209; batch classifier loss; 0.582486; batch adversarial loss: 0.647632\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.006658; batch classifier loss; 0.557354; batch adversarial loss: 0.636539\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.005865; batch classifier loss; 0.661714; batch adversarial loss: 0.652422\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.004980; batch classifier loss; 0.598827; batch adversarial loss: 0.629011\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.004857; batch classifier loss; 0.587982; batch adversarial loss: 0.630816\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.003673; batch classifier loss; 0.530353; batch adversarial loss: 0.612959\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.004022; batch classifier loss; 0.534418; batch adversarial loss: 0.598700\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.004613; batch classifier loss; 0.555813; batch adversarial loss: 0.631257\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.003824; batch classifier loss; 0.537469; batch adversarial loss: 0.598126\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.003889; batch classifier loss; 0.514648; batch adversarial loss: 0.608889\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.002623; batch classifier loss; 0.573177; batch adversarial loss: 0.593068\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.003715; batch classifier loss; 0.582620; batch adversarial loss: 0.607370\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.003147; batch classifier loss; 0.515083; batch adversarial loss: 0.602598\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.002879; batch classifier loss; 0.554622; batch adversarial loss: 0.582591\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.003237; batch classifier loss; 0.500521; batch adversarial loss: 0.589939\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.003321; batch classifier loss; 0.562631; batch adversarial loss: 0.568917\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.002907; batch classifier loss; 0.604545; batch adversarial loss: 0.599595\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.002698; batch classifier loss; 0.551730; batch adversarial loss: 0.557966\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.003243; batch classifier loss; 0.571472; batch adversarial loss: 0.599438\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.003012; batch classifier loss; 0.566672; batch adversarial loss: 0.571074\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.002914; batch classifier loss; 0.504267; batch adversarial loss: 0.571846\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.002612; batch classifier loss; 0.567146; batch adversarial loss: 0.563040\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.003489; batch classifier loss; 0.590643; batch adversarial loss: 0.567830\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.002973; batch classifier loss; 0.614290; batch adversarial loss: 0.580580\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.003187; batch classifier loss; 0.566614; batch adversarial loss: 0.553994\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.003568; batch classifier loss; 0.583461; batch adversarial loss: 0.566240\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.003066; batch classifier loss; 0.576134; batch adversarial loss: 0.574427\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.003610; batch classifier loss; 0.557061; batch adversarial loss: 0.554868\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.003349; batch classifier loss; 0.485302; batch adversarial loss: 0.550036\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.003048; batch classifier loss; 0.583570; batch adversarial loss: 0.532275\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.003560; batch classifier loss; 0.539960; batch adversarial loss: 0.559099\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.002769; batch classifier loss; 0.599177; batch adversarial loss: 0.557562\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.003441; batch classifier loss; 0.514877; batch adversarial loss: 0.526843\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.002902; batch classifier loss; 0.582095; batch adversarial loss: 0.549893\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.003543; batch classifier loss; 0.547490; batch adversarial loss: 0.571782\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.003237; batch classifier loss; 0.589602; batch adversarial loss: 0.534646\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.002904; batch classifier loss; 0.582230; batch adversarial loss: 0.519864\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.003152; batch classifier loss; 0.542399; batch adversarial loss: 0.472924\n",
      "seed=3 || fold=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:40.992960: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.771593\n",
      "epoch 1; iter: 0; batch classifier loss: 0.700633\n",
      "epoch 2; iter: 0; batch classifier loss: 0.676344\n",
      "epoch 3; iter: 0; batch classifier loss: 0.635292\n",
      "epoch 4; iter: 0; batch classifier loss: 0.644149\n",
      "epoch 5; iter: 0; batch classifier loss: 0.623557\n",
      "epoch 6; iter: 0; batch classifier loss: 0.638822\n",
      "epoch 7; iter: 0; batch classifier loss: 0.642467\n",
      "epoch 8; iter: 0; batch classifier loss: 0.609582\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557431\n",
      "epoch 10; iter: 0; batch classifier loss: 0.605180\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591017\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558830\n",
      "epoch 13; iter: 0; batch classifier loss: 0.580865\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544582\n",
      "epoch 15; iter: 0; batch classifier loss: 0.553630\n",
      "epoch 16; iter: 0; batch classifier loss: 0.583015\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550748\n",
      "epoch 18; iter: 0; batch classifier loss: 0.608197\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541596\n",
      "epoch 20; iter: 0; batch classifier loss: 0.603629\n",
      "epoch 21; iter: 0; batch classifier loss: 0.584308\n",
      "epoch 22; iter: 0; batch classifier loss: 0.497773\n",
      "epoch 23; iter: 0; batch classifier loss: 0.582535\n",
      "epoch 24; iter: 0; batch classifier loss: 0.595143\n",
      "epoch 25; iter: 0; batch classifier loss: 0.576462\n",
      "epoch 26; iter: 0; batch classifier loss: 0.615183\n",
      "epoch 27; iter: 0; batch classifier loss: 0.586724\n",
      "epoch 28; iter: 0; batch classifier loss: 0.542814\n",
      "epoch 29; iter: 0; batch classifier loss: 0.568623\n",
      "epoch 30; iter: 0; batch classifier loss: 0.561970\n",
      "epoch 31; iter: 0; batch classifier loss: 0.609787\n",
      "epoch 32; iter: 0; batch classifier loss: 0.608484\n",
      "epoch 33; iter: 0; batch classifier loss: 0.575744\n",
      "epoch 34; iter: 0; batch classifier loss: 0.640369\n",
      "epoch 35; iter: 0; batch classifier loss: 0.558826\n",
      "epoch 36; iter: 0; batch classifier loss: 0.540450\n",
      "epoch 37; iter: 0; batch classifier loss: 0.567986\n",
      "epoch 38; iter: 0; batch classifier loss: 0.532496\n",
      "epoch 39; iter: 0; batch classifier loss: 0.668504\n",
      "epoch 40; iter: 0; batch classifier loss: 0.569840\n",
      "epoch 41; iter: 0; batch classifier loss: 0.562788\n",
      "epoch 42; iter: 0; batch classifier loss: 0.584647\n",
      "epoch 43; iter: 0; batch classifier loss: 0.537324\n",
      "epoch 44; iter: 0; batch classifier loss: 0.525910\n",
      "epoch 45; iter: 0; batch classifier loss: 0.678206\n",
      "epoch 46; iter: 0; batch classifier loss: 0.544179\n",
      "epoch 47; iter: 0; batch classifier loss: 0.588928\n",
      "epoch 48; iter: 0; batch classifier loss: 0.603446\n",
      "epoch 49; iter: 0; batch classifier loss: 0.504776\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.055507; batch classifier loss; 0.662150; batch adversarial loss: 1.003553\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.043548; batch classifier loss; 0.561410; batch adversarial loss: 1.085622\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.034458; batch classifier loss; 0.533194; batch adversarial loss: 1.037601\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.035964; batch classifier loss; 0.565202; batch adversarial loss: 1.014588\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.027678; batch classifier loss; 0.638974; batch adversarial loss: 0.991500\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.025166; batch classifier loss; 0.633619; batch adversarial loss: 0.998986\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.025039; batch classifier loss; 0.593597; batch adversarial loss: 1.008695\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.020124; batch classifier loss; 0.607125; batch adversarial loss: 0.991237\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.024932; batch classifier loss; 0.595469; batch adversarial loss: 0.965983\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.018658; batch classifier loss; 0.619857; batch adversarial loss: 0.949228\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.021765; batch classifier loss; 0.615200; batch adversarial loss: 0.955790\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.016303; batch classifier loss; 0.552898; batch adversarial loss: 0.997091\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.017782; batch classifier loss; 0.541599; batch adversarial loss: 0.987407\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.016747; batch classifier loss; 0.572736; batch adversarial loss: 0.916865\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.013204; batch classifier loss; 0.538231; batch adversarial loss: 0.984678\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.013806; batch classifier loss; 0.591429; batch adversarial loss: 0.954720\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.013736; batch classifier loss; 0.565565; batch adversarial loss: 0.953998\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.010772; batch classifier loss; 0.574841; batch adversarial loss: 0.896617\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.010690; batch classifier loss; 0.530752; batch adversarial loss: 0.941000\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.010189; batch classifier loss; 0.583040; batch adversarial loss: 0.932605\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.008164; batch classifier loss; 0.548477; batch adversarial loss: 0.927201\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.008169; batch classifier loss; 0.602680; batch adversarial loss: 0.870404\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.007849; batch classifier loss; 0.491438; batch adversarial loss: 0.937356\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.006025; batch classifier loss; 0.578657; batch adversarial loss: 0.874297\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.005772; batch classifier loss; 0.557792; batch adversarial loss: 0.888592\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.005196; batch classifier loss; 0.548076; batch adversarial loss: 0.895248\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.006393; batch classifier loss; 0.595479; batch adversarial loss: 0.859591\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.005634; batch classifier loss; 0.618755; batch adversarial loss: 0.830024\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.004103; batch classifier loss; 0.547352; batch adversarial loss: 0.873629\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.004402; batch classifier loss; 0.617532; batch adversarial loss: 0.842543\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.004452; batch classifier loss; 0.611571; batch adversarial loss: 0.827897\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.003867; batch classifier loss; 0.551417; batch adversarial loss: 0.853109\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.003642; batch classifier loss; 0.565471; batch adversarial loss: 0.830199\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.003448; batch classifier loss; 0.619715; batch adversarial loss: 0.793196\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.002578; batch classifier loss; 0.566724; batch adversarial loss: 0.836330\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.003184; batch classifier loss; 0.546941; batch adversarial loss: 0.806239\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.002291; batch classifier loss; 0.590176; batch adversarial loss: 0.798764\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.002449; batch classifier loss; 0.511277; batch adversarial loss: 0.836608\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.002766; batch classifier loss; 0.562965; batch adversarial loss: 0.787635\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.002171; batch classifier loss; 0.602082; batch adversarial loss: 0.782411\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.001975; batch classifier loss; 0.584210; batch adversarial loss: 0.815539\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.001846; batch classifier loss; 0.604519; batch adversarial loss: 0.758626\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.001925; batch classifier loss; 0.606832; batch adversarial loss: 0.761956\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.001719; batch classifier loss; 0.555554; batch adversarial loss: 0.789467\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.002321; batch classifier loss; 0.498957; batch adversarial loss: 0.807928\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.001935; batch classifier loss; 0.577652; batch adversarial loss: 0.754345\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.001297; batch classifier loss; 0.606217; batch adversarial loss: 0.756323\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.001640; batch classifier loss; 0.542363; batch adversarial loss: 0.753091\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.001328; batch classifier loss; 0.614934; batch adversarial loss: 0.737878\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001553; batch classifier loss; 0.572322; batch adversarial loss: 0.739866\n",
      "seed=3 || fold=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:42.438632: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.713544\n",
      "epoch 1; iter: 0; batch classifier loss: 0.654022\n",
      "epoch 2; iter: 0; batch classifier loss: 0.654225\n",
      "epoch 3; iter: 0; batch classifier loss: 0.619038\n",
      "epoch 4; iter: 0; batch classifier loss: 0.625619\n",
      "epoch 5; iter: 0; batch classifier loss: 0.603317\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580367\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586231\n",
      "epoch 8; iter: 0; batch classifier loss: 0.621905\n",
      "epoch 9; iter: 0; batch classifier loss: 0.612739\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535507\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546310\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598381\n",
      "epoch 13; iter: 0; batch classifier loss: 0.576305\n",
      "epoch 14; iter: 0; batch classifier loss: 0.600446\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519483\n",
      "epoch 16; iter: 0; batch classifier loss: 0.573895\n",
      "epoch 17; iter: 0; batch classifier loss: 0.580744\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513817\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542872\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493268\n",
      "epoch 21; iter: 0; batch classifier loss: 0.571546\n",
      "epoch 22; iter: 0; batch classifier loss: 0.559623\n",
      "epoch 23; iter: 0; batch classifier loss: 0.527618\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505400\n",
      "epoch 25; iter: 0; batch classifier loss: 0.595560\n",
      "epoch 26; iter: 0; batch classifier loss: 0.573375\n",
      "epoch 27; iter: 0; batch classifier loss: 0.520470\n",
      "epoch 28; iter: 0; batch classifier loss: 0.574118\n",
      "epoch 29; iter: 0; batch classifier loss: 0.619845\n",
      "epoch 30; iter: 0; batch classifier loss: 0.547458\n",
      "epoch 31; iter: 0; batch classifier loss: 0.568989\n",
      "epoch 32; iter: 0; batch classifier loss: 0.594474\n",
      "epoch 33; iter: 0; batch classifier loss: 0.585016\n",
      "epoch 34; iter: 0; batch classifier loss: 0.536991\n",
      "epoch 35; iter: 0; batch classifier loss: 0.564414\n",
      "epoch 36; iter: 0; batch classifier loss: 0.525753\n",
      "epoch 37; iter: 0; batch classifier loss: 0.526966\n",
      "epoch 38; iter: 0; batch classifier loss: 0.545981\n",
      "epoch 39; iter: 0; batch classifier loss: 0.590642\n",
      "epoch 40; iter: 0; batch classifier loss: 0.517808\n",
      "epoch 41; iter: 0; batch classifier loss: 0.580225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.572881\n",
      "epoch 43; iter: 0; batch classifier loss: 0.504896\n",
      "epoch 44; iter: 0; batch classifier loss: 0.569148\n",
      "epoch 45; iter: 0; batch classifier loss: 0.525701\n",
      "epoch 46; iter: 0; batch classifier loss: 0.596751\n",
      "epoch 47; iter: 0; batch classifier loss: 0.577573\n",
      "epoch 48; iter: 0; batch classifier loss: 0.593890\n",
      "epoch 49; iter: 0; batch classifier loss: 0.598641\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.090752; batch classifier loss; 0.575591; batch adversarial loss: 0.617428\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.040386; batch classifier loss; 0.572187; batch adversarial loss: 0.623746\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.029573; batch classifier loss; 0.559984; batch adversarial loss: 0.604028\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.026847; batch classifier loss; 0.629472; batch adversarial loss: 0.601919\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.019770; batch classifier loss; 0.634503; batch adversarial loss: 0.614510\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.024368; batch classifier loss; 0.567797; batch adversarial loss: 0.597494\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.020329; batch classifier loss; 0.530475; batch adversarial loss: 0.586076\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.019286; batch classifier loss; 0.571143; batch adversarial loss: 0.589427\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.017454; batch classifier loss; 0.531805; batch adversarial loss: 0.589845\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.012390; batch classifier loss; 0.514606; batch adversarial loss: 0.565947\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.014535; batch classifier loss; 0.627987; batch adversarial loss: 0.603995\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.015058; batch classifier loss; 0.603531; batch adversarial loss: 0.595209\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.010725; batch classifier loss; 0.534829; batch adversarial loss: 0.550466\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.011936; batch classifier loss; 0.575192; batch adversarial loss: 0.569248\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.010809; batch classifier loss; 0.534535; batch adversarial loss: 0.564201\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.009455; batch classifier loss; 0.546432; batch adversarial loss: 0.575999\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.011455; batch classifier loss; 0.595699; batch adversarial loss: 0.542340\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.008185; batch classifier loss; 0.537941; batch adversarial loss: 0.546904\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.007599; batch classifier loss; 0.574212; batch adversarial loss: 0.555001\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.006265; batch classifier loss; 0.519214; batch adversarial loss: 0.554402\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.008932; batch classifier loss; 0.570707; batch adversarial loss: 0.558105\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.007429; batch classifier loss; 0.551757; batch adversarial loss: 0.564547\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.004835; batch classifier loss; 0.539087; batch adversarial loss: 0.569509\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.006446; batch classifier loss; 0.560882; batch adversarial loss: 0.539472\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.005643; batch classifier loss; 0.543993; batch adversarial loss: 0.528346\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.004935; batch classifier loss; 0.577628; batch adversarial loss: 0.531730\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.004682; batch classifier loss; 0.568358; batch adversarial loss: 0.532442\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.005282; batch classifier loss; 0.574841; batch adversarial loss: 0.577662\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.004704; batch classifier loss; 0.523668; batch adversarial loss: 0.490875\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.005164; batch classifier loss; 0.577695; batch adversarial loss: 0.562621\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.004183; batch classifier loss; 0.547158; batch adversarial loss: 0.520223\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.004072; batch classifier loss; 0.621394; batch adversarial loss: 0.494167\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.004228; batch classifier loss; 0.650253; batch adversarial loss: 0.548969\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.002804; batch classifier loss; 0.555410; batch adversarial loss: 0.536859\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.004318; batch classifier loss; 0.533488; batch adversarial loss: 0.518462\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.004827; batch classifier loss; 0.535326; batch adversarial loss: 0.535879\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.002639; batch classifier loss; 0.564994; batch adversarial loss: 0.531956\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.002505; batch classifier loss; 0.526837; batch adversarial loss: 0.473320\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.003871; batch classifier loss; 0.551326; batch adversarial loss: 0.524706\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.002734; batch classifier loss; 0.658227; batch adversarial loss: 0.560991\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.003141; batch classifier loss; 0.548472; batch adversarial loss: 0.527816\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.003445; batch classifier loss; 0.538229; batch adversarial loss: 0.500783\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.003029; batch classifier loss; 0.553566; batch adversarial loss: 0.520014\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.002614; batch classifier loss; 0.537483; batch adversarial loss: 0.482552\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.002452; batch classifier loss; 0.538736; batch adversarial loss: 0.479229\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.002842; batch classifier loss; 0.450590; batch adversarial loss: 0.475772\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.001633; batch classifier loss; 0.559554; batch adversarial loss: 0.481092\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.002704; batch classifier loss; 0.555907; batch adversarial loss: 0.496189\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.002658; batch classifier loss; 0.607110; batch adversarial loss: 0.470589\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001912; batch classifier loss; 0.441868; batch adversarial loss: 0.492343\n",
      "seed=3 || fold=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:43.843532: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.655868\n",
      "epoch 1; iter: 0; batch classifier loss: 0.631455\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591623\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559770\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574963\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607730\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523620\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595807\n",
      "epoch 8; iter: 0; batch classifier loss: 0.509427\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527996\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515370\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521104\n",
      "epoch 12; iter: 0; batch classifier loss: 0.624536\n",
      "epoch 13; iter: 0; batch classifier loss: 0.620862\n",
      "epoch 14; iter: 0; batch classifier loss: 0.568325\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485882\n",
      "epoch 16; iter: 0; batch classifier loss: 0.564419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515778\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496898\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537824\n",
      "epoch 20; iter: 0; batch classifier loss: 0.560653\n",
      "epoch 21; iter: 0; batch classifier loss: 0.564735\n",
      "epoch 22; iter: 0; batch classifier loss: 0.609086\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451104\n",
      "epoch 24; iter: 0; batch classifier loss: 0.573195\n",
      "epoch 25; iter: 0; batch classifier loss: 0.587705\n",
      "epoch 26; iter: 0; batch classifier loss: 0.564612\n",
      "epoch 27; iter: 0; batch classifier loss: 0.558774\n",
      "epoch 28; iter: 0; batch classifier loss: 0.634638\n",
      "epoch 29; iter: 0; batch classifier loss: 0.561818\n",
      "epoch 30; iter: 0; batch classifier loss: 0.557280\n",
      "epoch 31; iter: 0; batch classifier loss: 0.596344\n",
      "epoch 32; iter: 0; batch classifier loss: 0.532998\n",
      "epoch 33; iter: 0; batch classifier loss: 0.562901\n",
      "epoch 34; iter: 0; batch classifier loss: 0.568166\n",
      "epoch 35; iter: 0; batch classifier loss: 0.555347\n",
      "epoch 36; iter: 0; batch classifier loss: 0.565291\n",
      "epoch 37; iter: 0; batch classifier loss: 0.504352\n",
      "epoch 38; iter: 0; batch classifier loss: 0.506623\n",
      "epoch 39; iter: 0; batch classifier loss: 0.592174\n",
      "epoch 40; iter: 0; batch classifier loss: 0.604607\n",
      "epoch 41; iter: 0; batch classifier loss: 0.514458\n",
      "epoch 42; iter: 0; batch classifier loss: 0.540229\n",
      "epoch 43; iter: 0; batch classifier loss: 0.521678\n",
      "epoch 44; iter: 0; batch classifier loss: 0.565152\n",
      "epoch 45; iter: 0; batch classifier loss: 0.560638\n",
      "epoch 46; iter: 0; batch classifier loss: 0.604328\n",
      "epoch 47; iter: 0; batch classifier loss: 0.550795\n",
      "epoch 48; iter: 0; batch classifier loss: 0.585943\n",
      "epoch 49; iter: 0; batch classifier loss: 0.566272\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.061300; batch classifier loss; 0.593765; batch adversarial loss: 0.470658\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.039925; batch classifier loss; 0.561026; batch adversarial loss: 0.458373\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.035409; batch classifier loss; 0.526989; batch adversarial loss: 0.500519\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.026948; batch classifier loss; 0.536156; batch adversarial loss: 0.526442\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.027999; batch classifier loss; 0.546892; batch adversarial loss: 0.507278\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.029147; batch classifier loss; 0.509505; batch adversarial loss: 0.515090\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.023205; batch classifier loss; 0.578252; batch adversarial loss: 0.528303\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.023332; batch classifier loss; 0.536114; batch adversarial loss: 0.598989\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.018368; batch classifier loss; 0.575898; batch adversarial loss: 0.415119\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.020667; batch classifier loss; 0.463635; batch adversarial loss: 0.532657\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.014451; batch classifier loss; 0.525051; batch adversarial loss: 0.483464\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.012258; batch classifier loss; 0.556520; batch adversarial loss: 0.410805\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.015827; batch classifier loss; 0.569312; batch adversarial loss: 0.478506\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.015085; batch classifier loss; 0.489992; batch adversarial loss: 0.499148\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.013595; batch classifier loss; 0.547023; batch adversarial loss: 0.532722\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.015405; batch classifier loss; 0.562963; batch adversarial loss: 0.495119\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.014176; batch classifier loss; 0.559495; batch adversarial loss: 0.492353\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.010049; batch classifier loss; 0.514172; batch adversarial loss: 0.515560\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.012032; batch classifier loss; 0.613169; batch adversarial loss: 0.486190\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.011136; batch classifier loss; 0.542874; batch adversarial loss: 0.519988\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.012044; batch classifier loss; 0.557104; batch adversarial loss: 0.498221\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.011634; batch classifier loss; 0.522023; batch adversarial loss: 0.490057\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.012851; batch classifier loss; 0.517574; batch adversarial loss: 0.566638\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.008929; batch classifier loss; 0.592082; batch adversarial loss: 0.461390\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.009216; batch classifier loss; 0.581521; batch adversarial loss: 0.507727\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.009942; batch classifier loss; 0.561772; batch adversarial loss: 0.517416\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.007031; batch classifier loss; 0.573144; batch adversarial loss: 0.448395\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.010569; batch classifier loss; 0.562973; batch adversarial loss: 0.529715\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.008230; batch classifier loss; 0.527231; batch adversarial loss: 0.472675\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.007917; batch classifier loss; 0.523018; batch adversarial loss: 0.497309\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.007553; batch classifier loss; 0.607042; batch adversarial loss: 0.465637\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.009481; batch classifier loss; 0.606741; batch adversarial loss: 0.501574\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.007793; batch classifier loss; 0.594672; batch adversarial loss: 0.448343\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.007828; batch classifier loss; 0.543558; batch adversarial loss: 0.515547\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.007774; batch classifier loss; 0.527047; batch adversarial loss: 0.501725\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.007359; batch classifier loss; 0.471527; batch adversarial loss: 0.504079\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.009723; batch classifier loss; 0.564155; batch adversarial loss: 0.463642\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.006415; batch classifier loss; 0.541771; batch adversarial loss: 0.487217\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.007626; batch classifier loss; 0.533772; batch adversarial loss: 0.487197\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.007414; batch classifier loss; 0.504691; batch adversarial loss: 0.505327\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.007157; batch classifier loss; 0.536423; batch adversarial loss: 0.480020\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.008857; batch classifier loss; 0.545200; batch adversarial loss: 0.471184\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.007343; batch classifier loss; 0.545864; batch adversarial loss: 0.464648\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.004871; batch classifier loss; 0.551911; batch adversarial loss: 0.479698\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.009353; batch classifier loss; 0.556271; batch adversarial loss: 0.473991\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.005994; batch classifier loss; 0.558058; batch adversarial loss: 0.440428\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.005527; batch classifier loss; 0.563490; batch adversarial loss: 0.399010\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.011547; batch classifier loss; 0.508296; batch adversarial loss: 0.461793\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.006950; batch classifier loss; 0.572428; batch adversarial loss: 0.453170\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.005517; batch classifier loss; 0.499605; batch adversarial loss: 0.430277\n",
      "\n",
      "Seed 5/5\n",
      "seed=4 || fold=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:45.252689: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.698536\n",
      "epoch 1; iter: 0; batch classifier loss: 0.644113\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609352\n",
      "epoch 3; iter: 0; batch classifier loss: 0.596048\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583602\n",
      "epoch 5; iter: 0; batch classifier loss: 0.625700\n",
      "epoch 6; iter: 0; batch classifier loss: 0.629947\n",
      "epoch 7; iter: 0; batch classifier loss: 0.665734\n",
      "epoch 8; iter: 0; batch classifier loss: 0.620396\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569037\n",
      "epoch 10; iter: 0; batch classifier loss: 0.586416\n",
      "epoch 11; iter: 0; batch classifier loss: 0.503201\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553672\n",
      "epoch 13; iter: 0; batch classifier loss: 0.580706\n",
      "epoch 14; iter: 0; batch classifier loss: 0.568253\n",
      "epoch 15; iter: 0; batch classifier loss: 0.588090\n",
      "epoch 16; iter: 0; batch classifier loss: 0.542207\n",
      "epoch 17; iter: 0; batch classifier loss: 0.599608\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543347\n",
      "epoch 19; iter: 0; batch classifier loss: 0.585650\n",
      "epoch 20; iter: 0; batch classifier loss: 0.599686\n",
      "epoch 21; iter: 0; batch classifier loss: 0.625696\n",
      "epoch 22; iter: 0; batch classifier loss: 0.596082\n",
      "epoch 23; iter: 0; batch classifier loss: 0.616842\n",
      "epoch 24; iter: 0; batch classifier loss: 0.570984\n",
      "epoch 25; iter: 0; batch classifier loss: 0.572695\n",
      "epoch 26; iter: 0; batch classifier loss: 0.579875\n",
      "epoch 27; iter: 0; batch classifier loss: 0.540231\n",
      "epoch 28; iter: 0; batch classifier loss: 0.595519\n",
      "epoch 29; iter: 0; batch classifier loss: 0.538151\n",
      "epoch 30; iter: 0; batch classifier loss: 0.559465\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507608\n",
      "epoch 32; iter: 0; batch classifier loss: 0.529176\n",
      "epoch 33; iter: 0; batch classifier loss: 0.568646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.549603\n",
      "epoch 35; iter: 0; batch classifier loss: 0.541472\n",
      "epoch 36; iter: 0; batch classifier loss: 0.605946\n",
      "epoch 37; iter: 0; batch classifier loss: 0.577179\n",
      "epoch 38; iter: 0; batch classifier loss: 0.536361\n",
      "epoch 39; iter: 0; batch classifier loss: 0.548043\n",
      "epoch 40; iter: 0; batch classifier loss: 0.622670\n",
      "epoch 41; iter: 0; batch classifier loss: 0.612681\n",
      "epoch 42; iter: 0; batch classifier loss: 0.607679\n",
      "epoch 43; iter: 0; batch classifier loss: 0.580202\n",
      "epoch 44; iter: 0; batch classifier loss: 0.573781\n",
      "epoch 45; iter: 0; batch classifier loss: 0.646210\n",
      "epoch 46; iter: 0; batch classifier loss: 0.541363\n",
      "epoch 47; iter: 0; batch classifier loss: 0.569952\n",
      "epoch 48; iter: 0; batch classifier loss: 0.559757\n",
      "epoch 49; iter: 0; batch classifier loss: 0.535638\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.078237; batch classifier loss; 0.621520; batch adversarial loss: 1.360746\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.051220; batch classifier loss; 0.654054; batch adversarial loss: 1.261031\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.035177; batch classifier loss; 0.597477; batch adversarial loss: 1.320257\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.027346; batch classifier loss; 0.556938; batch adversarial loss: 1.379727\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.024672; batch classifier loss; 0.565664; batch adversarial loss: 1.292922\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.027245; batch classifier loss; 0.565474; batch adversarial loss: 1.325227\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.019139; batch classifier loss; 0.539986; batch adversarial loss: 1.315239\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.020226; batch classifier loss; 0.551661; batch adversarial loss: 1.252743\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.014446; batch classifier loss; 0.559229; batch adversarial loss: 1.219234\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.013689; batch classifier loss; 0.556681; batch adversarial loss: 1.239277\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.012589; batch classifier loss; 0.499015; batch adversarial loss: 1.319042\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.008062; batch classifier loss; 0.482827; batch adversarial loss: 1.292107\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.010433; batch classifier loss; 0.523574; batch adversarial loss: 1.253221\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.009602; batch classifier loss; 0.619642; batch adversarial loss: 1.250760\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.008443; batch classifier loss; 0.605819; batch adversarial loss: 1.210094\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.006523; batch classifier loss; 0.640811; batch adversarial loss: 1.198742\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.005715; batch classifier loss; 0.590895; batch adversarial loss: 1.159096\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.007443; batch classifier loss; 0.526655; batch adversarial loss: 1.169976\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.006263; batch classifier loss; 0.522830; batch adversarial loss: 1.229815\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.006172; batch classifier loss; 0.538876; batch adversarial loss: 1.222213\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.004948; batch classifier loss; 0.544975; batch adversarial loss: 1.208801\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.003866; batch classifier loss; 0.552003; batch adversarial loss: 1.213712\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.003563; batch classifier loss; 0.539023; batch adversarial loss: 1.193666\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.003251; batch classifier loss; 0.494454; batch adversarial loss: 1.129289\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.002904; batch classifier loss; 0.543191; batch adversarial loss: 1.157404\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.003287; batch classifier loss; 0.502778; batch adversarial loss: 1.154746\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.003310; batch classifier loss; 0.552759; batch adversarial loss: 1.175523\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.003145; batch classifier loss; 0.559324; batch adversarial loss: 1.068894\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.002538; batch classifier loss; 0.590024; batch adversarial loss: 1.101129\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.002486; batch classifier loss; 0.532319; batch adversarial loss: 1.103996\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.003045; batch classifier loss; 0.599379; batch adversarial loss: 1.080711\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.003485; batch classifier loss; 0.567891; batch adversarial loss: 1.099223\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.003011; batch classifier loss; 0.554987; batch adversarial loss: 1.048782\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.002721; batch classifier loss; 0.565821; batch adversarial loss: 1.058344\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.003966; batch classifier loss; 0.500660; batch adversarial loss: 1.046045\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.003743; batch classifier loss; 0.498527; batch adversarial loss: 1.050555\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.003876; batch classifier loss; 0.557495; batch adversarial loss: 1.099302\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.004036; batch classifier loss; 0.570633; batch adversarial loss: 1.059365\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.004077; batch classifier loss; 0.566580; batch adversarial loss: 1.036502\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.004092; batch classifier loss; 0.510290; batch adversarial loss: 1.043448\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.005218; batch classifier loss; 0.579328; batch adversarial loss: 1.001964\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.005789; batch classifier loss; 0.588235; batch adversarial loss: 1.021728\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.005096; batch classifier loss; 0.596256; batch adversarial loss: 1.047072\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.004818; batch classifier loss; 0.544260; batch adversarial loss: 1.052235\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.005789; batch classifier loss; 0.608956; batch adversarial loss: 0.987964\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.005769; batch classifier loss; 0.514607; batch adversarial loss: 1.033568\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.005737; batch classifier loss; 0.599018; batch adversarial loss: 1.001275\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.007647; batch classifier loss; 0.580513; batch adversarial loss: 0.978083\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.006531; batch classifier loss; 0.573974; batch adversarial loss: 0.972478\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.007241; batch classifier loss; 0.573589; batch adversarial loss: 0.976655\n",
      "seed=4 || fold=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:46.676393: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.689989\n",
      "epoch 1; iter: 0; batch classifier loss: 0.676749\n",
      "epoch 2; iter: 0; batch classifier loss: 0.612259\n",
      "epoch 3; iter: 0; batch classifier loss: 0.631384\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585656\n",
      "epoch 5; iter: 0; batch classifier loss: 0.604654\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574747\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571645\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568316\n",
      "epoch 9; iter: 0; batch classifier loss: 0.582896\n",
      "epoch 10; iter: 0; batch classifier loss: 0.582336\n",
      "epoch 11; iter: 0; batch classifier loss: 0.605189\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571102\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566200\n",
      "epoch 14; iter: 0; batch classifier loss: 0.599894\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546369\n",
      "epoch 16; iter: 0; batch classifier loss: 0.599420\n",
      "epoch 17; iter: 0; batch classifier loss: 0.598139\n",
      "epoch 18; iter: 0; batch classifier loss: 0.545546\n",
      "epoch 19; iter: 0; batch classifier loss: 0.576105\n",
      "epoch 20; iter: 0; batch classifier loss: 0.581277\n",
      "epoch 21; iter: 0; batch classifier loss: 0.572807\n",
      "epoch 22; iter: 0; batch classifier loss: 0.586369\n",
      "epoch 23; iter: 0; batch classifier loss: 0.582124\n",
      "epoch 24; iter: 0; batch classifier loss: 0.576670\n",
      "epoch 25; iter: 0; batch classifier loss: 0.638837\n",
      "epoch 26; iter: 0; batch classifier loss: 0.537449\n",
      "epoch 27; iter: 0; batch classifier loss: 0.548765\n",
      "epoch 28; iter: 0; batch classifier loss: 0.580869\n",
      "epoch 29; iter: 0; batch classifier loss: 0.584265\n",
      "epoch 30; iter: 0; batch classifier loss: 0.572731\n",
      "epoch 31; iter: 0; batch classifier loss: 0.517801\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504666\n",
      "epoch 33; iter: 0; batch classifier loss: 0.549649\n",
      "epoch 34; iter: 0; batch classifier loss: 0.585518\n",
      "epoch 35; iter: 0; batch classifier loss: 0.582020\n",
      "epoch 36; iter: 0; batch classifier loss: 0.677274\n",
      "epoch 37; iter: 0; batch classifier loss: 0.564033\n",
      "epoch 38; iter: 0; batch classifier loss: 0.570740\n",
      "epoch 39; iter: 0; batch classifier loss: 0.602201\n",
      "epoch 40; iter: 0; batch classifier loss: 0.515231\n",
      "epoch 41; iter: 0; batch classifier loss: 0.578655\n",
      "epoch 42; iter: 0; batch classifier loss: 0.579292\n",
      "epoch 43; iter: 0; batch classifier loss: 0.631662\n",
      "epoch 44; iter: 0; batch classifier loss: 0.547595\n",
      "epoch 45; iter: 0; batch classifier loss: 0.560348\n",
      "epoch 46; iter: 0; batch classifier loss: 0.514972\n",
      "epoch 47; iter: 0; batch classifier loss: 0.558052\n",
      "epoch 48; iter: 0; batch classifier loss: 0.588919\n",
      "epoch 49; iter: 0; batch classifier loss: 0.583892\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.057382; batch classifier loss; 0.519983; batch adversarial loss: 0.746576\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.028081; batch classifier loss; 0.534857; batch adversarial loss: 0.802033\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.021868; batch classifier loss; 0.505743; batch adversarial loss: 0.767652\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.020591; batch classifier loss; 0.532542; batch adversarial loss: 0.773090\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.017951; batch classifier loss; 0.566272; batch adversarial loss: 0.806065\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.013976; batch classifier loss; 0.491013; batch adversarial loss: 0.744295\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.012630; batch classifier loss; 0.537166; batch adversarial loss: 0.768322\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.011880; batch classifier loss; 0.600154; batch adversarial loss: 0.803189\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.011880; batch classifier loss; 0.542058; batch adversarial loss: 0.735108\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.008444; batch classifier loss; 0.517202; batch adversarial loss: 0.725857\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.007980; batch classifier loss; 0.505977; batch adversarial loss: 0.731884\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.009569; batch classifier loss; 0.587196; batch adversarial loss: 0.741849\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.006125; batch classifier loss; 0.474609; batch adversarial loss: 0.690574\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.006492; batch classifier loss; 0.565924; batch adversarial loss: 0.761671\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.007003; batch classifier loss; 0.558873; batch adversarial loss: 0.732692\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.007019; batch classifier loss; 0.550368; batch adversarial loss: 0.719620\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.004671; batch classifier loss; 0.593986; batch adversarial loss: 0.728701\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.004656; batch classifier loss; 0.501868; batch adversarial loss: 0.705654\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.004420; batch classifier loss; 0.540550; batch adversarial loss: 0.688595\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.004137; batch classifier loss; 0.593941; batch adversarial loss: 0.720425\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.004444; batch classifier loss; 0.499573; batch adversarial loss: 0.672067\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.003423; batch classifier loss; 0.580193; batch adversarial loss: 0.688965\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.002842; batch classifier loss; 0.580197; batch adversarial loss: 0.703657\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.002781; batch classifier loss; 0.553876; batch adversarial loss: 0.698555\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.003588; batch classifier loss; 0.649026; batch adversarial loss: 0.717718\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.002642; batch classifier loss; 0.530216; batch adversarial loss: 0.687849\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.002931; batch classifier loss; 0.652768; batch adversarial loss: 0.715545\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.001962; batch classifier loss; 0.494892; batch adversarial loss: 0.652303\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.002917; batch classifier loss; 0.545583; batch adversarial loss: 0.654409\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.001982; batch classifier loss; 0.568483; batch adversarial loss: 0.658930\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.002640; batch classifier loss; 0.471853; batch adversarial loss: 0.667401\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.002987; batch classifier loss; 0.494785; batch adversarial loss: 0.640253\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.001736; batch classifier loss; 0.598469; batch adversarial loss: 0.684648\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.002337; batch classifier loss; 0.582965; batch adversarial loss: 0.655790\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.001475; batch classifier loss; 0.560883; batch adversarial loss: 0.662932\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.001992; batch classifier loss; 0.476775; batch adversarial loss: 0.586561\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.001746; batch classifier loss; 0.550299; batch adversarial loss: 0.630585\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.001433; batch classifier loss; 0.517287; batch adversarial loss: 0.643278\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.002038; batch classifier loss; 0.536528; batch adversarial loss: 0.658269\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.001297; batch classifier loss; 0.602055; batch adversarial loss: 0.660675\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.002010; batch classifier loss; 0.585590; batch adversarial loss: 0.646987\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.001758; batch classifier loss; 0.540123; batch adversarial loss: 0.654627\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.001508; batch classifier loss; 0.502528; batch adversarial loss: 0.642914\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.001122; batch classifier loss; 0.539579; batch adversarial loss: 0.634691\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.001567; batch classifier loss; 0.529458; batch adversarial loss: 0.610131\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.001165; batch classifier loss; 0.571358; batch adversarial loss: 0.615389\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.001468; batch classifier loss; 0.546191; batch adversarial loss: 0.593923\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.001444; batch classifier loss; 0.506509; batch adversarial loss: 0.574803\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.001396; batch classifier loss; 0.624071; batch adversarial loss: 0.652362\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.001143; batch classifier loss; 0.526616; batch adversarial loss: 0.588784\n",
      "seed=4 || fold=2\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:48.061772: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 0; batch classifier loss: 0.642949\n",
      "epoch 2; iter: 0; batch classifier loss: 0.662991\n",
      "epoch 3; iter: 0; batch classifier loss: 0.698957\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595304\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633987\n",
      "epoch 6; iter: 0; batch classifier loss: 0.642359\n",
      "epoch 7; iter: 0; batch classifier loss: 0.617145\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613623\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551939\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564075\n",
      "epoch 11; iter: 0; batch classifier loss: 0.589007\n",
      "epoch 12; iter: 0; batch classifier loss: 0.520444\n",
      "epoch 13; iter: 0; batch classifier loss: 0.666085\n",
      "epoch 14; iter: 0; batch classifier loss: 0.626723\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523553\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520849\n",
      "epoch 17; iter: 0; batch classifier loss: 0.599929\n",
      "epoch 18; iter: 0; batch classifier loss: 0.577296\n",
      "epoch 19; iter: 0; batch classifier loss: 0.590163\n",
      "epoch 20; iter: 0; batch classifier loss: 0.559628\n",
      "epoch 21; iter: 0; batch classifier loss: 0.600837\n",
      "epoch 22; iter: 0; batch classifier loss: 0.577271\n",
      "epoch 23; iter: 0; batch classifier loss: 0.578113\n",
      "epoch 24; iter: 0; batch classifier loss: 0.564302\n",
      "epoch 25; iter: 0; batch classifier loss: 0.589373\n",
      "epoch 26; iter: 0; batch classifier loss: 0.591148\n",
      "epoch 27; iter: 0; batch classifier loss: 0.584080\n",
      "epoch 28; iter: 0; batch classifier loss: 0.613631\n",
      "epoch 29; iter: 0; batch classifier loss: 0.541365\n",
      "epoch 30; iter: 0; batch classifier loss: 0.553862\n",
      "epoch 31; iter: 0; batch classifier loss: 0.534794\n",
      "epoch 32; iter: 0; batch classifier loss: 0.555773\n",
      "epoch 33; iter: 0; batch classifier loss: 0.566628\n",
      "epoch 34; iter: 0; batch classifier loss: 0.605442\n",
      "epoch 35; iter: 0; batch classifier loss: 0.550152\n",
      "epoch 36; iter: 0; batch classifier loss: 0.553187\n",
      "epoch 37; iter: 0; batch classifier loss: 0.553197\n",
      "epoch 38; iter: 0; batch classifier loss: 0.536173\n",
      "epoch 39; iter: 0; batch classifier loss: 0.654963\n",
      "epoch 40; iter: 0; batch classifier loss: 0.530484\n",
      "epoch 41; iter: 0; batch classifier loss: 0.615916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.619452\n",
      "epoch 43; iter: 0; batch classifier loss: 0.535085\n",
      "epoch 44; iter: 0; batch classifier loss: 0.583314\n",
      "epoch 45; iter: 0; batch classifier loss: 0.641349\n",
      "epoch 46; iter: 0; batch classifier loss: 0.558657\n",
      "epoch 47; iter: 0; batch classifier loss: 0.619953\n",
      "epoch 48; iter: 0; batch classifier loss: 0.577006\n",
      "epoch 49; iter: 0; batch classifier loss: 0.576904\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.113773; batch classifier loss; 0.620312; batch adversarial loss: 0.435417\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.036621; batch classifier loss; 0.601121; batch adversarial loss: 0.499718\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.038554; batch classifier loss; 0.609161; batch adversarial loss: 0.472229\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.024569; batch classifier loss; 0.596544; batch adversarial loss: 0.471385\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.019208; batch classifier loss; 0.574311; batch adversarial loss: 0.461966\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.018268; batch classifier loss; 0.591203; batch adversarial loss: 0.469134\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.012828; batch classifier loss; 0.600030; batch adversarial loss: 0.424077\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.015849; batch classifier loss; 0.573731; batch adversarial loss: 0.474308\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.015192; batch classifier loss; 0.608846; batch adversarial loss: 0.440122\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.010743; batch classifier loss; 0.568217; batch adversarial loss: 0.479519\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.008977; batch classifier loss; 0.536975; batch adversarial loss: 0.446597\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.008879; batch classifier loss; 0.559172; batch adversarial loss: 0.484427\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.012758; batch classifier loss; 0.573289; batch adversarial loss: 0.445696\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.010118; batch classifier loss; 0.614695; batch adversarial loss: 0.409333\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.010999; batch classifier loss; 0.632226; batch adversarial loss: 0.460935\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.008511; batch classifier loss; 0.538869; batch adversarial loss: 0.453658\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.007094; batch classifier loss; 0.588997; batch adversarial loss: 0.447776\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.008933; batch classifier loss; 0.603700; batch adversarial loss: 0.414442\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.006880; batch classifier loss; 0.545511; batch adversarial loss: 0.482305\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.006208; batch classifier loss; 0.548079; batch adversarial loss: 0.430805\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.005956; batch classifier loss; 0.538367; batch adversarial loss: 0.379265\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.004849; batch classifier loss; 0.550320; batch adversarial loss: 0.432289\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.005066; batch classifier loss; 0.527114; batch adversarial loss: 0.389687\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.006426; batch classifier loss; 0.538312; batch adversarial loss: 0.446015\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.005482; batch classifier loss; 0.545427; batch adversarial loss: 0.485228\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.007051; batch classifier loss; 0.529521; batch adversarial loss: 0.490980\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.006325; batch classifier loss; 0.550904; batch adversarial loss: 0.442552\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.006083; batch classifier loss; 0.574563; batch adversarial loss: 0.432517\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.005147; batch classifier loss; 0.618682; batch adversarial loss: 0.485973\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.006659; batch classifier loss; 0.505805; batch adversarial loss: 0.440218\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.008069; batch classifier loss; 0.541814; batch adversarial loss: 0.487660\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.004723; batch classifier loss; 0.565184; batch adversarial loss: 0.458331\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.004360; batch classifier loss; 0.573942; batch adversarial loss: 0.431952\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.006049; batch classifier loss; 0.582980; batch adversarial loss: 0.436301\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.003236; batch classifier loss; 0.573961; batch adversarial loss: 0.397385\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.005634; batch classifier loss; 0.587165; batch adversarial loss: 0.444687\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.004471; batch classifier loss; 0.636078; batch adversarial loss: 0.417407\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.004903; batch classifier loss; 0.597512; batch adversarial loss: 0.476379\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.005272; batch classifier loss; 0.581386; batch adversarial loss: 0.514962\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.004167; batch classifier loss; 0.549927; batch adversarial loss: 0.463851\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.004483; batch classifier loss; 0.569297; batch adversarial loss: 0.462353\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.003999; batch classifier loss; 0.540187; batch adversarial loss: 0.379840\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.006614; batch classifier loss; 0.561165; batch adversarial loss: 0.470339\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.004068; batch classifier loss; 0.591560; batch adversarial loss: 0.386076\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.004234; batch classifier loss; 0.622675; batch adversarial loss: 0.407097\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.005039; batch classifier loss; 0.532048; batch adversarial loss: 0.491908\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.004205; batch classifier loss; 0.628435; batch adversarial loss: 0.370544\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.005208; batch classifier loss; 0.588565; batch adversarial loss: 0.453238\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.004677; batch classifier loss; 0.583950; batch adversarial loss: 0.461676\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.006458; batch classifier loss; 0.565770; batch adversarial loss: 0.538046\n",
      "seed=4 || fold=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:49.456997: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.663541\n",
      "epoch 1; iter: 0; batch classifier loss: 0.634294\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595762\n",
      "epoch 3; iter: 0; batch classifier loss: 0.581344\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550605\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550751\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591402\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552181\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547054\n",
      "epoch 9; iter: 0; batch classifier loss: 0.592685\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552673\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525316\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537887\n",
      "epoch 13; iter: 0; batch classifier loss: 0.579048\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554685\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563186\n",
      "epoch 16; iter: 0; batch classifier loss: 0.584138\n",
      "epoch 17; iter: 0; batch classifier loss: 0.556098\n",
      "epoch 18; iter: 0; batch classifier loss: 0.589743\n",
      "epoch 19; iter: 0; batch classifier loss: 0.597305\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548467\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517688\n",
      "epoch 22; iter: 0; batch classifier loss: 0.620718\n",
      "epoch 23; iter: 0; batch classifier loss: 0.634050\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517558\n",
      "epoch 25; iter: 0; batch classifier loss: 0.565675\n",
      "epoch 26; iter: 0; batch classifier loss: 0.567041\n",
      "epoch 27; iter: 0; batch classifier loss: 0.521215\n",
      "epoch 28; iter: 0; batch classifier loss: 0.557237\n",
      "epoch 29; iter: 0; batch classifier loss: 0.565760\n",
      "epoch 30; iter: 0; batch classifier loss: 0.574290\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523772\n",
      "epoch 32; iter: 0; batch classifier loss: 0.540183\n",
      "epoch 33; iter: 0; batch classifier loss: 0.585436\n",
      "epoch 34; iter: 0; batch classifier loss: 0.568574\n",
      "epoch 35; iter: 0; batch classifier loss: 0.546314\n",
      "epoch 36; iter: 0; batch classifier loss: 0.551247\n",
      "epoch 37; iter: 0; batch classifier loss: 0.482607\n",
      "epoch 38; iter: 0; batch classifier loss: 0.594121\n",
      "epoch 39; iter: 0; batch classifier loss: 0.512770\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522832\n",
      "epoch 41; iter: 0; batch classifier loss: 0.571565\n",
      "epoch 42; iter: 0; batch classifier loss: 0.591916\n",
      "epoch 43; iter: 0; batch classifier loss: 0.530225\n",
      "epoch 44; iter: 0; batch classifier loss: 0.527015\n",
      "epoch 45; iter: 0; batch classifier loss: 0.546821\n",
      "epoch 46; iter: 0; batch classifier loss: 0.484803\n",
      "epoch 47; iter: 0; batch classifier loss: 0.567318\n",
      "epoch 48; iter: 0; batch classifier loss: 0.581567\n",
      "epoch 49; iter: 0; batch classifier loss: 0.567908\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.048301; batch classifier loss; 0.523758; batch adversarial loss: 1.079006\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.035191; batch classifier loss; 0.582971; batch adversarial loss: 1.116257\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.028160; batch classifier loss; 0.553651; batch adversarial loss: 1.090844\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.025423; batch classifier loss; 0.543455; batch adversarial loss: 1.071040\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.023659; batch classifier loss; 0.482359; batch adversarial loss: 1.043785\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.018007; batch classifier loss; 0.519283; batch adversarial loss: 1.060937\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.014563; batch classifier loss; 0.513699; batch adversarial loss: 1.021909\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.018920; batch classifier loss; 0.549022; batch adversarial loss: 1.010943\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.018979; batch classifier loss; 0.611637; batch adversarial loss: 1.057490\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.012821; batch classifier loss; 0.558850; batch adversarial loss: 1.080821\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.014231; batch classifier loss; 0.643304; batch adversarial loss: 1.026581\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.013720; batch classifier loss; 0.489221; batch adversarial loss: 1.022520\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.013852; batch classifier loss; 0.537225; batch adversarial loss: 0.982241\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.013675; batch classifier loss; 0.504134; batch adversarial loss: 1.003586\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.014112; batch classifier loss; 0.530414; batch adversarial loss: 1.000570\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.012976; batch classifier loss; 0.519674; batch adversarial loss: 0.987563\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.013979; batch classifier loss; 0.567837; batch adversarial loss: 1.034663\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.014482; batch classifier loss; 0.542179; batch adversarial loss: 0.998220\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.016151; batch classifier loss; 0.536903; batch adversarial loss: 0.964241\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.016014; batch classifier loss; 0.492978; batch adversarial loss: 0.952083\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.013729; batch classifier loss; 0.550501; batch adversarial loss: 0.959173\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.013828; batch classifier loss; 0.557103; batch adversarial loss: 0.962439\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.011689; batch classifier loss; 0.563924; batch adversarial loss: 0.930932\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.013870; batch classifier loss; 0.560210; batch adversarial loss: 0.951440\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.014210; batch classifier loss; 0.526917; batch adversarial loss: 0.899427\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.016692; batch classifier loss; 0.530719; batch adversarial loss: 0.894459\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.012773; batch classifier loss; 0.575788; batch adversarial loss: 0.923992\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.013921; batch classifier loss; 0.496690; batch adversarial loss: 0.903934\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.015756; batch classifier loss; 0.585235; batch adversarial loss: 0.887787\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.015228; batch classifier loss; 0.507802; batch adversarial loss: 0.877480\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.015041; batch classifier loss; 0.504447; batch adversarial loss: 0.892908\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.015667; batch classifier loss; 0.526092; batch adversarial loss: 0.849643\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.015949; batch classifier loss; 0.542289; batch adversarial loss: 0.840638\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.013815; batch classifier loss; 0.558778; batch adversarial loss: 0.870631\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.014039; batch classifier loss; 0.579578; batch adversarial loss: 0.876723\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.017720; batch classifier loss; 0.463137; batch adversarial loss: 0.827958\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.015690; batch classifier loss; 0.594371; batch adversarial loss: 0.847298\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.017122; batch classifier loss; 0.598336; batch adversarial loss: 0.857843\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.016603; batch classifier loss; 0.588557; batch adversarial loss: 0.839965\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.015891; batch classifier loss; 0.570595; batch adversarial loss: 0.838602\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.016259; batch classifier loss; 0.529339; batch adversarial loss: 0.810756\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.017211; batch classifier loss; 0.517764; batch adversarial loss: 0.799304\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.015130; batch classifier loss; 0.548937; batch adversarial loss: 0.824054\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.013551; batch classifier loss; 0.504266; batch adversarial loss: 0.803595\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.013969; batch classifier loss; 0.569109; batch adversarial loss: 0.795843\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.016376; batch classifier loss; 0.557935; batch adversarial loss: 0.797244\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.018757; batch classifier loss; 0.549089; batch adversarial loss: 0.781828\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.015016; batch classifier loss; 0.537671; batch adversarial loss: 0.788414\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.018614; batch classifier loss; 0.584559; batch adversarial loss: 0.781346\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.016140; batch classifier loss; 0.535789; batch adversarial loss: 0.778572\n",
      "seed=4 || fold=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:50.870638: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.735410\n",
      "epoch 1; iter: 0; batch classifier loss: 0.683140\n",
      "epoch 2; iter: 0; batch classifier loss: 0.657581\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583051\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603309\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600414\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562279\n",
      "epoch 7; iter: 0; batch classifier loss: 0.605130\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569584\n",
      "epoch 9; iter: 0; batch classifier loss: 0.594956\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610973\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549844\n",
      "epoch 12; iter: 0; batch classifier loss: 0.589856\n",
      "epoch 13; iter: 0; batch classifier loss: 0.573770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.572699\n",
      "epoch 15; iter: 0; batch classifier loss: 0.560102\n",
      "epoch 16; iter: 0; batch classifier loss: 0.572233\n",
      "epoch 17; iter: 0; batch classifier loss: 0.633607\n",
      "epoch 18; iter: 0; batch classifier loss: 0.624999\n",
      "epoch 19; iter: 0; batch classifier loss: 0.544887\n",
      "epoch 20; iter: 0; batch classifier loss: 0.562362\n",
      "epoch 21; iter: 0; batch classifier loss: 0.595314\n",
      "epoch 22; iter: 0; batch classifier loss: 0.588878\n",
      "epoch 23; iter: 0; batch classifier loss: 0.532520\n",
      "epoch 24; iter: 0; batch classifier loss: 0.562551\n",
      "epoch 25; iter: 0; batch classifier loss: 0.648433\n",
      "epoch 26; iter: 0; batch classifier loss: 0.568269\n",
      "epoch 27; iter: 0; batch classifier loss: 0.571286\n",
      "epoch 28; iter: 0; batch classifier loss: 0.542269\n",
      "epoch 29; iter: 0; batch classifier loss: 0.509324\n",
      "epoch 30; iter: 0; batch classifier loss: 0.556106\n",
      "epoch 31; iter: 0; batch classifier loss: 0.580392\n",
      "epoch 32; iter: 0; batch classifier loss: 0.571470\n",
      "epoch 33; iter: 0; batch classifier loss: 0.625481\n",
      "epoch 34; iter: 0; batch classifier loss: 0.566729\n",
      "epoch 35; iter: 0; batch classifier loss: 0.600731\n",
      "epoch 36; iter: 0; batch classifier loss: 0.536584\n",
      "epoch 37; iter: 0; batch classifier loss: 0.526935\n",
      "epoch 38; iter: 0; batch classifier loss: 0.647880\n",
      "epoch 39; iter: 0; batch classifier loss: 0.569715\n",
      "epoch 40; iter: 0; batch classifier loss: 0.579783\n",
      "epoch 41; iter: 0; batch classifier loss: 0.575243\n",
      "epoch 42; iter: 0; batch classifier loss: 0.612943\n",
      "epoch 43; iter: 0; batch classifier loss: 0.578905\n",
      "epoch 44; iter: 0; batch classifier loss: 0.610475\n",
      "epoch 45; iter: 0; batch classifier loss: 0.562566\n",
      "epoch 46; iter: 0; batch classifier loss: 0.551341\n",
      "epoch 47; iter: 0; batch classifier loss: 0.581779\n",
      "epoch 48; iter: 0; batch classifier loss: 0.569184\n",
      "epoch 49; iter: 0; batch classifier loss: 0.530964\n",
      "epoch 0; iter: 0; batch adjuster loss: 0.039076; batch classifier loss; 0.518644; batch adversarial loss: 0.690019\n",
      "epoch 1; iter: 0; batch adjuster loss: 0.026063; batch classifier loss; 0.569646; batch adversarial loss: 0.679646\n",
      "epoch 2; iter: 0; batch adjuster loss: 0.015774; batch classifier loss; 0.540867; batch adversarial loss: 0.668423\n",
      "epoch 3; iter: 0; batch adjuster loss: 0.014808; batch classifier loss; 0.604442; batch adversarial loss: 0.670422\n",
      "epoch 4; iter: 0; batch adjuster loss: 0.011117; batch classifier loss; 0.610169; batch adversarial loss: 0.642498\n",
      "epoch 5; iter: 0; batch adjuster loss: 0.014750; batch classifier loss; 0.597491; batch adversarial loss: 0.635659\n",
      "epoch 6; iter: 0; batch adjuster loss: 0.010323; batch classifier loss; 0.528052; batch adversarial loss: 0.669832\n",
      "epoch 7; iter: 0; batch adjuster loss: 0.008335; batch classifier loss; 0.603325; batch adversarial loss: 0.647576\n",
      "epoch 8; iter: 0; batch adjuster loss: 0.010001; batch classifier loss; 0.590830; batch adversarial loss: 0.640657\n",
      "epoch 9; iter: 0; batch adjuster loss: 0.005757; batch classifier loss; 0.531424; batch adversarial loss: 0.610410\n",
      "epoch 10; iter: 0; batch adjuster loss: 0.008084; batch classifier loss; 0.607965; batch adversarial loss: 0.629765\n",
      "epoch 11; iter: 0; batch adjuster loss: 0.005586; batch classifier loss; 0.509132; batch adversarial loss: 0.653104\n",
      "epoch 12; iter: 0; batch adjuster loss: 0.004449; batch classifier loss; 0.593314; batch adversarial loss: 0.635078\n",
      "epoch 13; iter: 0; batch adjuster loss: 0.005290; batch classifier loss; 0.548878; batch adversarial loss: 0.611746\n",
      "epoch 14; iter: 0; batch adjuster loss: 0.004781; batch classifier loss; 0.535624; batch adversarial loss: 0.628050\n",
      "epoch 15; iter: 0; batch adjuster loss: 0.005592; batch classifier loss; 0.547516; batch adversarial loss: 0.661861\n",
      "epoch 16; iter: 0; batch adjuster loss: 0.003795; batch classifier loss; 0.537852; batch adversarial loss: 0.598388\n",
      "epoch 17; iter: 0; batch adjuster loss: 0.003014; batch classifier loss; 0.557272; batch adversarial loss: 0.633148\n",
      "epoch 18; iter: 0; batch adjuster loss: 0.003762; batch classifier loss; 0.591291; batch adversarial loss: 0.609770\n",
      "epoch 19; iter: 0; batch adjuster loss: 0.003391; batch classifier loss; 0.525524; batch adversarial loss: 0.603652\n",
      "epoch 20; iter: 0; batch adjuster loss: 0.002342; batch classifier loss; 0.523076; batch adversarial loss: 0.612470\n",
      "epoch 21; iter: 0; batch adjuster loss: 0.002210; batch classifier loss; 0.552346; batch adversarial loss: 0.612576\n",
      "epoch 22; iter: 0; batch adjuster loss: 0.002502; batch classifier loss; 0.513023; batch adversarial loss: 0.583380\n",
      "epoch 23; iter: 0; batch adjuster loss: 0.002324; batch classifier loss; 0.533204; batch adversarial loss: 0.584514\n",
      "epoch 24; iter: 0; batch adjuster loss: 0.001776; batch classifier loss; 0.603453; batch adversarial loss: 0.570967\n",
      "epoch 25; iter: 0; batch adjuster loss: 0.001921; batch classifier loss; 0.530391; batch adversarial loss: 0.567142\n",
      "epoch 26; iter: 0; batch adjuster loss: 0.002191; batch classifier loss; 0.568814; batch adversarial loss: 0.587262\n",
      "epoch 27; iter: 0; batch adjuster loss: 0.002141; batch classifier loss; 0.637738; batch adversarial loss: 0.568443\n",
      "epoch 28; iter: 0; batch adjuster loss: 0.001875; batch classifier loss; 0.589877; batch adversarial loss: 0.569446\n",
      "epoch 29; iter: 0; batch adjuster loss: 0.001412; batch classifier loss; 0.596686; batch adversarial loss: 0.544877\n",
      "epoch 30; iter: 0; batch adjuster loss: 0.001433; batch classifier loss; 0.540757; batch adversarial loss: 0.576817\n",
      "epoch 31; iter: 0; batch adjuster loss: 0.001349; batch classifier loss; 0.560218; batch adversarial loss: 0.552127\n",
      "epoch 32; iter: 0; batch adjuster loss: 0.001317; batch classifier loss; 0.556299; batch adversarial loss: 0.563825\n",
      "epoch 33; iter: 0; batch adjuster loss: 0.000932; batch classifier loss; 0.591118; batch adversarial loss: 0.577581\n",
      "epoch 34; iter: 0; batch adjuster loss: 0.001294; batch classifier loss; 0.557844; batch adversarial loss: 0.599603\n",
      "epoch 35; iter: 0; batch adjuster loss: 0.001361; batch classifier loss; 0.522985; batch adversarial loss: 0.536549\n",
      "epoch 36; iter: 0; batch adjuster loss: 0.001196; batch classifier loss; 0.537058; batch adversarial loss: 0.550907\n",
      "epoch 37; iter: 0; batch adjuster loss: 0.001090; batch classifier loss; 0.594221; batch adversarial loss: 0.571426\n",
      "epoch 38; iter: 0; batch adjuster loss: 0.001088; batch classifier loss; 0.494523; batch adversarial loss: 0.564033\n",
      "epoch 39; iter: 0; batch adjuster loss: 0.001044; batch classifier loss; 0.496653; batch adversarial loss: 0.596889\n",
      "epoch 40; iter: 0; batch adjuster loss: 0.000893; batch classifier loss; 0.567256; batch adversarial loss: 0.505153\n",
      "epoch 41; iter: 0; batch adjuster loss: 0.000765; batch classifier loss; 0.545075; batch adversarial loss: 0.526629\n",
      "epoch 42; iter: 0; batch adjuster loss: 0.000964; batch classifier loss; 0.551192; batch adversarial loss: 0.495951\n",
      "epoch 43; iter: 0; batch adjuster loss: 0.000927; batch classifier loss; 0.545517; batch adversarial loss: 0.536745\n",
      "epoch 44; iter: 0; batch adjuster loss: 0.000605; batch classifier loss; 0.566192; batch adversarial loss: 0.498923\n",
      "epoch 45; iter: 0; batch adjuster loss: 0.000780; batch classifier loss; 0.588441; batch adversarial loss: 0.499709\n",
      "epoch 46; iter: 0; batch adjuster loss: 0.000687; batch classifier loss; 0.522205; batch adversarial loss: 0.565236\n",
      "epoch 47; iter: 0; batch adjuster loss: 0.000830; batch classifier loss; 0.600320; batch adversarial loss: 0.498542\n",
      "epoch 48; iter: 0; batch adjuster loss: 0.000988; batch classifier loss; 0.545562; batch adversarial loss: 0.544917\n",
      "epoch 49; iter: 0; batch adjuster loss: 0.000833; batch classifier loss; 0.582630; batch adversarial loss: 0.538177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:22:52.309426: W tensorflow/c/c_api.cc:305] Operation '{name:'debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign' id:265 op device:{requested: '', assigned: ''} def:{{{node debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1, debiased_classifier/debiased_classifier/classifier_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "results = cross_validate_seeds(\n",
    "    dataset_orig,\n",
    "    privileged_groups,\n",
    "    unprivileged_groups,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7dffdab-d697-4253-b734-744740485e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Set: mean outcomes difference</th>\n",
       "      <th>Test Set: Classification accuracy</th>\n",
       "      <th>Test Set: Disparate impact</th>\n",
       "      <th>Test Set: Average odds difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Seed 0</th>\n",
       "      <td>-0.145631</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.793761</td>\n",
       "      <td>-0.224643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed 1</th>\n",
       "      <td>-0.155718</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.741260</td>\n",
       "      <td>-0.279001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed 2</th>\n",
       "      <td>-0.152968</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.771896</td>\n",
       "      <td>-0.232746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed 3</th>\n",
       "      <td>-0.146748</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.788861</td>\n",
       "      <td>-0.233485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed 4</th>\n",
       "      <td>-0.154603</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.693850</td>\n",
       "      <td>-0.324598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Test Set: mean outcomes difference  Test Set: Classification accuracy  \\\n",
       "Seed 0                           -0.145631                              0.701   \n",
       "Seed 1                           -0.155718                              0.711   \n",
       "Seed 2                           -0.152968                              0.705   \n",
       "Seed 3                           -0.146748                              0.709   \n",
       "Seed 4                           -0.154603                              0.708   \n",
       "\n",
       "        Test Set: Disparate impact  Test Set: Average odds difference  \n",
       "Seed 0                    0.793761                          -0.224643  \n",
       "Seed 1                    0.741260                          -0.279001  \n",
       "Seed 2                    0.771896                          -0.232746  \n",
       "Seed 3                    0.788861                          -0.233485  \n",
       "Seed 4                    0.693850                          -0.324598  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = {}\n",
    "for seed, res_dict in results.items():\n",
    "    agg[seed] = pd.DataFrame(res_dict).mean()\n",
    "\n",
    "pd.DataFrame.from_dict(agg).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca2e57-cefd-45c3-8d2c-cae300ca03b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aif360",
   "language": "python",
   "name": "aif360"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
