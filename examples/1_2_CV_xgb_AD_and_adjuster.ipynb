{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77f78f1-bbf9-4aa2-8ec6-770e81cff82c",
   "metadata": {},
   "source": [
    "# CV Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e77836-ff32-42a7-bd51-7253f8e050ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "779c3e6c-a01b-4980-955f-13df60267837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 14:52:09.935547: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 14:52:09.937599: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-08 14:52:09.967755: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 14:52:09.967777: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 14:52:09.967796: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 14:52:09.973414: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-08 14:52:09.974142: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 14:52:10.574209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
=======
   "execution_count": 3,
   "id": "779c3e6c-a01b-4980-955f-13df60267837",
   "metadata": {},
   "outputs": [],
>>>>>>> origin/main
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "from aif360.algorithms.inprocessing.fairness_adjuster import FairnessAdjuster\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import (\n",
    "    load_preproc_data_adult,\n",
    "    load_preproc_data_compas,\n",
    "    load_preproc_data_german,\n",
    ")\n",
    "from aif360.datasets import (\n",
    "    AdultDataset,\n",
    "    BinaryLabelDataset,\n",
    "    CompasDataset,\n",
    "    GermanDataset,\n",
    ")\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "\n",
<<<<<<< HEAD
    "from aif360.algorithms.inprocessing.xgb_fairness_adjuster import XGBFairnessAdjuster\n",
    "from aif360.algorithms.inprocessing.xgb_adversarial_debiasing import (\n",
    "    XGBAdversarialDebiasing,\n",
    ")\n",
    "\n",
=======
>>>>>>> origin/main
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "0b9b720e-6392-4bc4-be66-592bcb471c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SEEDS = 3\n",
    "SHOW_CI = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faaf39f4-c97f-41d0-8fbc-bc77ea549c5b",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 4,
   "id": "faaf39f4-c97f-41d0-8fbc-bc77ea549c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AIF360_dev/aif360/algorithms/preprocessing/optim_preproc_helpers/data_preproc_functions.py:261: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sex'] = df['personal_status'].replace(status_map)\n"
     ]
    }
   ],
>>>>>>> origin/main
   "source": [
    "dataset_orig = load_preproc_data_german([\"age\", \"sex\"])\n",
    "privileged_groups = [{\"age\": 1}]\n",
    "unprivileged_groups = [{\"age\": 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81b6fd7-4d91-4d75-b2ed-db763fbff33a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "protected_attribute_name = list(unprivileged_groups[0].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23007a55-be71-44bc-9fd2-f78ce2bd3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "\n",
    "min_max_scaler = MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e72b206-70b0-4189-97a2-c255e21f7614",
   "metadata": {},
   "source": [
    "Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a49cb98-4106-4c39-828f-88ddecec6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig.features = min_max_scaler.fit_transform(dataset_orig.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29974c55-e8af-45e6-a41f-e71184477f62",
   "metadata": {},
   "source": [
    "CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45f5854-17ad-4b22-9408-40ec54907c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(\n",
    "    dataset_orig_test, dataset_pred_test, unprivileged_groups, privileged_groups\n",
    "):\n",
    "    metric_dataset_debiasing_test = BinaryLabelDatasetMetric(\n",
    "        dataset_orig_test,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "    )\n",
    "    classified_metric_debiasing_test = ClassificationMetric(\n",
    "        dataset_orig_test,\n",
    "        dataset_pred_test,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups,\n",
    "    )\n",
    "    metrics_dict = {\n",
    "        \"Test Set: mean outcomes difference\": metric_dataset_debiasing_test.mean_difference(),\n",
    "        \"Test Set: Classification accuracy\": classified_metric_debiasing_test.accuracy(),\n",
    "        \"Test Set: Disparate impact\": classified_metric_debiasing_test.disparate_impact(),\n",
    "        \"Test Set: Average odds difference\": classified_metric_debiasing_test.average_odds_difference(),\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 27,
>>>>>>> origin/main
   "id": "166e2407-f436-49aa-819d-0cc61542cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score  # Replace with desired metric\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "protected_attribute_name = \"age\"\n",
    "\n",
    "\n",
    "def cross_validate_seeds(\n",
    "    model_class,\n",
    "    model_kwargs,\n",
    "    dataset,\n",
    "    seeds=5,\n",
    "    n_folds=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs cross-validation with multiple seeds.\n",
    "\n",
    "    Parameters:\n",
    "        model: The Scikit-learn model to validate.\n",
    "        X: Feature matrix.\n",
    "        y: Target vector.\n",
    "        seeds: Number of seeds for cross-validation.\n",
    "        folds: Number of folds for each cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        results: Dictionary containing accuracy scores for each seed and fold.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    original_df = dataset.convert_to_dataframe()[0]\n",
    "    for seed in range(seeds):\n",
    "        print(f\"\\nSeed {seed + 1}/{seeds}\")\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "        seed_results = {}\n",
    "        for to_debias in [True, False]:\n",
    "            model_kwargs[\"debias\"] = to_debias\n",
    "            fold_results = []\n",
    "            for fold, (train_idx, test_idx) in enumerate(kf.split(original_df)):\n",
<<<<<<< HEAD
    "                # print(f\"{seed=} || {fold=}\")\n",
=======
    "                print(f\"{seed=} || {fold=}\")\n",
>>>>>>> origin/main
    "                # Splitting data\n",
    "                dataset_X_train, dataset_X_test = dataset.subset(\n",
    "                    train_idx\n",
    "                ), dataset.subset(test_idx)\n",
    "\n",
    "                # Training model\n",
    "                Z = dataset_X_train.protected_attributes[\n",
    "                    :,\n",
    "                    dataset_X_train.protected_attribute_names.index(\n",
    "                        protected_attribute_name\n",
    "                    ),\n",
    "                ]\n",
    "                model_kwargs[\"protected_group_vector\"] = Z\n",
    "                model = model_class(**model_kwargs)\n",
    "                model.fit(dataset_X_train)\n",
    "\n",
    "                # Making predictions\n",
    "                dataset_preds = model.predict(dataset_X_test)\n",
    "\n",
    "                # Evaluating model\n",
    "                metrics = get_metrics(\n",
    "                    dataset_X_test,\n",
    "                    dataset_preds,\n",
    "                    model_kwargs[\"unprivileged_groups\"],\n",
    "                    model_kwargs[\"privileged_groups\"],\n",
    "                )\n",
    "                fold_results.append(metrics)\n",
    "\n",
    "                # end session\n",
    "            seed_results[f\"{to_debias=}\"] = fold_results\n",
    "        results[f\"Seed {seed}\"] = seed_results\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd638e-026b-4ed7-9010-5e0fadcf7e99",
   "metadata": {},
   "source": [
    "Fairness adjuster"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 23,
>>>>>>> origin/main
   "id": "c8fa353a-7302-4cda-83b6-d840f1802397",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "model_class = XGBFairnessAdjuster\n",
    "model_kwargs = {\n",
    "    \"privileged_groups\": privileged_groups,\n",
    "    \"unprivileged_groups\": unprivileged_groups,\n",
    "    \"adversary_loss_weight\": 25.0,\n",
    "    \"seed\": 1234,\n",
    "    \"task\": \"regression\",\n",
=======
    "from _utils import _XGBAdversarialDebiasing, _XGBFairnessAdjuster\n",
    "\n",
    "model_class = _XGBFairnessAdjuster\n",
    "model_kwargs = {\n",
    "    \"privileged_groups\": privileged_groups,\n",
    "    \"unprivileged_groups\": unprivileged_groups,\n",
    "    \"adversary_loss_weight\": 10,\n",
    "    \"seed\": 1234,\n",
>>>>>>> origin/main
    "}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "id": "cddf7c8f-1cbd-48f5-90bb-77fe8eb235d6",
   "metadata": {},
=======
   "execution_count": 24,
   "id": "cddf7c8f-1cbd-48f5-90bb-77fe8eb235d6",
   "metadata": {
    "scrolled": true
   },
>>>>>>> origin/main
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed 1/3\n",
<<<<<<< HEAD
      "\n",
      "Seed 2/3\n",
      "\n",
      "Seed 3/3\n"
=======
      "seed=0 || fold=0\n",
      "seed=0 || fold=1\n",
      "seed=0 || fold=2\n",
      "seed=0 || fold=3\n",
      "seed=0 || fold=4\n",
      "seed=0 || fold=5\n",
      "seed=0 || fold=6\n",
      "seed=0 || fold=7\n",
      "seed=0 || fold=8\n",
      "seed=0 || fold=9\n",
      "seed=0 || fold=0\n",
      "seed=0 || fold=1\n",
      "seed=0 || fold=2\n",
      "seed=0 || fold=3\n",
      "seed=0 || fold=4\n",
      "seed=0 || fold=5\n",
      "seed=0 || fold=6\n",
      "seed=0 || fold=7\n",
      "seed=0 || fold=8\n",
      "seed=0 || fold=9\n",
      "\n",
      "Seed 2/3\n",
      "seed=1 || fold=0\n",
      "seed=1 || fold=1\n",
      "seed=1 || fold=2\n",
      "seed=1 || fold=3\n",
      "seed=1 || fold=4\n",
      "seed=1 || fold=5\n",
      "seed=1 || fold=6\n",
      "seed=1 || fold=7\n",
      "seed=1 || fold=8\n",
      "seed=1 || fold=9\n",
      "seed=1 || fold=0\n",
      "seed=1 || fold=1\n",
      "seed=1 || fold=2\n",
      "seed=1 || fold=3\n",
      "seed=1 || fold=4\n",
      "seed=1 || fold=5\n",
      "seed=1 || fold=6\n",
      "seed=1 || fold=7\n",
      "seed=1 || fold=8\n",
      "seed=1 || fold=9\n",
      "\n",
      "Seed 3/3\n",
      "seed=2 || fold=0\n",
      "seed=2 || fold=1\n",
      "seed=2 || fold=2\n",
      "seed=2 || fold=3\n",
      "seed=2 || fold=4\n",
      "seed=2 || fold=5\n",
      "seed=2 || fold=6\n",
      "seed=2 || fold=7\n",
      "seed=2 || fold=8\n",
      "seed=2 || fold=9\n",
      "seed=2 || fold=0\n",
      "seed=2 || fold=1\n",
      "seed=2 || fold=2\n",
      "seed=2 || fold=3\n",
      "seed=2 || fold=4\n",
      "seed=2 || fold=5\n",
      "seed=2 || fold=6\n",
      "seed=2 || fold=7\n",
      "seed=2 || fold=8\n",
      "seed=2 || fold=9\n"
>>>>>>> origin/main
     ]
    }
   ],
   "source": [
    "results = cross_validate_seeds(\n",
    "    model_class,\n",
    "    model_kwargs,\n",
    "    dataset_orig,\n",
<<<<<<< HEAD
    "    seeds=N_SEEDS,\n",
=======
    "    seeds=3,\n",
>>>>>>> origin/main
    "    n_folds=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 25,
>>>>>>> origin/main
   "id": "ac515715-373e-4375-bfba-c351bf09c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./data/xgb_adjuster_group_cv_results.pickle\", \"wb\") as path:\n",
    "    pickle.dump(results, path, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 26,
>>>>>>> origin/main
   "id": "f0f6d54e-b6c6-4ab9-bf7a-9303c9e891a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Test Set: mean outcomes difference</th>\n",
       "      <th>Test Set: Classification accuracy</th>\n",
       "      <th>Test Set: Disparate impact</th>\n",
       "      <th>Test Set: Average odds difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seed 0</th>\n",
       "      <th>to_debias=True</th>\n",
<<<<<<< HEAD
       "      <td>-0.138795</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.884720</td>\n",
       "      <td>-0.124042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.138795</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.642273</td>\n",
       "      <td>-0.376956</td>\n",
=======
       "      <td>-0.1388 (-0.2802,0.0504)</td>\n",
       "      <td>0.6870 (0.6322,0.7478)</td>\n",
       "      <td>0.6951 (0.5072,0.8638)</td>\n",
       "      <td>-0.3178 (-0.5917,-0.1021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.1388 (-0.2802,0.0504)</td>\n",
       "      <td>0.6870 (0.6245,0.7578)</td>\n",
       "      <td>0.6423 (0.4947,0.8182)</td>\n",
       "      <td>-0.3770 (-0.6058,-0.1918)</td>\n",
>>>>>>> origin/main
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seed 1</th>\n",
       "      <th>to_debias=True</th>\n",
<<<<<<< HEAD
       "      <td>-0.155415</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.892569</td>\n",
       "      <td>-0.115106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.155415</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.635326</td>\n",
       "      <td>-0.379981</td>\n",
=======
       "      <td>-0.1554 (-0.3321,-0.0244)</td>\n",
       "      <td>0.6780 (0.5725,0.7355)</td>\n",
       "      <td>0.7261 (0.5624,0.9194)</td>\n",
       "      <td>-0.2905 (-0.5152,-0.0834)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.1554 (-0.3321,-0.0244)</td>\n",
       "      <td>0.6880 (0.6135,0.7355)</td>\n",
       "      <td>0.6353 (0.4026,0.8333)</td>\n",
       "      <td>-0.3800 (-0.6328,-0.1922)</td>\n",
>>>>>>> origin/main
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seed 2</th>\n",
       "      <th>to_debias=True</th>\n",
<<<<<<< HEAD
       "      <td>-0.153424</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.855516</td>\n",
       "      <td>-0.148835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.153424</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.654457</td>\n",
       "      <td>-0.368520</td>\n",
=======
       "      <td>-0.1534 (-0.3167,-0.0148)</td>\n",
       "      <td>0.6830 (0.6168,0.7810)</td>\n",
       "      <td>0.7871 (0.5835,1.0607)</td>\n",
       "      <td>-0.2267 (-0.4368,0.0691)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.1534 (-0.3167,-0.0148)</td>\n",
       "      <td>0.6990 (0.6445,0.7878)</td>\n",
       "      <td>0.6545 (0.4548,0.7738)</td>\n",
       "      <td>-0.3685 (-0.5950,-0.2118)</td>\n",
>>>>>>> origin/main
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                        Test Set: mean outcomes difference  \\\n",
       "Seed 0 to_debias=True                            -0.138795   \n",
       "       to_debias=False                           -0.138795   \n",
       "Seed 1 to_debias=True                            -0.155415   \n",
       "       to_debias=False                           -0.155415   \n",
       "Seed 2 to_debias=True                            -0.153424   \n",
       "       to_debias=False                           -0.153424   \n",
       "\n",
       "                        Test Set: Classification accuracy  \\\n",
       "Seed 0 to_debias=True                               0.665   \n",
       "       to_debias=False                              0.687   \n",
       "Seed 1 to_debias=True                               0.663   \n",
       "       to_debias=False                              0.688   \n",
       "Seed 2 to_debias=True                               0.676   \n",
       "       to_debias=False                              0.699   \n",
       "\n",
       "                        Test Set: Disparate impact  \\\n",
       "Seed 0 to_debias=True                     0.884720   \n",
       "       to_debias=False                    0.642273   \n",
       "Seed 1 to_debias=True                     0.892569   \n",
       "       to_debias=False                    0.635326   \n",
       "Seed 2 to_debias=True                     0.855516   \n",
       "       to_debias=False                    0.654457   \n",
       "\n",
       "                        Test Set: Average odds difference  \n",
       "Seed 0 to_debias=True                           -0.124042  \n",
       "       to_debias=False                          -0.376956  \n",
       "Seed 1 to_debias=True                           -0.115106  \n",
       "       to_debias=False                          -0.379981  \n",
       "Seed 2 to_debias=True                           -0.148835  \n",
       "       to_debias=False                          -0.368520  "
      ]
     },
     "execution_count": 13,
=======
       "                       Test Set: mean outcomes difference  \\\n",
       "Seed 0 to_debias=True            -0.1388 (-0.2802,0.0504)   \n",
       "       to_debias=False           -0.1388 (-0.2802,0.0504)   \n",
       "Seed 1 to_debias=True           -0.1554 (-0.3321,-0.0244)   \n",
       "       to_debias=False          -0.1554 (-0.3321,-0.0244)   \n",
       "Seed 2 to_debias=True           -0.1534 (-0.3167,-0.0148)   \n",
       "       to_debias=False          -0.1534 (-0.3167,-0.0148)   \n",
       "\n",
       "                       Test Set: Classification accuracy  \\\n",
       "Seed 0 to_debias=True             0.6870 (0.6322,0.7478)   \n",
       "       to_debias=False            0.6870 (0.6245,0.7578)   \n",
       "Seed 1 to_debias=True             0.6780 (0.5725,0.7355)   \n",
       "       to_debias=False            0.6880 (0.6135,0.7355)   \n",
       "Seed 2 to_debias=True             0.6830 (0.6168,0.7810)   \n",
       "       to_debias=False            0.6990 (0.6445,0.7878)   \n",
       "\n",
       "                       Test Set: Disparate impact  \\\n",
       "Seed 0 to_debias=True      0.6951 (0.5072,0.8638)   \n",
       "       to_debias=False     0.6423 (0.4947,0.8182)   \n",
       "Seed 1 to_debias=True      0.7261 (0.5624,0.9194)   \n",
       "       to_debias=False     0.6353 (0.4026,0.8333)   \n",
       "Seed 2 to_debias=True      0.7871 (0.5835,1.0607)   \n",
       "       to_debias=False     0.6545 (0.4548,0.7738)   \n",
       "\n",
       "                       Test Set: Average odds difference  \n",
       "Seed 0 to_debias=True          -0.3178 (-0.5917,-0.1021)  \n",
       "       to_debias=False         -0.3770 (-0.6058,-0.1918)  \n",
       "Seed 1 to_debias=True          -0.2905 (-0.5152,-0.0834)  \n",
       "       to_debias=False         -0.3800 (-0.6328,-0.1922)  \n",
       "Seed 2 to_debias=True           -0.2267 (-0.4368,0.0691)  \n",
       "       to_debias=False         -0.3685 (-0.5950,-0.2118)  "
      ]
     },
     "execution_count": 26,
>>>>>>> origin/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs = {}\n",
    "for seed, res_dict in results.items():\n",
    "    aggs[seed] = {}\n",
    "    for to_debias, fold_res_dict in res_dict.items():\n",
    "        res = pd.DataFrame(fold_res_dict).quantile([0.025, 0.975]).T\n",
    "        res[\"means\"] = pd.DataFrame(fold_res_dict).mean()\n",
<<<<<<< HEAD
    "\n",
    "        if SHOW_CI:\n",
    "            aggs[seed][to_debias] = res.apply(\n",
    "                lambda x: f\"{x.means:.4f} ({x[0.025]:.4f},{x[0.975]:.4f})\", axis=1\n",
    "            )\n",
    "        else:\n",
    "            aggs[seed][to_debias] = res.means\n",
=======
    "        aggs[seed][to_debias] = res.apply(\n",
    "            lambda x: f\"{x.means:.4f} ({x[0.025]:.4f},{x[0.975]:.4f})\", axis=1\n",
    "        )\n",
>>>>>>> origin/main
    "\n",
    "reform = {\n",
    "    (outerKey, innerKey): values\n",
    "    for outerKey, innerDict in aggs.items()\n",
    "    for innerKey, values in innerDict.items()\n",
    "}\n",
<<<<<<< HEAD
    "\n",
    "adjuster_results = pd.DataFrame(reform).T\n",
    "adjuster_results"
=======
    "pd.DataFrame(reform).T"
>>>>>>> origin/main
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce3e8fd-af1a-4af3-9385-cf961c315102",
   "metadata": {},
   "source": [
    "AD"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "id": "6d43353e-c3d3-4093-a180-81aad160953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = XGBAdversarialDebiasing\n",
=======
   "execution_count": 28,
   "id": "6d43353e-c3d3-4093-a180-81aad160953d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_class = _XGBAdversarialDebiasing\n",
>>>>>>> origin/main
    "model_kwargs = {\n",
    "    \"privileged_groups\": privileged_groups,\n",
    "    \"unprivileged_groups\": unprivileged_groups,\n",
    "    \"adversary_loss_weight\": 10,\n",
    "    \"seed\": 1234,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "id": "ff72dd54-832a-4600-b630-603643e7e075",
   "metadata": {},
=======
   "execution_count": 29,
   "id": "ff72dd54-832a-4600-b630-603643e7e075",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
>>>>>>> origin/main
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed 1/3\n",
<<<<<<< HEAD
      "\n",
      "Seed 2/3\n",
      "\n",
      "Seed 3/3\n"
=======
      "seed=0 || fold=0\n",
      "debug=False\n",
      "seed=0 || fold=1\n",
      "debug=False\n",
      "seed=0 || fold=2\n",
      "debug=False\n",
      "seed=0 || fold=3\n",
      "debug=False\n",
      "seed=0 || fold=4\n",
      "debug=False\n",
      "seed=0 || fold=5\n",
      "debug=False\n",
      "seed=0 || fold=6\n",
      "debug=False\n",
      "seed=0 || fold=7\n",
      "debug=False\n",
      "seed=0 || fold=8\n",
      "debug=False\n",
      "seed=0 || fold=9\n",
      "debug=False\n",
      "seed=0 || fold=0\n",
      "seed=0 || fold=1\n",
      "seed=0 || fold=2\n",
      "seed=0 || fold=3\n",
      "seed=0 || fold=4\n",
      "seed=0 || fold=5\n",
      "seed=0 || fold=6\n",
      "seed=0 || fold=7\n",
      "seed=0 || fold=8\n",
      "seed=0 || fold=9\n",
      "\n",
      "Seed 2/3\n",
      "seed=1 || fold=0\n",
      "debug=False\n",
      "seed=1 || fold=1\n",
      "debug=False\n",
      "seed=1 || fold=2\n",
      "debug=False\n",
      "seed=1 || fold=3\n",
      "debug=False\n",
      "seed=1 || fold=4\n",
      "debug=False\n",
      "seed=1 || fold=5\n",
      "debug=False\n",
      "seed=1 || fold=6\n",
      "debug=False\n",
      "seed=1 || fold=7\n",
      "debug=False\n",
      "seed=1 || fold=8\n",
      "debug=False\n",
      "seed=1 || fold=9\n",
      "debug=False\n",
      "seed=1 || fold=0\n",
      "seed=1 || fold=1\n",
      "seed=1 || fold=2\n",
      "seed=1 || fold=3\n",
      "seed=1 || fold=4\n",
      "seed=1 || fold=5\n",
      "seed=1 || fold=6\n",
      "seed=1 || fold=7\n",
      "seed=1 || fold=8\n",
      "seed=1 || fold=9\n",
      "\n",
      "Seed 3/3\n",
      "seed=2 || fold=0\n",
      "debug=False\n",
      "seed=2 || fold=1\n",
      "debug=False\n",
      "seed=2 || fold=2\n",
      "debug=False\n",
      "seed=2 || fold=3\n",
      "debug=False\n",
      "seed=2 || fold=4\n",
      "debug=False\n",
      "seed=2 || fold=5\n",
      "debug=False\n",
      "seed=2 || fold=6\n",
      "debug=False\n",
      "seed=2 || fold=7\n",
      "debug=False\n",
      "seed=2 || fold=8\n",
      "debug=False\n",
      "seed=2 || fold=9\n",
      "debug=False\n",
      "seed=2 || fold=0\n",
      "seed=2 || fold=1\n",
      "seed=2 || fold=2\n",
      "seed=2 || fold=3\n",
      "seed=2 || fold=4\n",
      "seed=2 || fold=5\n",
      "seed=2 || fold=6\n",
      "seed=2 || fold=7\n",
      "seed=2 || fold=8\n",
      "seed=2 || fold=9\n"
>>>>>>> origin/main
     ]
    }
   ],
   "source": [
    "results = cross_validate_seeds(\n",
    "    model_class,\n",
    "    model_kwargs,\n",
    "    dataset_orig,\n",
<<<<<<< HEAD
    "    seeds=N_SEEDS,\n",
=======
    "    seeds=3,\n",
>>>>>>> origin/main
    "    n_folds=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "id": "9b5d194e-86a2-49a1-9a0d-100cd333dc54",
   "metadata": {},
   "outputs": [],
   "source": [
=======
   "execution_count": 30,
   "id": "9b5d194e-86a2-49a1-9a0d-100cd333dc54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
>>>>>>> origin/main
    "with open(\"./data/xgb_ad_group_cv_results.pickle\", \"wb\") as path:\n",
    "    pickle.dump(results, path, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "id": "5b0bddb0-96c5-4e83-9c50-3b1bc1f08f6b",
   "metadata": {},
=======
   "execution_count": 31,
   "id": "5b0bddb0-96c5-4e83-9c50-3b1bc1f08f6b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
>>>>>>> origin/main
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Test Set: mean outcomes difference</th>\n",
       "      <th>Test Set: Classification accuracy</th>\n",
       "      <th>Test Set: Disparate impact</th>\n",
       "      <th>Test Set: Average odds difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seed 0</th>\n",
       "      <th>to_debias=True</th>\n",
<<<<<<< HEAD
       "      <td>-0.138795</td>\n",
       "      <td>0.666</td>\n",
       "      <td>1.035066</td>\n",
       "      <td>0.027509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.138795</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.642273</td>\n",
       "      <td>-0.376956</td>\n",
=======
       "      <td>-0.1388 (-0.2802,0.0504)</td>\n",
       "      <td>0.6660 (0.6200,0.7000)</td>\n",
       "      <td>1.0351 (0.9553,1.1110)</td>\n",
       "      <td>0.0275 (-0.0356,0.0991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.1388 (-0.2802,0.0504)</td>\n",
       "      <td>0.6870 (0.6245,0.7578)</td>\n",
       "      <td>0.6423 (0.4947,0.8182)</td>\n",
       "      <td>-0.3770 (-0.6058,-0.1918)</td>\n",
>>>>>>> origin/main
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seed 1</th>\n",
       "      <th>to_debias=True</th>\n",
<<<<<<< HEAD
       "      <td>-0.155415</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1.047274</td>\n",
       "      <td>0.035766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.155415</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.635326</td>\n",
       "      <td>-0.379981</td>\n",
=======
       "      <td>-0.1554 (-0.3321,-0.0244)</td>\n",
       "      <td>0.6650 (0.5658,0.7077)</td>\n",
       "      <td>1.0473 (0.9592,1.1031)</td>\n",
       "      <td>0.0358 (-0.0398,0.0781)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.1554 (-0.3321,-0.0244)</td>\n",
       "      <td>0.6880 (0.6135,0.7355)</td>\n",
       "      <td>0.6353 (0.4026,0.8333)</td>\n",
       "      <td>-0.3800 (-0.6328,-0.1922)</td>\n",
>>>>>>> origin/main
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seed 2</th>\n",
       "      <th>to_debias=True</th>\n",
<<<<<<< HEAD
       "      <td>-0.153424</td>\n",
       "      <td>0.673</td>\n",
       "      <td>1.033360</td>\n",
       "      <td>0.031944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.153424</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.654457</td>\n",
       "      <td>-0.368520</td>\n",
=======
       "      <td>-0.1534 (-0.3167,-0.0148)</td>\n",
       "      <td>0.6730 (0.6190,0.7588)</td>\n",
       "      <td>1.0334 (0.9040,1.0948)</td>\n",
       "      <td>0.0319 (-0.1010,0.0939)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.1534 (-0.3167,-0.0148)</td>\n",
       "      <td>0.6990 (0.6445,0.7878)</td>\n",
       "      <td>0.6545 (0.4548,0.7738)</td>\n",
       "      <td>-0.3685 (-0.5950,-0.2118)</td>\n",
>>>>>>> origin/main
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                        Test Set: mean outcomes difference  \\\n",
       "Seed 0 to_debias=True                            -0.138795   \n",
       "       to_debias=False                           -0.138795   \n",
       "Seed 1 to_debias=True                            -0.155415   \n",
       "       to_debias=False                           -0.155415   \n",
       "Seed 2 to_debias=True                            -0.153424   \n",
       "       to_debias=False                           -0.153424   \n",
       "\n",
       "                        Test Set: Classification accuracy  \\\n",
       "Seed 0 to_debias=True                               0.666   \n",
       "       to_debias=False                              0.687   \n",
       "Seed 1 to_debias=True                               0.665   \n",
       "       to_debias=False                              0.688   \n",
       "Seed 2 to_debias=True                               0.673   \n",
       "       to_debias=False                              0.699   \n",
       "\n",
       "                        Test Set: Disparate impact  \\\n",
       "Seed 0 to_debias=True                     1.035066   \n",
       "       to_debias=False                    0.642273   \n",
       "Seed 1 to_debias=True                     1.047274   \n",
       "       to_debias=False                    0.635326   \n",
       "Seed 2 to_debias=True                     1.033360   \n",
       "       to_debias=False                    0.654457   \n",
       "\n",
       "                        Test Set: Average odds difference  \n",
       "Seed 0 to_debias=True                            0.027509  \n",
       "       to_debias=False                          -0.376956  \n",
       "Seed 1 to_debias=True                            0.035766  \n",
       "       to_debias=False                          -0.379981  \n",
       "Seed 2 to_debias=True                            0.031944  \n",
       "       to_debias=False                          -0.368520  "
      ]
     },
     "execution_count": 17,
=======
       "                       Test Set: mean outcomes difference  \\\n",
       "Seed 0 to_debias=True            -0.1388 (-0.2802,0.0504)   \n",
       "       to_debias=False           -0.1388 (-0.2802,0.0504)   \n",
       "Seed 1 to_debias=True           -0.1554 (-0.3321,-0.0244)   \n",
       "       to_debias=False          -0.1554 (-0.3321,-0.0244)   \n",
       "Seed 2 to_debias=True           -0.1534 (-0.3167,-0.0148)   \n",
       "       to_debias=False          -0.1534 (-0.3167,-0.0148)   \n",
       "\n",
       "                       Test Set: Classification accuracy  \\\n",
       "Seed 0 to_debias=True             0.6660 (0.6200,0.7000)   \n",
       "       to_debias=False            0.6870 (0.6245,0.7578)   \n",
       "Seed 1 to_debias=True             0.6650 (0.5658,0.7077)   \n",
       "       to_debias=False            0.6880 (0.6135,0.7355)   \n",
       "Seed 2 to_debias=True             0.6730 (0.6190,0.7588)   \n",
       "       to_debias=False            0.6990 (0.6445,0.7878)   \n",
       "\n",
       "                       Test Set: Disparate impact  \\\n",
       "Seed 0 to_debias=True      1.0351 (0.9553,1.1110)   \n",
       "       to_debias=False     0.6423 (0.4947,0.8182)   \n",
       "Seed 1 to_debias=True      1.0473 (0.9592,1.1031)   \n",
       "       to_debias=False     0.6353 (0.4026,0.8333)   \n",
       "Seed 2 to_debias=True      1.0334 (0.9040,1.0948)   \n",
       "       to_debias=False     0.6545 (0.4548,0.7738)   \n",
       "\n",
       "                       Test Set: Average odds difference  \n",
       "Seed 0 to_debias=True            0.0275 (-0.0356,0.0991)  \n",
       "       to_debias=False         -0.3770 (-0.6058,-0.1918)  \n",
       "Seed 1 to_debias=True            0.0358 (-0.0398,0.0781)  \n",
       "       to_debias=False         -0.3800 (-0.6328,-0.1922)  \n",
       "Seed 2 to_debias=True            0.0319 (-0.1010,0.0939)  \n",
       "       to_debias=False         -0.3685 (-0.5950,-0.2118)  "
      ]
     },
     "execution_count": 31,
>>>>>>> origin/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs = {}\n",
    "for seed, res_dict in results.items():\n",
    "    aggs[seed] = {}\n",
    "    for to_debias, fold_res_dict in res_dict.items():\n",
    "        res = pd.DataFrame(fold_res_dict).quantile([0.025, 0.975]).T\n",
    "        res[\"means\"] = pd.DataFrame(fold_res_dict).mean()\n",
<<<<<<< HEAD
    "\n",
    "        if SHOW_CI:\n",
    "            aggs[seed][to_debias] = res.apply(\n",
    "                lambda x: f\"{x.means:.4f} ({x[0.025]:.4f},{x[0.975]:.4f})\", axis=1\n",
    "            )\n",
    "        else:\n",
    "            aggs[seed][to_debias] = res.means\n",
=======
    "        aggs[seed][to_debias] = res.apply(\n",
    "            lambda x: f\"{x.means:.4f} ({x[0.025]:.4f},{x[0.975]:.4f})\", axis=1\n",
    "        )\n",
>>>>>>> origin/main
    "\n",
    "reform = {\n",
    "    (outerKey, innerKey): values\n",
    "    for outerKey, innerDict in aggs.items()\n",
    "    for innerKey, values in innerDict.items()\n",
    "}\n",
<<<<<<< HEAD
    "\n",
    "ad_results = pd.DataFrame(reform).T\n",
    "ad_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aa86873-07f9-4608-aa8d-153ad751128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Test Set: mean outcomes difference</th>\n",
       "      <th>Test Set: Classification accuracy</th>\n",
       "      <th>Test Set: Disparate impact</th>\n",
       "      <th>Test Set: Average odds difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seed 0</th>\n",
       "      <th>to_debias=True</th>\n",
       "      <td>-0.138795</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.884720</td>\n",
       "      <td>-0.124042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.138795</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.642273</td>\n",
       "      <td>-0.376956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seed 1</th>\n",
       "      <th>to_debias=True</th>\n",
       "      <td>-0.155415</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.892569</td>\n",
       "      <td>-0.115106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.155415</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.635326</td>\n",
       "      <td>-0.379981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seed 2</th>\n",
       "      <th>to_debias=True</th>\n",
       "      <td>-0.153424</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.855516</td>\n",
       "      <td>-0.148835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_debias=False</th>\n",
       "      <td>-0.153424</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.654457</td>\n",
       "      <td>-0.368520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Test Set: mean outcomes difference  \\\n",
       "Seed 0 to_debias=True                            -0.138795   \n",
       "       to_debias=False                           -0.138795   \n",
       "Seed 1 to_debias=True                            -0.155415   \n",
       "       to_debias=False                           -0.155415   \n",
       "Seed 2 to_debias=True                            -0.153424   \n",
       "       to_debias=False                           -0.153424   \n",
       "\n",
       "                        Test Set: Classification accuracy  \\\n",
       "Seed 0 to_debias=True                               0.665   \n",
       "       to_debias=False                              0.687   \n",
       "Seed 1 to_debias=True                               0.663   \n",
       "       to_debias=False                              0.688   \n",
       "Seed 2 to_debias=True                               0.676   \n",
       "       to_debias=False                              0.699   \n",
       "\n",
       "                        Test Set: Disparate impact  \\\n",
       "Seed 0 to_debias=True                     0.884720   \n",
       "       to_debias=False                    0.642273   \n",
       "Seed 1 to_debias=True                     0.892569   \n",
       "       to_debias=False                    0.635326   \n",
       "Seed 2 to_debias=True                     0.855516   \n",
       "       to_debias=False                    0.654457   \n",
       "\n",
       "                        Test Set: Average odds difference  \n",
       "Seed 0 to_debias=True                           -0.124042  \n",
       "       to_debias=False                          -0.376956  \n",
       "Seed 1 to_debias=True                           -0.115106  \n",
       "       to_debias=False                          -0.379981  \n",
       "Seed 2 to_debias=True                           -0.148835  \n",
       "       to_debias=False                          -0.368520  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjuster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dc773cb-6c5e-4d9a-acfd-4b006bc600f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Test Set: mean outcomes difference</th>\n",
       "      <th>Test Set: Classification accuracy</th>\n",
       "      <th>Test Set: Disparate impact</th>\n",
       "      <th>Test Set: Average odds difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Seed 0</th>\n",
       "      <th>to_debias=True</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.150150</td>\n",
       "      <td>-14.525292</td>\n",
       "      <td>-550.909983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed 1</th>\n",
       "      <th>to_debias=True</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.300752</td>\n",
       "      <td>-14.772151</td>\n",
       "      <td>-421.833633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed 2</th>\n",
       "      <th>to_debias=True</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.445765</td>\n",
       "      <td>-17.210270</td>\n",
       "      <td>-565.922893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Test Set: mean outcomes difference  \\\n",
       "Seed 0 to_debias=True                                -0.0   \n",
       "Seed 1 to_debias=True                                -0.0   \n",
       "Seed 2 to_debias=True                                -0.0   \n",
       "\n",
       "                       Test Set: Classification accuracy  \\\n",
       "Seed 0 to_debias=True                          -0.150150   \n",
       "Seed 1 to_debias=True                          -0.300752   \n",
       "Seed 2 to_debias=True                           0.445765   \n",
       "\n",
       "                       Test Set: Disparate impact  \\\n",
       "Seed 0 to_debias=True                  -14.525292   \n",
       "Seed 1 to_debias=True                  -14.772151   \n",
       "Seed 2 to_debias=True                  -17.210270   \n",
       "\n",
       "                       Test Set: Average odds difference  \n",
       "Seed 0 to_debias=True                        -550.909983  \n",
       "Seed 1 to_debias=True                        -421.833633  \n",
       "Seed 2 to_debias=True                        -565.922893  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Test Set: mean outcomes difference      0.000000\n",
       "Test Set: Classification accuracy      -0.001712\n",
       "Test Set: Disparate impact            -15.502571\n",
       "Test Set: Average odds difference    -512.888836\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SHOW_CI:\n",
    "    diffs = (adjuster_results - ad_results) / ad_results * 100\n",
    "    diffs = diffs.loc[diffs.index.get_level_values(1) == \"to_debias=True\", :]\n",
    "    display(diffs)\n",
    "    display(diffs.mean(axis=0))\n",
    "\n",
    "    plt.scatter(diffs[\"Test Set: Classification accuracy\"], diffs[\"Test Set: Disparate impact\"])\n",
    "    plt.xlabel(\"Accuracy Percent Change: AD to Adjuster\")\n",
    "    plt.ylabel(\"Disparate Impact Percent Change: AD to Adjuster\")\n",
    "    plt.show()"
=======
    "pd.DataFrame(reform).T"
>>>>>>> origin/main
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aif360",
   "language": "python",
   "name": "aif360"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.15"
=======
   "version": "3.11.10"
>>>>>>> origin/main
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
